{
  "experiment_info": {
    "study": "adaptive_tree_speculative_decoding_paper",
    "target_model": "/mnt/disk1/models/pythia-2.8b",
    "draft_model": "/mnt/disk1/models/pythia-70m",
    "dataset": "WikiText-2 (ModelScope)",
    "num_samples": 10,
    "warmup_runs": 2,
    "max_prompt_length": 800
  },
  "all_results": [
    {
      "method": "Baseline (AR)",
      "experiment": "ablation",
      "config": {
        "max_new_tokens": 500
      },
      "throughput_tps": 132.6502265776551,
      "speedup": 1.0,
      "ttft_ms": 19.11052782088518,
      "ttft_std": 6.213539623024404,
      "tpot_ms": 7.500738041475415,
      "tpot_std": 0.047599166279531105,
      "total_time_ms": 3769.479548558593,
      "total_tokens_generated": 500,
      "tokens_per_round": 1.0,
      "acceptance_rate": 0.0,
      "avg_path_length": 0.0,
      "total_rounds": 500,
      "high_conf_ratio": 0.0,
      "medium_conf_ratio": 0.0,
      "low_conf_ratio": 0.0,
      "early_stops": 0,
      "deep_expansions": 0,
      "total_adjustments": 0,
      "peak_memory_mb": 5798.40234375,
      "throughput_std": 0.8874462406136382,
      "acceptance_std": 0.0,
      "path_length_std": 0.0
    },
    {
      "method": "Fixed Tree (D=4, B=2)",
      "experiment": "ablation",
      "config": {
        "max_new_tokens": 500,
        "tree_depth": 4,
        "branch_factor": 2,
        "max_tree_nodes": 256
      },
      "throughput_tps": 145.13108450843401,
      "speedup": 1.0,
      "ttft_ms": 14.374672342091799,
      "ttft_std": 4.335481038552162,
      "tpot_ms": 7.4720003817230465,
      "tpot_std": 2.392558181595122,
      "total_time_ms": 0.0,
      "total_tokens_generated": 500,
      "tokens_per_round": 4.62962962962963,
      "acceptance_rate": 0.777245213003013,
      "avg_path_length": 4.663471278018078,
      "total_rounds": 108,
      "high_conf_ratio": 0.0,
      "medium_conf_ratio": 0.0,
      "low_conf_ratio": 0.0,
      "early_stops": 0,
      "deep_expansions": 0,
      "total_adjustments": 0,
      "peak_memory_mb": 5891.70556640625,
      "throughput_std": 37.936970135364334,
      "acceptance_std": 0.08798608312876184,
      "path_length_std": 0.527916498772571
    },
    {
      "method": "Fixed Tree (D=5, B=2)",
      "experiment": "ablation",
      "config": {
        "max_new_tokens": 500,
        "tree_depth": 5,
        "branch_factor": 2,
        "max_tree_nodes": 256
      },
      "throughput_tps": 176.97085315212388,
      "speedup": 1.0,
      "ttft_ms": 12.003568187355995,
      "ttft_std": 2.206439197179833,
      "tpot_ms": 5.701577521115541,
      "tpot_std": 0.6227346337696695,
      "total_time_ms": 0.0,
      "total_tokens_generated": 500,
      "tokens_per_round": 5.1020408163265305,
      "acceptance_rate": 0.7380099288546942,
      "avg_path_length": 5.166069501982859,
      "total_rounds": 98,
      "high_conf_ratio": 0.0,
      "medium_conf_ratio": 0.0,
      "low_conf_ratio": 0.0,
      "early_stops": 0,
      "deep_expansions": 0,
      "total_adjustments": 0,
      "peak_memory_mb": 5890.7177734375,
      "throughput_std": 21.36678738794073,
      "acceptance_std": 0.10046624776312355,
      "path_length_std": 0.703263734341865
    },
    {
      "method": "Fixed Tree (D=6, B=2)",
      "experiment": "ablation",
      "config": {
        "max_new_tokens": 500,
        "tree_depth": 6,
        "branch_factor": 2,
        "max_tree_nodes": 256
      },
      "throughput_tps": 183.28681078670485,
      "speedup": 1.0,
      "ttft_ms": 12.56922259926796,
      "ttft_std": 3.178315065515893,
      "tpot_ms": 5.516068235225975,
      "tpot_std": 0.6259520945933017,
      "total_time_ms": 0.0,
      "total_tokens_generated": 500,
      "tokens_per_round": 5.4945054945054945,
      "acceptance_rate": 0.6952579827064341,
      "avg_path_length": 5.562063861651473,
      "total_rounds": 91,
      "high_conf_ratio": 0.0,
      "medium_conf_ratio": 0.0,
      "low_conf_ratio": 0.0,
      "early_stops": 0,
      "deep_expansions": 0,
      "total_adjustments": 0,
      "peak_memory_mb": 5892.02587890625,
      "throughput_std": 25.014555027687866,
      "acceptance_std": 0.10720300025428754,
      "path_length_std": 0.8576240020343003
    },
    {
      "method": "Fixed Tree (D=7, B=2)",
      "experiment": "ablation",
      "config": {
        "max_new_tokens": 500,
        "tree_depth": 7,
        "branch_factor": 2,
        "max_tree_nodes": 256
      },
      "throughput_tps": 182.67642480186979,
      "speedup": 1.0,
      "ttft_ms": 12.041124980896711,
      "ttft_std": 2.1492183391782143,
      "tpot_ms": 5.589985313452781,
      "tpot_std": 0.8441847333483699,
      "total_time_ms": 0.0,
      "total_tokens_generated": 500,
      "tokens_per_round": 5.617977528089888,
      "acceptance_rate": 0.6451105608732017,
      "avg_path_length": 5.805995047858815,
      "total_rounds": 89,
      "high_conf_ratio": 0.0,
      "medium_conf_ratio": 0.0,
      "low_conf_ratio": 0.0,
      "early_stops": 0,
      "deep_expansions": 0,
      "total_adjustments": 0,
      "peak_memory_mb": 5893.79296875,
      "throughput_std": 30.837274412022136,
      "acceptance_std": 0.12593870439451182,
      "path_length_std": 1.1334483395506068
    },
    {
      "method": "Phase 1: Adaptive Branch",
      "experiment": "ablation",
      "config": {
        "phase": 1,
        "max_new_tokens": 500,
        "base_depth": 4,
        "max_depth": 8,
        "high_conf_threshold": 0.8,
        "low_conf_threshold": 0.3,
        "min_branch": 1,
        "max_branch": 4
      },
      "throughput_tps": 167.44528192842867,
      "speedup": 1.0,
      "ttft_ms": 12.21045358106494,
      "ttft_std": 2.14132372906826,
      "tpot_ms": 6.029525864869356,
      "tpot_std": 0.664115062487129,
      "total_time_ms": 0.0,
      "total_tokens_generated": 500,
      "tokens_per_round": 4.587155963302752,
      "acceptance_rate": 0.7705647641940668,
      "avg_path_length": 4.623388585164402,
      "total_rounds": 109,
      "high_conf_ratio": 0.6560027747560606,
      "medium_conf_ratio": 0.2128079812745789,
      "low_conf_ratio": 0.13118924396936063,
      "early_stops": 0,
      "deep_expansions": 0,
      "total_adjustments": 0,
      "peak_memory_mb": 5889.2666015625,
      "throughput_std": 20.683792641006757,
      "acceptance_std": 0.08961516966721242,
      "path_length_std": 0.5376910180032746
    },
    {
      "method": "Phase 2: + Dynamic Depth",
      "experiment": "ablation",
      "config": {
        "phase": 2,
        "max_new_tokens": 500,
        "base_depth": 4,
        "max_depth": 8,
        "high_conf_threshold": 0.8,
        "low_conf_threshold": 0.3,
        "min_branch": 1,
        "max_branch": 4
      },
      "throughput_tps": 185.29272228773195,
      "speedup": 1.0,
      "ttft_ms": 12.057099211961031,
      "ttft_std": 2.201188249927965,
      "tpot_ms": 5.562875969894231,
      "tpot_std": 1.0437214044859695,
      "total_time_ms": 0.0,
      "total_tokens_generated": 500,
      "tokens_per_round": 4.901960784313726,
      "acceptance_rate": 0.8696511913559062,
      "avg_path_length": 5.2179071481354375,
      "total_rounds": 102,
      "high_conf_ratio": 0.6898912645699808,
      "medium_conf_ratio": 0.20278918413252253,
      "low_conf_ratio": 0.10731955129749671,
      "early_stops": 217,
      "deep_expansions": 131,
      "total_adjustments": 0,
      "peak_memory_mb": 5887.87353515625,
      "throughput_std": 34.77182675104414,
      "acceptance_std": 0.23268815345431718,
      "path_length_std": 1.3961289207259033
    },
    {
      "method": "Phase 3: + History Adjust",
      "experiment": "ablation",
      "config": {
        "phase": 3,
        "max_new_tokens": 500,
        "base_depth": 4,
        "max_depth": 8,
        "high_conf_threshold": 0.8,
        "low_conf_threshold": 0.3,
        "min_branch": 1,
        "max_branch": 4
      },
      "throughput_tps": 189.43862906779114,
      "speedup": 1.0,
      "ttft_ms": 22.707947343587875,
      "ttft_std": 32.36244692915673,
      "tpot_ms": 5.415073308907449,
      "tpot_std": 1.0562161513737867,
      "total_time_ms": 0.0,
      "total_tokens_generated": 500,
      "tokens_per_round": 5.2631578947368425,
      "acceptance_rate": 0.9225139553146,
      "avg_path_length": 5.535083731887601,
      "total_rounds": 95,
      "high_conf_ratio": 0.7738321297328673,
      "medium_conf_ratio": 0.12278743322351351,
      "low_conf_ratio": 0.1033804370436193,
      "early_stops": 208,
      "deep_expansions": 81,
      "total_adjustments": 8,
      "peak_memory_mb": 5891.19384765625,
      "throughput_std": 34.38477006584937,
      "acceptance_std": 0.21400388960106048,
      "path_length_std": 1.2840233376063628
    },
    {
      "method": "Phase 1: Adaptive Branch",
      "experiment": "ablation",
      "config": {
        "phase": 1,
        "max_new_tokens": 500,
        "base_depth": 5,
        "max_depth": 9,
        "high_conf_threshold": 0.8,
        "low_conf_threshold": 0.3,
        "min_branch": 1,
        "max_branch": 4
      },
      "throughput_tps": 173.9845897536091,
      "speedup": 1.0,
      "ttft_ms": 12.19066958874464,
      "ttft_std": 2.1268694223766094,
      "tpot_ms": 5.8393566945567725,
      "tpot_std": 0.7814509989749627,
      "total_time_ms": 0.0,
      "total_tokens_generated": 500,
      "tokens_per_round": 5.0,
      "acceptance_rate": 0.7289246994688324,
      "avg_path_length": 5.102472896281827,
      "total_rounds": 100,
      "high_conf_ratio": 0.6687652049397693,
      "medium_conf_ratio": 0.20493645774475794,
      "low_conf_ratio": 0.1262983373154728,
      "early_stops": 0,
      "deep_expansions": 0,
      "total_adjustments": 0,
      "peak_memory_mb": 5890.7099609375,
      "throughput_std": 26.041835588322567,
      "acceptance_std": 0.10915480804303959,
      "path_length_std": 0.7640836563012772
    },
    {
      "method": "Phase 2: + Dynamic Depth",
      "experiment": "ablation",
      "config": {
        "phase": 2,
        "max_new_tokens": 500,
        "base_depth": 5,
        "max_depth": 9,
        "high_conf_threshold": 0.8,
        "low_conf_threshold": 0.3,
        "min_branch": 1,
        "max_branch": 4
      },
      "throughput_tps": 183.53999577126362,
      "speedup": 1.0,
      "ttft_ms": 12.032621540129185,
      "ttft_std": 2.2357328417603846,
      "tpot_ms": 5.589734222181141,
      "tpot_std": 0.9142242507380702,
      "total_time_ms": 0.0,
      "total_tokens_generated": 500,
      "tokens_per_round": 5.05050505050505,
      "acceptance_rate": 0.7590433038261619,
      "avg_path_length": 5.3133031267831345,
      "total_rounds": 99,
      "high_conf_ratio": 0.6783755336399067,
      "medium_conf_ratio": 0.21273175637983482,
      "low_conf_ratio": 0.10889270998025853,
      "early_stops": 245,
      "deep_expansions": 98,
      "total_adjustments": 0,
      "peak_memory_mb": 5889.45166015625,
      "throughput_std": 34.182512169649,
      "acceptance_std": 0.20931567789129094,
      "path_length_std": 1.4652097452390365
    },
    {
      "method": "Phase 3: + History Adjust",
      "experiment": "ablation",
      "config": {
        "phase": 3,
        "max_new_tokens": 500,
        "base_depth": 5,
        "max_depth": 9,
        "high_conf_threshold": 0.8,
        "low_conf_threshold": 0.3,
        "min_branch": 1,
        "max_branch": 4
      },
      "throughput_tps": 187.23885218462414,
      "speedup": 1.0,
      "ttft_ms": 12.099421955645084,
      "ttft_std": 2.162500107971628,
      "tpot_ms": 5.503231918253005,
      "tpot_std": 1.040213730194245,
      "total_time_ms": 0.0,
      "total_tokens_generated": 500,
      "tokens_per_round": 5.319148936170213,
      "acceptance_rate": 0.8027933738791161,
      "avg_path_length": 5.619553617153812,
      "total_rounds": 94,
      "high_conf_ratio": 0.7512532954636691,
      "medium_conf_ratio": 0.1398274323813799,
      "low_conf_ratio": 0.10891927215495097,
      "early_stops": 239,
      "deep_expansions": 61,
      "total_adjustments": 8,
      "peak_memory_mb": 5886.30615234375,
      "throughput_std": 35.13235526842775,
      "acceptance_std": 0.2048541152102152,
      "path_length_std": 1.4339788064715064
    },
    {
      "method": "Phase 1: Adaptive Branch",
      "experiment": "ablation",
      "config": {
        "phase": 1,
        "max_new_tokens": 500,
        "base_depth": 6,
        "max_depth": 10,
        "high_conf_threshold": 0.8,
        "low_conf_threshold": 0.3,
        "min_branch": 1,
        "max_branch": 4
      },
      "throughput_tps": 176.85275648349634,
      "speedup": 1.0,
      "ttft_ms": 11.98486527428031,
      "ttft_std": 2.096551778710222,
      "tpot_ms": 5.755119572766125,
      "tpot_std": 0.7850349727352507,
      "total_time_ms": 0.0,
      "total_tokens_generated": 500,
      "tokens_per_round": 5.434782608695652,
      "acceptance_rate": 0.688742550104522,
      "avg_path_length": 5.509940400836176,
      "total_rounds": 92,
      "high_conf_ratio": 0.6530406188963191,
      "medium_conf_ratio": 0.21749319098685863,
      "low_conf_ratio": 0.1294661901168223,
      "early_stops": 0,
      "deep_expansions": 0,
      "total_adjustments": 0,
      "peak_memory_mb": 5891.708984375,
      "throughput_std": 28.30929610728101,
      "acceptance_std": 0.1105579792215144,
      "path_length_std": 0.8844638337721152
    },
    {
      "method": "Phase 2: + Dynamic Depth",
      "experiment": "ablation",
      "config": {
        "phase": 2,
        "max_new_tokens": 500,
        "base_depth": 6,
        "max_depth": 10,
        "high_conf_threshold": 0.8,
        "low_conf_threshold": 0.3,
        "min_branch": 1,
        "max_branch": 4
      },
      "throughput_tps": 191.3047490034919,
      "speedup": 1.0,
      "ttft_ms": 12.056670244783163,
      "ttft_std": 2.1745108548487906,
      "tpot_ms": 5.389101213589311,
      "tpot_std": 1.0057355244631447,
      "total_time_ms": 0.0,
      "total_tokens_generated": 500,
      "tokens_per_round": 5.434782608695652,
      "acceptance_rate": 0.7223753954060215,
      "avg_path_length": 5.779003163248172,
      "total_rounds": 92,
      "high_conf_ratio": 0.6978521298718383,
      "medium_conf_ratio": 0.19302322247003106,
      "low_conf_ratio": 0.10912464765813061,
      "early_stops": 249,
      "deep_expansions": 92,
      "total_adjustments": 0,
      "peak_memory_mb": 5888.08642578125,
      "throughput_std": 36.8470602445332,
      "acceptance_std": 0.20171861572101987,
      "path_length_std": 1.613748925768159
    },
    {
      "method": "Phase 3: + History Adjust",
      "experiment": "ablation",
      "config": {
        "phase": 3,
        "max_new_tokens": 500,
        "base_depth": 6,
        "max_depth": 10,
        "high_conf_threshold": 0.8,
        "low_conf_threshold": 0.3,
        "min_branch": 1,
        "max_branch": 4
      },
      "throughput_tps": 192.25482668327294,
      "speedup": 1.0,
      "ttft_ms": 12.18658471480012,
      "ttft_std": 2.3531899582570626,
      "tpot_ms": 5.352353573031723,
      "tpot_std": 0.9703482465580824,
      "total_time_ms": 0.0,
      "total_tokens_generated": 500,
      "tokens_per_round": 5.617977528089888,
      "acceptance_rate": 0.7419142067942378,
      "avg_path_length": 5.9353136543539025,
      "total_rounds": 89,
      "high_conf_ratio": 0.73101330025182,
      "medium_conf_ratio": 0.16149032438132932,
      "low_conf_ratio": 0.10749637536685072,
      "early_stops": 248,
      "deep_expansions": 63,
      "total_adjustments": 8,
      "peak_memory_mb": 5890.50732421875,
      "throughput_std": 36.1405110527844,
      "acceptance_std": 0.1951370448553543,
      "path_length_std": 1.5610963588428344
    }
  ],
  "paper_tables": {
    "ablation_study": {
      "title": "Ablation Study Results",
      "data": [
        {
          "method": "Baseline (AR)",
          "experiment": "ablation",
          "config": {
            "max_new_tokens": 500
          },
          "throughput_tps": 132.6502265776551,
          "speedup": 1.0,
          "ttft_ms": 19.11052782088518,
          "ttft_std": 6.213539623024404,
          "tpot_ms": 7.500738041475415,
          "tpot_std": 0.047599166279531105,
          "total_time_ms": 3769.479548558593,
          "total_tokens_generated": 500,
          "tokens_per_round": 1.0,
          "acceptance_rate": 0.0,
          "avg_path_length": 0.0,
          "total_rounds": 500,
          "high_conf_ratio": 0.0,
          "medium_conf_ratio": 0.0,
          "low_conf_ratio": 0.0,
          "early_stops": 0,
          "deep_expansions": 0,
          "total_adjustments": 0,
          "peak_memory_mb": 5798.40234375,
          "throughput_std": 0.8874462406136382,
          "acceptance_std": 0.0,
          "path_length_std": 0.0
        },
        {
          "method": "Fixed Tree (D=4, B=2)",
          "experiment": "ablation",
          "config": {
            "max_new_tokens": 500,
            "tree_depth": 4,
            "branch_factor": 2,
            "max_tree_nodes": 256
          },
          "throughput_tps": 145.13108450843401,
          "speedup": 1.0,
          "ttft_ms": 14.374672342091799,
          "ttft_std": 4.335481038552162,
          "tpot_ms": 7.4720003817230465,
          "tpot_std": 2.392558181595122,
          "total_time_ms": 0.0,
          "total_tokens_generated": 500,
          "tokens_per_round": 4.62962962962963,
          "acceptance_rate": 0.777245213003013,
          "avg_path_length": 4.663471278018078,
          "total_rounds": 108,
          "high_conf_ratio": 0.0,
          "medium_conf_ratio": 0.0,
          "low_conf_ratio": 0.0,
          "early_stops": 0,
          "deep_expansions": 0,
          "total_adjustments": 0,
          "peak_memory_mb": 5891.70556640625,
          "throughput_std": 37.936970135364334,
          "acceptance_std": 0.08798608312876184,
          "path_length_std": 0.527916498772571
        },
        {
          "method": "Fixed Tree (D=5, B=2)",
          "experiment": "ablation",
          "config": {
            "max_new_tokens": 500,
            "tree_depth": 5,
            "branch_factor": 2,
            "max_tree_nodes": 256
          },
          "throughput_tps": 176.97085315212388,
          "speedup": 1.0,
          "ttft_ms": 12.003568187355995,
          "ttft_std": 2.206439197179833,
          "tpot_ms": 5.701577521115541,
          "tpot_std": 0.6227346337696695,
          "total_time_ms": 0.0,
          "total_tokens_generated": 500,
          "tokens_per_round": 5.1020408163265305,
          "acceptance_rate": 0.7380099288546942,
          "avg_path_length": 5.166069501982859,
          "total_rounds": 98,
          "high_conf_ratio": 0.0,
          "medium_conf_ratio": 0.0,
          "low_conf_ratio": 0.0,
          "early_stops": 0,
          "deep_expansions": 0,
          "total_adjustments": 0,
          "peak_memory_mb": 5890.7177734375,
          "throughput_std": 21.36678738794073,
          "acceptance_std": 0.10046624776312355,
          "path_length_std": 0.703263734341865
        },
        {
          "method": "Fixed Tree (D=6, B=2)",
          "experiment": "ablation",
          "config": {
            "max_new_tokens": 500,
            "tree_depth": 6,
            "branch_factor": 2,
            "max_tree_nodes": 256
          },
          "throughput_tps": 183.28681078670485,
          "speedup": 1.0,
          "ttft_ms": 12.56922259926796,
          "ttft_std": 3.178315065515893,
          "tpot_ms": 5.516068235225975,
          "tpot_std": 0.6259520945933017,
          "total_time_ms": 0.0,
          "total_tokens_generated": 500,
          "tokens_per_round": 5.4945054945054945,
          "acceptance_rate": 0.6952579827064341,
          "avg_path_length": 5.562063861651473,
          "total_rounds": 91,
          "high_conf_ratio": 0.0,
          "medium_conf_ratio": 0.0,
          "low_conf_ratio": 0.0,
          "early_stops": 0,
          "deep_expansions": 0,
          "total_adjustments": 0,
          "peak_memory_mb": 5892.02587890625,
          "throughput_std": 25.014555027687866,
          "acceptance_std": 0.10720300025428754,
          "path_length_std": 0.8576240020343003
        },
        {
          "method": "Fixed Tree (D=7, B=2)",
          "experiment": "ablation",
          "config": {
            "max_new_tokens": 500,
            "tree_depth": 7,
            "branch_factor": 2,
            "max_tree_nodes": 256
          },
          "throughput_tps": 182.67642480186979,
          "speedup": 1.0,
          "ttft_ms": 12.041124980896711,
          "ttft_std": 2.1492183391782143,
          "tpot_ms": 5.589985313452781,
          "tpot_std": 0.8441847333483699,
          "total_time_ms": 0.0,
          "total_tokens_generated": 500,
          "tokens_per_round": 5.617977528089888,
          "acceptance_rate": 0.6451105608732017,
          "avg_path_length": 5.805995047858815,
          "total_rounds": 89,
          "high_conf_ratio": 0.0,
          "medium_conf_ratio": 0.0,
          "low_conf_ratio": 0.0,
          "early_stops": 0,
          "deep_expansions": 0,
          "total_adjustments": 0,
          "peak_memory_mb": 5893.79296875,
          "throughput_std": 30.837274412022136,
          "acceptance_std": 0.12593870439451182,
          "path_length_std": 1.1334483395506068
        },
        {
          "method": "Phase 1: Adaptive Branch",
          "experiment": "ablation",
          "config": {
            "phase": 1,
            "max_new_tokens": 500,
            "base_depth": 4,
            "max_depth": 8,
            "high_conf_threshold": 0.8,
            "low_conf_threshold": 0.3,
            "min_branch": 1,
            "max_branch": 4
          },
          "throughput_tps": 167.44528192842867,
          "speedup": 1.0,
          "ttft_ms": 12.21045358106494,
          "ttft_std": 2.14132372906826,
          "tpot_ms": 6.029525864869356,
          "tpot_std": 0.664115062487129,
          "total_time_ms": 0.0,
          "total_tokens_generated": 500,
          "tokens_per_round": 4.587155963302752,
          "acceptance_rate": 0.7705647641940668,
          "avg_path_length": 4.623388585164402,
          "total_rounds": 109,
          "high_conf_ratio": 0.6560027747560606,
          "medium_conf_ratio": 0.2128079812745789,
          "low_conf_ratio": 0.13118924396936063,
          "early_stops": 0,
          "deep_expansions": 0,
          "total_adjustments": 0,
          "peak_memory_mb": 5889.2666015625,
          "throughput_std": 20.683792641006757,
          "acceptance_std": 0.08961516966721242,
          "path_length_std": 0.5376910180032746
        },
        {
          "method": "Phase 2: + Dynamic Depth",
          "experiment": "ablation",
          "config": {
            "phase": 2,
            "max_new_tokens": 500,
            "base_depth": 4,
            "max_depth": 8,
            "high_conf_threshold": 0.8,
            "low_conf_threshold": 0.3,
            "min_branch": 1,
            "max_branch": 4
          },
          "throughput_tps": 185.29272228773195,
          "speedup": 1.0,
          "ttft_ms": 12.057099211961031,
          "ttft_std": 2.201188249927965,
          "tpot_ms": 5.562875969894231,
          "tpot_std": 1.0437214044859695,
          "total_time_ms": 0.0,
          "total_tokens_generated": 500,
          "tokens_per_round": 4.901960784313726,
          "acceptance_rate": 0.8696511913559062,
          "avg_path_length": 5.2179071481354375,
          "total_rounds": 102,
          "high_conf_ratio": 0.6898912645699808,
          "medium_conf_ratio": 0.20278918413252253,
          "low_conf_ratio": 0.10731955129749671,
          "early_stops": 217,
          "deep_expansions": 131,
          "total_adjustments": 0,
          "peak_memory_mb": 5887.87353515625,
          "throughput_std": 34.77182675104414,
          "acceptance_std": 0.23268815345431718,
          "path_length_std": 1.3961289207259033
        },
        {
          "method": "Phase 3: + History Adjust",
          "experiment": "ablation",
          "config": {
            "phase": 3,
            "max_new_tokens": 500,
            "base_depth": 4,
            "max_depth": 8,
            "high_conf_threshold": 0.8,
            "low_conf_threshold": 0.3,
            "min_branch": 1,
            "max_branch": 4
          },
          "throughput_tps": 189.43862906779114,
          "speedup": 1.0,
          "ttft_ms": 22.707947343587875,
          "ttft_std": 32.36244692915673,
          "tpot_ms": 5.415073308907449,
          "tpot_std": 1.0562161513737867,
          "total_time_ms": 0.0,
          "total_tokens_generated": 500,
          "tokens_per_round": 5.2631578947368425,
          "acceptance_rate": 0.9225139553146,
          "avg_path_length": 5.535083731887601,
          "total_rounds": 95,
          "high_conf_ratio": 0.7738321297328673,
          "medium_conf_ratio": 0.12278743322351351,
          "low_conf_ratio": 0.1033804370436193,
          "early_stops": 208,
          "deep_expansions": 81,
          "total_adjustments": 8,
          "peak_memory_mb": 5891.19384765625,
          "throughput_std": 34.38477006584937,
          "acceptance_std": 0.21400388960106048,
          "path_length_std": 1.2840233376063628
        },
        {
          "method": "Phase 1: Adaptive Branch",
          "experiment": "ablation",
          "config": {
            "phase": 1,
            "max_new_tokens": 500,
            "base_depth": 5,
            "max_depth": 9,
            "high_conf_threshold": 0.8,
            "low_conf_threshold": 0.3,
            "min_branch": 1,
            "max_branch": 4
          },
          "throughput_tps": 173.9845897536091,
          "speedup": 1.0,
          "ttft_ms": 12.19066958874464,
          "ttft_std": 2.1268694223766094,
          "tpot_ms": 5.8393566945567725,
          "tpot_std": 0.7814509989749627,
          "total_time_ms": 0.0,
          "total_tokens_generated": 500,
          "tokens_per_round": 5.0,
          "acceptance_rate": 0.7289246994688324,
          "avg_path_length": 5.102472896281827,
          "total_rounds": 100,
          "high_conf_ratio": 0.6687652049397693,
          "medium_conf_ratio": 0.20493645774475794,
          "low_conf_ratio": 0.1262983373154728,
          "early_stops": 0,
          "deep_expansions": 0,
          "total_adjustments": 0,
          "peak_memory_mb": 5890.7099609375,
          "throughput_std": 26.041835588322567,
          "acceptance_std": 0.10915480804303959,
          "path_length_std": 0.7640836563012772
        },
        {
          "method": "Phase 2: + Dynamic Depth",
          "experiment": "ablation",
          "config": {
            "phase": 2,
            "max_new_tokens": 500,
            "base_depth": 5,
            "max_depth": 9,
            "high_conf_threshold": 0.8,
            "low_conf_threshold": 0.3,
            "min_branch": 1,
            "max_branch": 4
          },
          "throughput_tps": 183.53999577126362,
          "speedup": 1.0,
          "ttft_ms": 12.032621540129185,
          "ttft_std": 2.2357328417603846,
          "tpot_ms": 5.589734222181141,
          "tpot_std": 0.9142242507380702,
          "total_time_ms": 0.0,
          "total_tokens_generated": 500,
          "tokens_per_round": 5.05050505050505,
          "acceptance_rate": 0.7590433038261619,
          "avg_path_length": 5.3133031267831345,
          "total_rounds": 99,
          "high_conf_ratio": 0.6783755336399067,
          "medium_conf_ratio": 0.21273175637983482,
          "low_conf_ratio": 0.10889270998025853,
          "early_stops": 245,
          "deep_expansions": 98,
          "total_adjustments": 0,
          "peak_memory_mb": 5889.45166015625,
          "throughput_std": 34.182512169649,
          "acceptance_std": 0.20931567789129094,
          "path_length_std": 1.4652097452390365
        },
        {
          "method": "Phase 3: + History Adjust",
          "experiment": "ablation",
          "config": {
            "phase": 3,
            "max_new_tokens": 500,
            "base_depth": 5,
            "max_depth": 9,
            "high_conf_threshold": 0.8,
            "low_conf_threshold": 0.3,
            "min_branch": 1,
            "max_branch": 4
          },
          "throughput_tps": 187.23885218462414,
          "speedup": 1.0,
          "ttft_ms": 12.099421955645084,
          "ttft_std": 2.162500107971628,
          "tpot_ms": 5.503231918253005,
          "tpot_std": 1.040213730194245,
          "total_time_ms": 0.0,
          "total_tokens_generated": 500,
          "tokens_per_round": 5.319148936170213,
          "acceptance_rate": 0.8027933738791161,
          "avg_path_length": 5.619553617153812,
          "total_rounds": 94,
          "high_conf_ratio": 0.7512532954636691,
          "medium_conf_ratio": 0.1398274323813799,
          "low_conf_ratio": 0.10891927215495097,
          "early_stops": 239,
          "deep_expansions": 61,
          "total_adjustments": 8,
          "peak_memory_mb": 5886.30615234375,
          "throughput_std": 35.13235526842775,
          "acceptance_std": 0.2048541152102152,
          "path_length_std": 1.4339788064715064
        },
        {
          "method": "Phase 1: Adaptive Branch",
          "experiment": "ablation",
          "config": {
            "phase": 1,
            "max_new_tokens": 500,
            "base_depth": 6,
            "max_depth": 10,
            "high_conf_threshold": 0.8,
            "low_conf_threshold": 0.3,
            "min_branch": 1,
            "max_branch": 4
          },
          "throughput_tps": 176.85275648349634,
          "speedup": 1.0,
          "ttft_ms": 11.98486527428031,
          "ttft_std": 2.096551778710222,
          "tpot_ms": 5.755119572766125,
          "tpot_std": 0.7850349727352507,
          "total_time_ms": 0.0,
          "total_tokens_generated": 500,
          "tokens_per_round": 5.434782608695652,
          "acceptance_rate": 0.688742550104522,
          "avg_path_length": 5.509940400836176,
          "total_rounds": 92,
          "high_conf_ratio": 0.6530406188963191,
          "medium_conf_ratio": 0.21749319098685863,
          "low_conf_ratio": 0.1294661901168223,
          "early_stops": 0,
          "deep_expansions": 0,
          "total_adjustments": 0,
          "peak_memory_mb": 5891.708984375,
          "throughput_std": 28.30929610728101,
          "acceptance_std": 0.1105579792215144,
          "path_length_std": 0.8844638337721152
        },
        {
          "method": "Phase 2: + Dynamic Depth",
          "experiment": "ablation",
          "config": {
            "phase": 2,
            "max_new_tokens": 500,
            "base_depth": 6,
            "max_depth": 10,
            "high_conf_threshold": 0.8,
            "low_conf_threshold": 0.3,
            "min_branch": 1,
            "max_branch": 4
          },
          "throughput_tps": 191.3047490034919,
          "speedup": 1.0,
          "ttft_ms": 12.056670244783163,
          "ttft_std": 2.1745108548487906,
          "tpot_ms": 5.389101213589311,
          "tpot_std": 1.0057355244631447,
          "total_time_ms": 0.0,
          "total_tokens_generated": 500,
          "tokens_per_round": 5.434782608695652,
          "acceptance_rate": 0.7223753954060215,
          "avg_path_length": 5.779003163248172,
          "total_rounds": 92,
          "high_conf_ratio": 0.6978521298718383,
          "medium_conf_ratio": 0.19302322247003106,
          "low_conf_ratio": 0.10912464765813061,
          "early_stops": 249,
          "deep_expansions": 92,
          "total_adjustments": 0,
          "peak_memory_mb": 5888.08642578125,
          "throughput_std": 36.8470602445332,
          "acceptance_std": 0.20171861572101987,
          "path_length_std": 1.613748925768159
        },
        {
          "method": "Phase 3: + History Adjust",
          "experiment": "ablation",
          "config": {
            "phase": 3,
            "max_new_tokens": 500,
            "base_depth": 6,
            "max_depth": 10,
            "high_conf_threshold": 0.8,
            "low_conf_threshold": 0.3,
            "min_branch": 1,
            "max_branch": 4
          },
          "throughput_tps": 192.25482668327294,
          "speedup": 1.0,
          "ttft_ms": 12.18658471480012,
          "ttft_std": 2.3531899582570626,
          "tpot_ms": 5.352353573031723,
          "tpot_std": 0.9703482465580824,
          "total_time_ms": 0.0,
          "total_tokens_generated": 500,
          "tokens_per_round": 5.617977528089888,
          "acceptance_rate": 0.7419142067942378,
          "avg_path_length": 5.9353136543539025,
          "total_rounds": 89,
          "high_conf_ratio": 0.73101330025182,
          "medium_conf_ratio": 0.16149032438132932,
          "low_conf_ratio": 0.10749637536685072,
          "early_stops": 248,
          "deep_expansions": 63,
          "total_adjustments": 8,
          "peak_memory_mb": 5890.50732421875,
          "throughput_std": 36.1405110527844,
          "acceptance_std": 0.1951370448553543,
          "path_length_std": 1.5610963588428344
        }
      ]
    }
  },
  "timestamp": "2026-01-04T16:20:54.184813"
}