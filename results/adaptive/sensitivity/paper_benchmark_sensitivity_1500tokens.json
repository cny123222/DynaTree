{
  "experiment_info": {
    "study": "adaptive_tree_speculative_decoding_paper",
    "target_model": "/mnt/disk1/models/pythia-2.8b",
    "draft_model": "/mnt/disk1/models/pythia-70m",
    "dataset": "WikiText-2 (ModelScope)",
    "num_samples": 10,
    "warmup_runs": 2,
    "max_prompt_length": 800
  },
  "all_results": [
    {
      "method": "Baseline (AR)",
      "experiment": "sensitivity",
      "config": {
        "max_new_tokens": 1500
      },
      "throughput_tps": 132.89254035983203,
      "speedup": 1.0,
      "ttft_ms": 24.315893463790417,
      "ttft_std": 18.53429269234645,
      "tpot_ms": 7.508767073539396,
      "tpot_std": 0.017544846933557377,
      "total_time_ms": 11287.466503772885,
      "total_tokens_generated": 1500,
      "tokens_per_round": 1.0,
      "acceptance_rate": 0.0,
      "avg_path_length": 0.0,
      "total_rounds": 1500,
      "high_conf_ratio": 0.0,
      "medium_conf_ratio": 0.0,
      "low_conf_ratio": 0.0,
      "early_stops": 0,
      "deep_expansions": 0,
      "total_adjustments": 0,
      "peak_memory_mb": 6110.0478515625,
      "throughput_std": 0.48502927285587794,
      "acceptance_std": 0.0,
      "path_length_std": 0.0
    },
    {
      "method": "Linear Spec (K=5)",
      "experiment": "sensitivity",
      "config": {
        "max_new_tokens": 1500,
        "K": 5
      },
      "throughput_tps": 165.59890088766784,
      "speedup": 1.2461113350627286,
      "ttft_ms": 14.798724744468927,
      "ttft_std": 3.9816545876857985,
      "tpot_ms": 6.215498788282274,
      "tpot_std": 1.199929857759219,
      "total_time_ms": 0.0,
      "total_tokens_generated": 1500,
      "tokens_per_round": 4.838709677419355,
      "acceptance_rate": 0.9766699358505975,
      "avg_path_length": 4.883349679252987,
      "total_rounds": 310,
      "high_conf_ratio": 0.0,
      "medium_conf_ratio": 0.0,
      "low_conf_ratio": 0.0,
      "early_stops": 0,
      "deep_expansions": 0,
      "total_adjustments": 0,
      "peak_memory_mb": 6315.60986328125,
      "throughput_std": 26.50568758389206,
      "acceptance_std": 0.09608676547124308,
      "path_length_std": 0.48043382735621554
    },
    {
      "method": "Fixed Tree (D=5, B=2)",
      "experiment": "sensitivity",
      "config": {
        "max_new_tokens": 1500,
        "tree_depth": 5,
        "branch_factor": 2,
        "max_tree_nodes": 256
      },
      "throughput_tps": 188.24530843395254,
      "speedup": 1.4165227628596933,
      "ttft_ms": 16.000104043632746,
      "ttft_std": 3.699121693222986,
      "tpot_ms": 5.34466956810405,
      "tpot_std": 0.49973548445425,
      "total_time_ms": 0.0,
      "total_tokens_generated": 1500,
      "tokens_per_round": 5.747126436781609,
      "acceptance_rate": 0.825941627645741,
      "avg_path_length": 5.781591393520188,
      "total_rounds": 261,
      "high_conf_ratio": 0.0,
      "medium_conf_ratio": 0.0,
      "low_conf_ratio": 0.0,
      "early_stops": 0,
      "deep_expansions": 0,
      "total_adjustments": 0,
      "peak_memory_mb": 6312.23486328125,
      "throughput_std": 16.35572733061212,
      "acceptance_std": 0.07393047962268853,
      "path_length_std": 0.5175133573588199
    },
    {
      "method": "Phase 3: + History Adjust",
      "experiment": "sensitivity_thresh_0.7_0.2",
      "config": {
        "phase": 3,
        "max_new_tokens": 1500,
        "base_depth": 5,
        "max_depth": 8,
        "high_conf_threshold": 0.7,
        "low_conf_threshold": 0.2,
        "min_branch": 1,
        "max_branch": 3
      },
      "throughput_tps": 211.9320195799334,
      "speedup": 1.5947623471271364,
      "ttft_ms": 14.959119912236929,
      "ttft_std": 3.99514201629615,
      "tpot_ms": 4.871948568398754,
      "tpot_std": 1.0393190566811377,
      "total_time_ms": 0.0,
      "total_tokens_generated": 1500,
      "tokens_per_round": 6.437768240343348,
      "acceptance_rate": 0.9779842619113577,
      "avg_path_length": 6.845889833379504,
      "total_rounds": 233,
      "high_conf_ratio": 0.8865498145988651,
      "medium_conf_ratio": 0.077230787285891,
      "low_conf_ratio": 0.03621939811524384,
      "early_stops": 218,
      "deep_expansions": 238,
      "total_adjustments": 8,
      "peak_memory_mb": 6313.8427734375,
      "throughput_std": 34.11338323080291,
      "acceptance_std": 0.19433963596727358,
      "path_length_std": 1.3603774517709153
    },
    {
      "method": "Phase 3: + History Adjust",
      "experiment": "sensitivity_thresh_0.8_0.3",
      "config": {
        "phase": 3,
        "max_new_tokens": 1500,
        "base_depth": 5,
        "max_depth": 8,
        "high_conf_threshold": 0.8,
        "low_conf_threshold": 0.3,
        "min_branch": 1,
        "max_branch": 3
      },
      "throughput_tps": 201.595475114188,
      "speedup": 1.516981123006074,
      "ttft_ms": 15.556770842522383,
      "ttft_std": 3.6396303586567798,
      "tpot_ms": 5.031186192668974,
      "tpot_std": 0.667494724192682,
      "total_time_ms": 0.0,
      "total_tokens_generated": 1500,
      "tokens_per_round": 6.8493150684931505,
      "acceptance_rate": 1.0007785893688514,
      "avg_path_length": 7.0054501255819615,
      "total_rounds": 219,
      "high_conf_ratio": 0.8738297776063915,
      "medium_conf_ratio": 0.07702944986630618,
      "low_conf_ratio": 0.0491407725273024,
      "early_stops": 247,
      "deep_expansions": 240,
      "total_adjustments": 8,
      "peak_memory_mb": 6314.083984375,
      "throughput_std": 24.670423745644293,
      "acceptance_std": 0.14333170437320755,
      "path_length_std": 1.003321930612453
    },
    {
      "method": "Phase 3: + History Adjust",
      "experiment": "sensitivity_thresh_0.9_0.4",
      "config": {
        "phase": 3,
        "max_new_tokens": 1500,
        "base_depth": 5,
        "max_depth": 8,
        "high_conf_threshold": 0.9,
        "low_conf_threshold": 0.4,
        "min_branch": 1,
        "max_branch": 3
      },
      "throughput_tps": 217.7953785674891,
      "speedup": 1.638883401414153,
      "ttft_ms": 14.707969035953283,
      "ttft_std": 4.059774256999667,
      "tpot_ms": 4.629873780533672,
      "tpot_std": 0.4739493420033517,
      "total_time_ms": 0.0,
      "total_tokens_generated": 1500,
      "tokens_per_round": 7.0754716981132075,
      "acceptance_rate": 1.0217663066942029,
      "avg_path_length": 7.152364146859421,
      "total_rounds": 212,
      "high_conf_ratio": 0.8566188679398692,
      "medium_conf_ratio": 0.07732636430527094,
      "low_conf_ratio": 0.06605476775485983,
      "early_stops": 273,
      "deep_expansions": 239,
      "total_adjustments": 8,
      "peak_memory_mb": 6316.3779296875,
      "throughput_std": 22.216605746811773,
      "acceptance_std": 0.11998937420487714,
      "path_length_std": 0.8399256194341401
    },
    {
      "method": "Phase 3: + History Adjust",
      "experiment": "sensitivity_branch_1_2",
      "config": {
        "phase": 3,
        "max_new_tokens": 1500,
        "base_depth": 5,
        "max_depth": 8,
        "high_conf_threshold": 0.9,
        "low_conf_threshold": 0.4,
        "min_branch": 1,
        "max_branch": 2
      },
      "throughput_tps": 217.79240719592798,
      "speedup": 1.6388610422090908,
      "ttft_ms": 14.961251989006996,
      "ttft_std": 4.090416694120826,
      "tpot_ms": 4.751264667200545,
      "tpot_std": 1.0879740518066816,
      "total_time_ms": 0.0,
      "total_tokens_generated": 1500,
      "tokens_per_round": 6.550218340611353,
      "acceptance_rate": 1.0066518308328527,
      "avg_path_length": 7.04656281582997,
      "total_rounds": 229,
      "high_conf_ratio": 0.8450402751573914,
      "medium_conf_ratio": 0.07459548565745147,
      "low_conf_ratio": 0.08036423918515714,
      "early_stops": 237,
      "deep_expansions": 245,
      "total_adjustments": 8,
      "peak_memory_mb": 6313.69287109375,
      "throughput_std": 34.58687768216252,
      "acceptance_std": 0.2065374083133367,
      "path_length_std": 1.4457618581933571
    },
    {
      "method": "Phase 3: + History Adjust",
      "experiment": "sensitivity_branch_1_3",
      "config": {
        "phase": 3,
        "max_new_tokens": 1500,
        "base_depth": 5,
        "max_depth": 8,
        "high_conf_threshold": 0.9,
        "low_conf_threshold": 0.4,
        "min_branch": 1,
        "max_branch": 3
      },
      "throughput_tps": 217.48011652783103,
      "speedup": 1.6365110933914118,
      "ttft_ms": 15.210725087672472,
      "ttft_std": 4.485910689337008,
      "tpot_ms": 4.633585930801928,
      "tpot_std": 0.46148724020738763,
      "total_time_ms": 0.0,
      "total_tokens_generated": 1500,
      "tokens_per_round": 7.0754716981132075,
      "acceptance_rate": 1.0217663066942029,
      "avg_path_length": 7.152364146859421,
      "total_rounds": 212,
      "high_conf_ratio": 0.8566188679398692,
      "medium_conf_ratio": 0.07732636430527094,
      "low_conf_ratio": 0.06605476775485983,
      "early_stops": 273,
      "deep_expansions": 239,
      "total_adjustments": 8,
      "peak_memory_mb": 6316.3779296875,
      "throughput_std": 21.52929473236562,
      "acceptance_std": 0.11998937420487714,
      "path_length_std": 0.8399256194341401
    },
    {
      "method": "Phase 3: + History Adjust",
      "experiment": "sensitivity_branch_1_4",
      "config": {
        "phase": 3,
        "max_new_tokens": 1500,
        "base_depth": 5,
        "max_depth": 8,
        "high_conf_threshold": 0.9,
        "low_conf_threshold": 0.4,
        "min_branch": 1,
        "max_branch": 4
      },
      "throughput_tps": 217.73895784519272,
      "speedup": 1.6384588424272932,
      "ttft_ms": 17.79354866594076,
      "ttft_std": 10.542021799302368,
      "tpot_ms": 4.630895289716621,
      "tpot_std": 0.47849414693959846,
      "total_time_ms": 0.0,
      "total_tokens_generated": 1500,
      "tokens_per_round": 7.109004739336493,
      "acceptance_rate": 1.0259250327566258,
      "avg_path_length": 7.18147522929638,
      "total_rounds": 211,
      "high_conf_ratio": 0.8733884585613982,
      "medium_conf_ratio": 0.06431934967181291,
      "low_conf_ratio": 0.06229219176678885,
      "early_stops": 327,
      "deep_expansions": 245,
      "total_adjustments": 8,
      "peak_memory_mb": 6314.099609375,
      "throughput_std": 22.87139737567852,
      "acceptance_std": 0.11855016576934659,
      "path_length_std": 0.8298511603854262
    },
    {
      "method": "Phase 3: + History Adjust",
      "experiment": "sensitivity_branch_2_4",
      "config": {
        "phase": 3,
        "max_new_tokens": 1500,
        "base_depth": 5,
        "max_depth": 8,
        "high_conf_threshold": 0.9,
        "low_conf_threshold": 0.4,
        "min_branch": 2,
        "max_branch": 4
      },
      "throughput_tps": 183.0843598638963,
      "speedup": 1.3776872604599197,
      "ttft_ms": 16.548031195998192,
      "ttft_std": 6.2799988334345045,
      "tpot_ms": 5.720788499837121,
      "tpot_std": 1.4867875369038641,
      "total_time_ms": 0.0,
      "total_tokens_generated": 1500,
      "tokens_per_round": 6.122448979591836,
      "acceptance_rate": 0.8932080910209569,
      "avg_path_length": 6.252456637146698,
      "total_rounds": 245,
      "high_conf_ratio": 0.7589070930715448,
      "medium_conf_ratio": 0.1234284807200174,
      "low_conf_ratio": 0.1176644262084378,
      "early_stops": 1650,
      "deep_expansions": 194,
      "total_adjustments": 8,
      "peak_memory_mb": 6319.78466796875,
      "throughput_std": 34.548437905509424,
      "acceptance_std": 0.12609234397238483,
      "path_length_std": 0.8826464078066938
    }
  ],
  "paper_tables": {
    "parameter_sensitivity": {
      "title": "Parameter Sensitivity Results",
      "data": [
        {
          "method": "Baseline (AR)",
          "experiment": "sensitivity",
          "config": {
            "max_new_tokens": 1500
          },
          "throughput_tps": 132.89254035983203,
          "speedup": 1.0,
          "ttft_ms": 24.315893463790417,
          "ttft_std": 18.53429269234645,
          "tpot_ms": 7.508767073539396,
          "tpot_std": 0.017544846933557377,
          "total_time_ms": 11287.466503772885,
          "total_tokens_generated": 1500,
          "tokens_per_round": 1.0,
          "acceptance_rate": 0.0,
          "avg_path_length": 0.0,
          "total_rounds": 1500,
          "high_conf_ratio": 0.0,
          "medium_conf_ratio": 0.0,
          "low_conf_ratio": 0.0,
          "early_stops": 0,
          "deep_expansions": 0,
          "total_adjustments": 0,
          "peak_memory_mb": 6110.0478515625,
          "throughput_std": 0.48502927285587794,
          "acceptance_std": 0.0,
          "path_length_std": 0.0
        },
        {
          "method": "Linear Spec (K=5)",
          "experiment": "sensitivity",
          "config": {
            "max_new_tokens": 1500,
            "K": 5
          },
          "throughput_tps": 165.59890088766784,
          "speedup": 1.2461113350627286,
          "ttft_ms": 14.798724744468927,
          "ttft_std": 3.9816545876857985,
          "tpot_ms": 6.215498788282274,
          "tpot_std": 1.199929857759219,
          "total_time_ms": 0.0,
          "total_tokens_generated": 1500,
          "tokens_per_round": 4.838709677419355,
          "acceptance_rate": 0.9766699358505975,
          "avg_path_length": 4.883349679252987,
          "total_rounds": 310,
          "high_conf_ratio": 0.0,
          "medium_conf_ratio": 0.0,
          "low_conf_ratio": 0.0,
          "early_stops": 0,
          "deep_expansions": 0,
          "total_adjustments": 0,
          "peak_memory_mb": 6315.60986328125,
          "throughput_std": 26.50568758389206,
          "acceptance_std": 0.09608676547124308,
          "path_length_std": 0.48043382735621554
        },
        {
          "method": "Fixed Tree (D=5, B=2)",
          "experiment": "sensitivity",
          "config": {
            "max_new_tokens": 1500,
            "tree_depth": 5,
            "branch_factor": 2,
            "max_tree_nodes": 256
          },
          "throughput_tps": 188.24530843395254,
          "speedup": 1.4165227628596933,
          "ttft_ms": 16.000104043632746,
          "ttft_std": 3.699121693222986,
          "tpot_ms": 5.34466956810405,
          "tpot_std": 0.49973548445425,
          "total_time_ms": 0.0,
          "total_tokens_generated": 1500,
          "tokens_per_round": 5.747126436781609,
          "acceptance_rate": 0.825941627645741,
          "avg_path_length": 5.781591393520188,
          "total_rounds": 261,
          "high_conf_ratio": 0.0,
          "medium_conf_ratio": 0.0,
          "low_conf_ratio": 0.0,
          "early_stops": 0,
          "deep_expansions": 0,
          "total_adjustments": 0,
          "peak_memory_mb": 6312.23486328125,
          "throughput_std": 16.35572733061212,
          "acceptance_std": 0.07393047962268853,
          "path_length_std": 0.5175133573588199
        },
        {
          "method": "Phase 3: + History Adjust",
          "experiment": "sensitivity_thresh_0.7_0.2",
          "config": {
            "phase": 3,
            "max_new_tokens": 1500,
            "base_depth": 5,
            "max_depth": 8,
            "high_conf_threshold": 0.7,
            "low_conf_threshold": 0.2,
            "min_branch": 1,
            "max_branch": 3
          },
          "throughput_tps": 211.9320195799334,
          "speedup": 1.5947623471271364,
          "ttft_ms": 14.959119912236929,
          "ttft_std": 3.99514201629615,
          "tpot_ms": 4.871948568398754,
          "tpot_std": 1.0393190566811377,
          "total_time_ms": 0.0,
          "total_tokens_generated": 1500,
          "tokens_per_round": 6.437768240343348,
          "acceptance_rate": 0.9779842619113577,
          "avg_path_length": 6.845889833379504,
          "total_rounds": 233,
          "high_conf_ratio": 0.8865498145988651,
          "medium_conf_ratio": 0.077230787285891,
          "low_conf_ratio": 0.03621939811524384,
          "early_stops": 218,
          "deep_expansions": 238,
          "total_adjustments": 8,
          "peak_memory_mb": 6313.8427734375,
          "throughput_std": 34.11338323080291,
          "acceptance_std": 0.19433963596727358,
          "path_length_std": 1.3603774517709153
        },
        {
          "method": "Phase 3: + History Adjust",
          "experiment": "sensitivity_thresh_0.8_0.3",
          "config": {
            "phase": 3,
            "max_new_tokens": 1500,
            "base_depth": 5,
            "max_depth": 8,
            "high_conf_threshold": 0.8,
            "low_conf_threshold": 0.3,
            "min_branch": 1,
            "max_branch": 3
          },
          "throughput_tps": 201.595475114188,
          "speedup": 1.516981123006074,
          "ttft_ms": 15.556770842522383,
          "ttft_std": 3.6396303586567798,
          "tpot_ms": 5.031186192668974,
          "tpot_std": 0.667494724192682,
          "total_time_ms": 0.0,
          "total_tokens_generated": 1500,
          "tokens_per_round": 6.8493150684931505,
          "acceptance_rate": 1.0007785893688514,
          "avg_path_length": 7.0054501255819615,
          "total_rounds": 219,
          "high_conf_ratio": 0.8738297776063915,
          "medium_conf_ratio": 0.07702944986630618,
          "low_conf_ratio": 0.0491407725273024,
          "early_stops": 247,
          "deep_expansions": 240,
          "total_adjustments": 8,
          "peak_memory_mb": 6314.083984375,
          "throughput_std": 24.670423745644293,
          "acceptance_std": 0.14333170437320755,
          "path_length_std": 1.003321930612453
        },
        {
          "method": "Phase 3: + History Adjust",
          "experiment": "sensitivity_thresh_0.9_0.4",
          "config": {
            "phase": 3,
            "max_new_tokens": 1500,
            "base_depth": 5,
            "max_depth": 8,
            "high_conf_threshold": 0.9,
            "low_conf_threshold": 0.4,
            "min_branch": 1,
            "max_branch": 3
          },
          "throughput_tps": 217.7953785674891,
          "speedup": 1.638883401414153,
          "ttft_ms": 14.707969035953283,
          "ttft_std": 4.059774256999667,
          "tpot_ms": 4.629873780533672,
          "tpot_std": 0.4739493420033517,
          "total_time_ms": 0.0,
          "total_tokens_generated": 1500,
          "tokens_per_round": 7.0754716981132075,
          "acceptance_rate": 1.0217663066942029,
          "avg_path_length": 7.152364146859421,
          "total_rounds": 212,
          "high_conf_ratio": 0.8566188679398692,
          "medium_conf_ratio": 0.07732636430527094,
          "low_conf_ratio": 0.06605476775485983,
          "early_stops": 273,
          "deep_expansions": 239,
          "total_adjustments": 8,
          "peak_memory_mb": 6316.3779296875,
          "throughput_std": 22.216605746811773,
          "acceptance_std": 0.11998937420487714,
          "path_length_std": 0.8399256194341401
        },
        {
          "method": "Phase 3: + History Adjust",
          "experiment": "sensitivity_branch_1_2",
          "config": {
            "phase": 3,
            "max_new_tokens": 1500,
            "base_depth": 5,
            "max_depth": 8,
            "high_conf_threshold": 0.9,
            "low_conf_threshold": 0.4,
            "min_branch": 1,
            "max_branch": 2
          },
          "throughput_tps": 217.79240719592798,
          "speedup": 1.6388610422090908,
          "ttft_ms": 14.961251989006996,
          "ttft_std": 4.090416694120826,
          "tpot_ms": 4.751264667200545,
          "tpot_std": 1.0879740518066816,
          "total_time_ms": 0.0,
          "total_tokens_generated": 1500,
          "tokens_per_round": 6.550218340611353,
          "acceptance_rate": 1.0066518308328527,
          "avg_path_length": 7.04656281582997,
          "total_rounds": 229,
          "high_conf_ratio": 0.8450402751573914,
          "medium_conf_ratio": 0.07459548565745147,
          "low_conf_ratio": 0.08036423918515714,
          "early_stops": 237,
          "deep_expansions": 245,
          "total_adjustments": 8,
          "peak_memory_mb": 6313.69287109375,
          "throughput_std": 34.58687768216252,
          "acceptance_std": 0.2065374083133367,
          "path_length_std": 1.4457618581933571
        },
        {
          "method": "Phase 3: + History Adjust",
          "experiment": "sensitivity_branch_1_3",
          "config": {
            "phase": 3,
            "max_new_tokens": 1500,
            "base_depth": 5,
            "max_depth": 8,
            "high_conf_threshold": 0.9,
            "low_conf_threshold": 0.4,
            "min_branch": 1,
            "max_branch": 3
          },
          "throughput_tps": 217.48011652783103,
          "speedup": 1.6365110933914118,
          "ttft_ms": 15.210725087672472,
          "ttft_std": 4.485910689337008,
          "tpot_ms": 4.633585930801928,
          "tpot_std": 0.46148724020738763,
          "total_time_ms": 0.0,
          "total_tokens_generated": 1500,
          "tokens_per_round": 7.0754716981132075,
          "acceptance_rate": 1.0217663066942029,
          "avg_path_length": 7.152364146859421,
          "total_rounds": 212,
          "high_conf_ratio": 0.8566188679398692,
          "medium_conf_ratio": 0.07732636430527094,
          "low_conf_ratio": 0.06605476775485983,
          "early_stops": 273,
          "deep_expansions": 239,
          "total_adjustments": 8,
          "peak_memory_mb": 6316.3779296875,
          "throughput_std": 21.52929473236562,
          "acceptance_std": 0.11998937420487714,
          "path_length_std": 0.8399256194341401
        },
        {
          "method": "Phase 3: + History Adjust",
          "experiment": "sensitivity_branch_1_4",
          "config": {
            "phase": 3,
            "max_new_tokens": 1500,
            "base_depth": 5,
            "max_depth": 8,
            "high_conf_threshold": 0.9,
            "low_conf_threshold": 0.4,
            "min_branch": 1,
            "max_branch": 4
          },
          "throughput_tps": 217.73895784519272,
          "speedup": 1.6384588424272932,
          "ttft_ms": 17.79354866594076,
          "ttft_std": 10.542021799302368,
          "tpot_ms": 4.630895289716621,
          "tpot_std": 0.47849414693959846,
          "total_time_ms": 0.0,
          "total_tokens_generated": 1500,
          "tokens_per_round": 7.109004739336493,
          "acceptance_rate": 1.0259250327566258,
          "avg_path_length": 7.18147522929638,
          "total_rounds": 211,
          "high_conf_ratio": 0.8733884585613982,
          "medium_conf_ratio": 0.06431934967181291,
          "low_conf_ratio": 0.06229219176678885,
          "early_stops": 327,
          "deep_expansions": 245,
          "total_adjustments": 8,
          "peak_memory_mb": 6314.099609375,
          "throughput_std": 22.87139737567852,
          "acceptance_std": 0.11855016576934659,
          "path_length_std": 0.8298511603854262
        },
        {
          "method": "Phase 3: + History Adjust",
          "experiment": "sensitivity_branch_2_4",
          "config": {
            "phase": 3,
            "max_new_tokens": 1500,
            "base_depth": 5,
            "max_depth": 8,
            "high_conf_threshold": 0.9,
            "low_conf_threshold": 0.4,
            "min_branch": 2,
            "max_branch": 4
          },
          "throughput_tps": 183.0843598638963,
          "speedup": 1.3776872604599197,
          "ttft_ms": 16.548031195998192,
          "ttft_std": 6.2799988334345045,
          "tpot_ms": 5.720788499837121,
          "tpot_std": 1.4867875369038641,
          "total_time_ms": 0.0,
          "total_tokens_generated": 1500,
          "tokens_per_round": 6.122448979591836,
          "acceptance_rate": 0.8932080910209569,
          "avg_path_length": 6.252456637146698,
          "total_rounds": 245,
          "high_conf_ratio": 0.7589070930715448,
          "medium_conf_ratio": 0.1234284807200174,
          "low_conf_ratio": 0.1176644262084378,
          "early_stops": 1650,
          "deep_expansions": 194,
          "total_adjustments": 8,
          "peak_memory_mb": 6319.78466796875,
          "throughput_std": 34.548437905509424,
          "acceptance_std": 0.12609234397238483,
          "path_length_std": 0.8826464078066938
        }
      ]
    }
  },
  "timestamp": "2026-01-06T06:03:24.640361"
}