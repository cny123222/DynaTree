{
  "experiment_info": {
    "study": "adaptive_tree_speculative_decoding_paper",
    "target_model": "/mnt/disk1/models/pythia-2.8b",
    "draft_model": "/mnt/disk1/models/pythia-70m",
    "dataset": "WikiText-2 (ModelScope)",
    "num_samples": 10,
    "warmup_runs": 2,
    "max_prompt_length": 800
  },
  "all_results": [
    {
      "method": "Baseline (AR)",
      "experiment": "sensitivity",
      "config": {
        "max_new_tokens": 500
      },
      "throughput_tps": 99.20444140171597,
      "speedup": 1.0,
      "ttft_ms": 25.766596663743258,
      "ttft_std": 9.711769826618632,
      "tpot_ms": 10.56667939275503,
      "tpot_std": 2.38278660138039,
      "total_time_ms": 5309.106293041259,
      "total_tokens_generated": 500,
      "tokens_per_round": 1.0,
      "acceptance_rate": 0.0,
      "avg_path_length": 0.0,
      "total_rounds": 500,
      "high_conf_ratio": 0.0,
      "medium_conf_ratio": 0.0,
      "low_conf_ratio": 0.0,
      "early_stops": 0,
      "deep_expansions": 0,
      "total_adjustments": 0,
      "peak_memory_mb": 5798.40234375,
      "throughput_std": 22.33713875874986,
      "acceptance_std": 0.0,
      "path_length_std": 0.0
    },
    {
      "method": "Phase 3: + History Adjust",
      "experiment": "sensitivity_thresh_0.7_0.2",
      "config": {
        "phase": 3,
        "max_new_tokens": 500,
        "base_depth": 5,
        "max_depth": 8,
        "high_conf_threshold": 0.7,
        "low_conf_threshold": 0.2,
        "min_branch": 1,
        "max_branch": 4
      },
      "throughput_tps": 169.87114154151763,
      "speedup": 1.0,
      "ttft_ms": 12.900983542203903,
      "ttft_std": 2.3240110928733206,
      "tpot_ms": 5.990977140143514,
      "tpot_std": 0.8522295528957843,
      "total_time_ms": 0.0,
      "total_tokens_generated": 500,
      "tokens_per_round": 5.319148936170213,
      "acceptance_rate": 0.7836950771893101,
      "avg_path_length": 5.48586554032517,
      "total_rounds": 94,
      "high_conf_ratio": 0.7894455276070612,
      "medium_conf_ratio": 0.14186567187853125,
      "low_conf_ratio": 0.06868880051440754,
      "early_stops": 172,
      "deep_expansions": 61,
      "total_adjustments": 8,
      "peak_memory_mb": 5887.6884765625,
      "throughput_std": 26.39345574156608,
      "acceptance_std": 0.16374785849609608,
      "path_length_std": 1.1462350094726725
    },
    {
      "method": "Phase 3: + History Adjust",
      "experiment": "sensitivity_thresh_0.8_0.3",
      "config": {
        "phase": 3,
        "max_new_tokens": 500,
        "base_depth": 5,
        "max_depth": 8,
        "high_conf_threshold": 0.8,
        "low_conf_threshold": 0.3,
        "min_branch": 1,
        "max_branch": 4
      },
      "throughput_tps": 173.5313868513394,
      "speedup": 1.0,
      "ttft_ms": 12.72821081802249,
      "ttft_std": 2.252861228949756,
      "tpot_ms": 5.931405805796385,
      "tpot_std": 1.1176810882789097,
      "total_time_ms": 0.0,
      "total_tokens_generated": 500,
      "tokens_per_round": 5.154639175257732,
      "acceptance_rate": 0.7729047793302842,
      "avg_path_length": 5.4103334553119895,
      "total_rounds": 97,
      "high_conf_ratio": 0.7271503998008825,
      "medium_conf_ratio": 0.15949103180089313,
      "low_conf_ratio": 0.11335856839822434,
      "early_stops": 250,
      "deep_expansions": 53,
      "total_adjustments": 8,
      "peak_memory_mb": 5887.59716796875,
      "throughput_std": 31.471460132445138,
      "acceptance_std": 0.1781395903997791,
      "path_length_std": 1.246977132798454
    },
    {
      "method": "Phase 3: + History Adjust",
      "experiment": "sensitivity_thresh_0.9_0.4",
      "config": {
        "phase": 3,
        "max_new_tokens": 500,
        "base_depth": 5,
        "max_depth": 8,
        "high_conf_threshold": 0.9,
        "low_conf_threshold": 0.4,
        "min_branch": 1,
        "max_branch": 4
      },
      "throughput_tps": 180.48723041989507,
      "speedup": 1.0,
      "ttft_ms": 12.766583915799856,
      "ttft_std": 2.18427308663498,
      "tpot_ms": 5.665917551703751,
      "tpot_std": 0.9418583908895651,
      "total_time_ms": 0.0,
      "total_tokens_generated": 500,
      "tokens_per_round": 5.4945054945054945,
      "acceptance_rate": 0.8110353306986207,
      "avg_path_length": 5.677247314890345,
      "total_rounds": 91,
      "high_conf_ratio": 0.7515258019553028,
      "medium_conf_ratio": 0.11336234397493375,
      "low_conf_ratio": 0.13511185406976337,
      "early_stops": 253,
      "deep_expansions": 65,
      "total_adjustments": 8,
      "peak_memory_mb": 5891.28955078125,
      "throughput_std": 29.556719956588328,
      "acceptance_std": 0.1683398743163267,
      "path_length_std": 1.178379120214287
    },
    {
      "method": "Phase 3: + History Adjust",
      "experiment": "sensitivity_branch_1_2",
      "config": {
        "phase": 3,
        "max_new_tokens": 500,
        "base_depth": 5,
        "max_depth": 8,
        "high_conf_threshold": 0.8,
        "low_conf_threshold": 0.3,
        "min_branch": 1,
        "max_branch": 2
      },
      "throughput_tps": 178.33663767472433,
      "speedup": 1.0,
      "ttft_ms": 12.667510937899351,
      "ttft_std": 2.25856587729158,
      "tpot_ms": 5.729804272018373,
      "tpot_std": 0.9324478674965845,
      "total_time_ms": 0.0,
      "total_tokens_generated": 500,
      "tokens_per_round": 5.319148936170213,
      "acceptance_rate": 0.7857402683010246,
      "avg_path_length": 5.500181878107173,
      "total_rounds": 94,
      "high_conf_ratio": 0.7353219198619698,
      "medium_conf_ratio": 0.15513780660922355,
      "low_conf_ratio": 0.10954027352880666,
      "early_stops": 150,
      "deep_expansions": 60,
      "total_adjustments": 8,
      "peak_memory_mb": 5889.7744140625,
      "throughput_std": 29.167788235168306,
      "acceptance_std": 0.16723057821872878,
      "path_length_std": 1.1706140475311018
    },
    {
      "method": "Phase 3: + History Adjust",
      "experiment": "sensitivity_branch_1_3",
      "config": {
        "phase": 3,
        "max_new_tokens": 500,
        "base_depth": 5,
        "max_depth": 8,
        "high_conf_threshold": 0.8,
        "low_conf_threshold": 0.3,
        "min_branch": 1,
        "max_branch": 3
      },
      "throughput_tps": 178.98298261448457,
      "speedup": 1.0,
      "ttft_ms": 12.832061760127544,
      "ttft_std": 2.3143362929520843,
      "tpot_ms": 5.68632063344121,
      "tpot_std": 0.832276914027622,
      "total_time_ms": 0.0,
      "total_tokens_generated": 500,
      "tokens_per_round": 5.376344086021505,
      "acceptance_rate": 0.7965971941747274,
      "avg_path_length": 5.576180359223091,
      "total_rounds": 93,
      "high_conf_ratio": 0.7674397911727108,
      "medium_conf_ratio": 0.12758754587078938,
      "low_conf_ratio": 0.10497266295649985,
      "early_stops": 175,
      "deep_expansions": 64,
      "total_adjustments": 8,
      "peak_memory_mb": 5891.49072265625,
      "throughput_std": 27.33175513719771,
      "acceptance_std": 0.16525856788923732,
      "path_length_std": 1.1568099752246614
    },
    {
      "method": "Phase 3: + History Adjust",
      "experiment": "sensitivity_branch_1_4",
      "config": {
        "phase": 3,
        "max_new_tokens": 500,
        "base_depth": 5,
        "max_depth": 8,
        "high_conf_threshold": 0.8,
        "low_conf_threshold": 0.3,
        "min_branch": 1,
        "max_branch": 4
      },
      "throughput_tps": 174.8449849662548,
      "speedup": 1.0,
      "ttft_ms": 12.728088814765215,
      "ttft_std": 2.237510587008082,
      "tpot_ms": 5.8785393964499235,
      "tpot_std": 1.0749512767351874,
      "total_time_ms": 0.0,
      "total_tokens_generated": 500,
      "tokens_per_round": 5.154639175257732,
      "acceptance_rate": 0.7729047793302842,
      "avg_path_length": 5.4103334553119895,
      "total_rounds": 97,
      "high_conf_ratio": 0.7271503998008825,
      "medium_conf_ratio": 0.15949103180089313,
      "low_conf_ratio": 0.11335856839822434,
      "early_stops": 250,
      "deep_expansions": 53,
      "total_adjustments": 8,
      "peak_memory_mb": 5887.59716796875,
      "throughput_std": 31.2595411530793,
      "acceptance_std": 0.1781395903997791,
      "path_length_std": 1.246977132798454
    },
    {
      "method": "Phase 3: + History Adjust",
      "experiment": "sensitivity_branch_2_4",
      "config": {
        "phase": 3,
        "max_new_tokens": 500,
        "base_depth": 5,
        "max_depth": 8,
        "high_conf_threshold": 0.8,
        "low_conf_threshold": 0.3,
        "min_branch": 2,
        "max_branch": 4
      },
      "throughput_tps": 145.9111277495795,
      "speedup": 1.0,
      "ttft_ms": 14.86563142389059,
      "ttft_std": 4.2734903545695415,
      "tpot_ms": 7.2862808192148805,
      "tpot_std": 1.7418075963644817,
      "total_time_ms": 0.0,
      "total_tokens_generated": 500,
      "tokens_per_round": 5.208333333333333,
      "acceptance_rate": 0.7715537320803554,
      "avg_path_length": 5.400876124562489,
      "total_rounds": 96,
      "high_conf_ratio": 0.7266906390005856,
      "medium_conf_ratio": 0.16578227360102132,
      "low_conf_ratio": 0.10752708739839319,
      "early_stops": 590,
      "deep_expansions": 54,
      "total_adjustments": 8,
      "peak_memory_mb": 5894.130859375,
      "throughput_std": 40.05302661052739,
      "acceptance_std": 0.1661776392087245,
      "path_length_std": 1.1632434744610716
    }
  ],
  "paper_tables": {
    "parameter_sensitivity": {
      "title": "Parameter Sensitivity Results",
      "data": [
        {
          "method": "Baseline (AR)",
          "experiment": "sensitivity",
          "config": {
            "max_new_tokens": 500
          },
          "throughput_tps": 99.20444140171597,
          "speedup": 1.0,
          "ttft_ms": 25.766596663743258,
          "ttft_std": 9.711769826618632,
          "tpot_ms": 10.56667939275503,
          "tpot_std": 2.38278660138039,
          "total_time_ms": 5309.106293041259,
          "total_tokens_generated": 500,
          "tokens_per_round": 1.0,
          "acceptance_rate": 0.0,
          "avg_path_length": 0.0,
          "total_rounds": 500,
          "high_conf_ratio": 0.0,
          "medium_conf_ratio": 0.0,
          "low_conf_ratio": 0.0,
          "early_stops": 0,
          "deep_expansions": 0,
          "total_adjustments": 0,
          "peak_memory_mb": 5798.40234375,
          "throughput_std": 22.33713875874986,
          "acceptance_std": 0.0,
          "path_length_std": 0.0
        },
        {
          "method": "Phase 3: + History Adjust",
          "experiment": "sensitivity_thresh_0.7_0.2",
          "config": {
            "phase": 3,
            "max_new_tokens": 500,
            "base_depth": 5,
            "max_depth": 8,
            "high_conf_threshold": 0.7,
            "low_conf_threshold": 0.2,
            "min_branch": 1,
            "max_branch": 4
          },
          "throughput_tps": 169.87114154151763,
          "speedup": 1.0,
          "ttft_ms": 12.900983542203903,
          "ttft_std": 2.3240110928733206,
          "tpot_ms": 5.990977140143514,
          "tpot_std": 0.8522295528957843,
          "total_time_ms": 0.0,
          "total_tokens_generated": 500,
          "tokens_per_round": 5.319148936170213,
          "acceptance_rate": 0.7836950771893101,
          "avg_path_length": 5.48586554032517,
          "total_rounds": 94,
          "high_conf_ratio": 0.7894455276070612,
          "medium_conf_ratio": 0.14186567187853125,
          "low_conf_ratio": 0.06868880051440754,
          "early_stops": 172,
          "deep_expansions": 61,
          "total_adjustments": 8,
          "peak_memory_mb": 5887.6884765625,
          "throughput_std": 26.39345574156608,
          "acceptance_std": 0.16374785849609608,
          "path_length_std": 1.1462350094726725
        },
        {
          "method": "Phase 3: + History Adjust",
          "experiment": "sensitivity_thresh_0.8_0.3",
          "config": {
            "phase": 3,
            "max_new_tokens": 500,
            "base_depth": 5,
            "max_depth": 8,
            "high_conf_threshold": 0.8,
            "low_conf_threshold": 0.3,
            "min_branch": 1,
            "max_branch": 4
          },
          "throughput_tps": 173.5313868513394,
          "speedup": 1.0,
          "ttft_ms": 12.72821081802249,
          "ttft_std": 2.252861228949756,
          "tpot_ms": 5.931405805796385,
          "tpot_std": 1.1176810882789097,
          "total_time_ms": 0.0,
          "total_tokens_generated": 500,
          "tokens_per_round": 5.154639175257732,
          "acceptance_rate": 0.7729047793302842,
          "avg_path_length": 5.4103334553119895,
          "total_rounds": 97,
          "high_conf_ratio": 0.7271503998008825,
          "medium_conf_ratio": 0.15949103180089313,
          "low_conf_ratio": 0.11335856839822434,
          "early_stops": 250,
          "deep_expansions": 53,
          "total_adjustments": 8,
          "peak_memory_mb": 5887.59716796875,
          "throughput_std": 31.471460132445138,
          "acceptance_std": 0.1781395903997791,
          "path_length_std": 1.246977132798454
        },
        {
          "method": "Phase 3: + History Adjust",
          "experiment": "sensitivity_thresh_0.9_0.4",
          "config": {
            "phase": 3,
            "max_new_tokens": 500,
            "base_depth": 5,
            "max_depth": 8,
            "high_conf_threshold": 0.9,
            "low_conf_threshold": 0.4,
            "min_branch": 1,
            "max_branch": 4
          },
          "throughput_tps": 180.48723041989507,
          "speedup": 1.0,
          "ttft_ms": 12.766583915799856,
          "ttft_std": 2.18427308663498,
          "tpot_ms": 5.665917551703751,
          "tpot_std": 0.9418583908895651,
          "total_time_ms": 0.0,
          "total_tokens_generated": 500,
          "tokens_per_round": 5.4945054945054945,
          "acceptance_rate": 0.8110353306986207,
          "avg_path_length": 5.677247314890345,
          "total_rounds": 91,
          "high_conf_ratio": 0.7515258019553028,
          "medium_conf_ratio": 0.11336234397493375,
          "low_conf_ratio": 0.13511185406976337,
          "early_stops": 253,
          "deep_expansions": 65,
          "total_adjustments": 8,
          "peak_memory_mb": 5891.28955078125,
          "throughput_std": 29.556719956588328,
          "acceptance_std": 0.1683398743163267,
          "path_length_std": 1.178379120214287
        },
        {
          "method": "Phase 3: + History Adjust",
          "experiment": "sensitivity_branch_1_2",
          "config": {
            "phase": 3,
            "max_new_tokens": 500,
            "base_depth": 5,
            "max_depth": 8,
            "high_conf_threshold": 0.8,
            "low_conf_threshold": 0.3,
            "min_branch": 1,
            "max_branch": 2
          },
          "throughput_tps": 178.33663767472433,
          "speedup": 1.0,
          "ttft_ms": 12.667510937899351,
          "ttft_std": 2.25856587729158,
          "tpot_ms": 5.729804272018373,
          "tpot_std": 0.9324478674965845,
          "total_time_ms": 0.0,
          "total_tokens_generated": 500,
          "tokens_per_round": 5.319148936170213,
          "acceptance_rate": 0.7857402683010246,
          "avg_path_length": 5.500181878107173,
          "total_rounds": 94,
          "high_conf_ratio": 0.7353219198619698,
          "medium_conf_ratio": 0.15513780660922355,
          "low_conf_ratio": 0.10954027352880666,
          "early_stops": 150,
          "deep_expansions": 60,
          "total_adjustments": 8,
          "peak_memory_mb": 5889.7744140625,
          "throughput_std": 29.167788235168306,
          "acceptance_std": 0.16723057821872878,
          "path_length_std": 1.1706140475311018
        },
        {
          "method": "Phase 3: + History Adjust",
          "experiment": "sensitivity_branch_1_3",
          "config": {
            "phase": 3,
            "max_new_tokens": 500,
            "base_depth": 5,
            "max_depth": 8,
            "high_conf_threshold": 0.8,
            "low_conf_threshold": 0.3,
            "min_branch": 1,
            "max_branch": 3
          },
          "throughput_tps": 178.98298261448457,
          "speedup": 1.0,
          "ttft_ms": 12.832061760127544,
          "ttft_std": 2.3143362929520843,
          "tpot_ms": 5.68632063344121,
          "tpot_std": 0.832276914027622,
          "total_time_ms": 0.0,
          "total_tokens_generated": 500,
          "tokens_per_round": 5.376344086021505,
          "acceptance_rate": 0.7965971941747274,
          "avg_path_length": 5.576180359223091,
          "total_rounds": 93,
          "high_conf_ratio": 0.7674397911727108,
          "medium_conf_ratio": 0.12758754587078938,
          "low_conf_ratio": 0.10497266295649985,
          "early_stops": 175,
          "deep_expansions": 64,
          "total_adjustments": 8,
          "peak_memory_mb": 5891.49072265625,
          "throughput_std": 27.33175513719771,
          "acceptance_std": 0.16525856788923732,
          "path_length_std": 1.1568099752246614
        },
        {
          "method": "Phase 3: + History Adjust",
          "experiment": "sensitivity_branch_1_4",
          "config": {
            "phase": 3,
            "max_new_tokens": 500,
            "base_depth": 5,
            "max_depth": 8,
            "high_conf_threshold": 0.8,
            "low_conf_threshold": 0.3,
            "min_branch": 1,
            "max_branch": 4
          },
          "throughput_tps": 174.8449849662548,
          "speedup": 1.0,
          "ttft_ms": 12.728088814765215,
          "ttft_std": 2.237510587008082,
          "tpot_ms": 5.8785393964499235,
          "tpot_std": 1.0749512767351874,
          "total_time_ms": 0.0,
          "total_tokens_generated": 500,
          "tokens_per_round": 5.154639175257732,
          "acceptance_rate": 0.7729047793302842,
          "avg_path_length": 5.4103334553119895,
          "total_rounds": 97,
          "high_conf_ratio": 0.7271503998008825,
          "medium_conf_ratio": 0.15949103180089313,
          "low_conf_ratio": 0.11335856839822434,
          "early_stops": 250,
          "deep_expansions": 53,
          "total_adjustments": 8,
          "peak_memory_mb": 5887.59716796875,
          "throughput_std": 31.2595411530793,
          "acceptance_std": 0.1781395903997791,
          "path_length_std": 1.246977132798454
        },
        {
          "method": "Phase 3: + History Adjust",
          "experiment": "sensitivity_branch_2_4",
          "config": {
            "phase": 3,
            "max_new_tokens": 500,
            "base_depth": 5,
            "max_depth": 8,
            "high_conf_threshold": 0.8,
            "low_conf_threshold": 0.3,
            "min_branch": 2,
            "max_branch": 4
          },
          "throughput_tps": 145.9111277495795,
          "speedup": 1.0,
          "ttft_ms": 14.86563142389059,
          "ttft_std": 4.2734903545695415,
          "tpot_ms": 7.2862808192148805,
          "tpot_std": 1.7418075963644817,
          "total_time_ms": 0.0,
          "total_tokens_generated": 500,
          "tokens_per_round": 5.208333333333333,
          "acceptance_rate": 0.7715537320803554,
          "avg_path_length": 5.400876124562489,
          "total_rounds": 96,
          "high_conf_ratio": 0.7266906390005856,
          "medium_conf_ratio": 0.16578227360102132,
          "low_conf_ratio": 0.10752708739839319,
          "early_stops": 590,
          "deep_expansions": 54,
          "total_adjustments": 8,
          "peak_memory_mb": 5894.130859375,
          "throughput_std": 40.05302661052739,
          "acceptance_std": 0.1661776392087245,
          "path_length_std": 1.1632434744610716
        }
      ]
    }
  },
  "timestamp": "2026-01-04T16:25:20.111977"
}