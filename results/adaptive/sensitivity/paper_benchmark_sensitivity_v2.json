{
  "experiment_info": {
    "study": "adaptive_tree_speculative_decoding_paper",
    "target_model": "/mnt/disk1/models/pythia-2.8b",
    "draft_model": "/mnt/disk1/models/pythia-70m",
    "dataset": "WikiText-2 (ModelScope)",
    "num_samples": 10,
    "warmup_runs": 2,
    "max_prompt_length": 800
  },
  "all_results": [
    {
      "method": "Baseline (AR)",
      "experiment": "sensitivity",
      "config": {
        "max_new_tokens": 1000
      },
      "throughput_tps": 133.52864874314642,
      "speedup": 1.0,
      "ttft_ms": 19.011153746396303,
      "ttft_std": 5.824966914397783,
      "tpot_ms": 7.470177007466555,
      "tpot_std": 0.03179156619074569,
      "total_time_ms": 7489.188161212951,
      "total_tokens_generated": 1000,
      "tokens_per_round": 1.0,
      "acceptance_rate": 0.0,
      "avg_path_length": 0.0,
      "total_rounds": 1000,
      "high_conf_ratio": 0.0,
      "medium_conf_ratio": 0.0,
      "low_conf_ratio": 0.0,
      "early_stops": 0,
      "deep_expansions": 0,
      "total_adjustments": 0,
      "peak_memory_mb": 5962.412109375,
      "throughput_std": 0.6149384847482418,
      "acceptance_std": 0.0,
      "path_length_std": 0.0
    },
    {
      "method": "Linear Spec (K=5)",
      "experiment": "sensitivity",
      "config": {
        "max_new_tokens": 1000,
        "K": 5
      },
      "throughput_tps": 164.8051341814001,
      "speedup": 1.2342305245551959,
      "ttft_ms": 12.632781080901623,
      "ttft_std": 2.7364877844978195,
      "tpot_ms": 6.171088895946741,
      "tpot_std": 0.8472939521057116,
      "total_time_ms": 0.0,
      "total_tokens_generated": 1000,
      "tokens_per_round": 4.608294930875576,
      "acceptance_rate": 0.934910214598745,
      "avg_path_length": 4.674551072993726,
      "total_rounds": 217,
      "high_conf_ratio": 0.0,
      "medium_conf_ratio": 0.0,
      "low_conf_ratio": 0.0,
      "early_stops": 0,
      "deep_expansions": 0,
      "total_adjustments": 0,
      "peak_memory_mb": 6104.05712890625,
      "throughput_std": 22.834741757626475,
      "acceptance_std": 0.11646185553519339,
      "path_length_std": 0.582309277675967
    },
    {
      "method": "Fixed Tree (D=5, B=2)",
      "experiment": "sensitivity",
      "config": {
        "max_new_tokens": 1000,
        "tree_depth": 5,
        "branch_factor": 2,
        "max_tree_nodes": 256
      },
      "throughput_tps": 190.42833497842304,
      "speedup": 1.4261234332171513,
      "ttft_ms": 12.47499929741025,
      "ttft_std": 2.696848177920948,
      "tpot_ms": 5.266502071171999,
      "tpot_std": 0.3799897251654345,
      "total_time_ms": 0.0,
      "total_tokens_generated": 1000,
      "tokens_per_round": 5.649717514124294,
      "acceptance_rate": 0.8076971979588142,
      "avg_path_length": 5.6538803857117,
      "total_rounds": 177,
      "high_conf_ratio": 0.0,
      "medium_conf_ratio": 0.0,
      "low_conf_ratio": 0.0,
      "early_stops": 0,
      "deep_expansions": 0,
      "total_adjustments": 0,
      "peak_memory_mb": 6105.55615234375,
      "throughput_std": 13.941742704999697,
      "acceptance_std": 0.05889819747798692,
      "path_length_std": 0.41228738234590856
    },
    {
      "method": "Phase 3: + History Adjust",
      "experiment": "sensitivity_thresh_0.7_0.2",
      "config": {
        "phase": 3,
        "max_new_tokens": 1000,
        "base_depth": 5,
        "max_depth": 8,
        "high_conf_threshold": 0.7,
        "low_conf_threshold": 0.2,
        "min_branch": 1,
        "max_branch": 3
      },
      "throughput_tps": 207.1465921840282,
      "speedup": 1.5513269559290763,
      "ttft_ms": 12.481412291526794,
      "ttft_std": 2.6042959941464856,
      "tpot_ms": 5.005847646389157,
      "tpot_std": 1.1392998412497854,
      "total_time_ms": 0.0,
      "total_tokens_generated": 1000,
      "tokens_per_round": 5.9880239520958085,
      "acceptance_rate": 0.9130653034251065,
      "avg_path_length": 6.391457123975745,
      "total_rounds": 167,
      "high_conf_ratio": 0.8626952789221551,
      "medium_conf_ratio": 0.09012506352478543,
      "low_conf_ratio": 0.0471796575530594,
      "early_stops": 184,
      "deep_expansions": 151,
      "total_adjustments": 8,
      "peak_memory_mb": 6105.68994140625,
      "throughput_std": 35.731302904113626,
      "acceptance_std": 0.19567062396886786,
      "path_length_std": 1.369694367782075
    },
    {
      "method": "Phase 3: + History Adjust",
      "experiment": "sensitivity_thresh_0.8_0.3",
      "config": {
        "phase": 3,
        "max_new_tokens": 1000,
        "base_depth": 5,
        "max_depth": 8,
        "high_conf_threshold": 0.8,
        "low_conf_threshold": 0.3,
        "min_branch": 1,
        "max_branch": 3
      },
      "throughput_tps": 210.42253379222774,
      "speedup": 1.5758605795299643,
      "ttft_ms": 12.803591694682837,
      "ttft_std": 2.9559318340382816,
      "tpot_ms": 4.830208660196513,
      "tpot_std": 0.6771801528416672,
      "total_time_ms": 0.0,
      "total_tokens_generated": 1000,
      "tokens_per_round": 6.369426751592357,
      "acceptance_rate": 0.932631881711762,
      "avg_path_length": 6.528423171982334,
      "total_rounds": 157,
      "high_conf_ratio": 0.8438046775356298,
      "medium_conf_ratio": 0.091490148570313,
      "low_conf_ratio": 0.06470517389405725,
      "early_stops": 215,
      "deep_expansions": 151,
      "total_adjustments": 8,
      "peak_memory_mb": 6104.4072265625,
      "throughput_std": 28.485110302344278,
      "acceptance_std": 0.1519088133408028,
      "path_length_std": 1.0633616933856196
    },
    {
      "method": "Phase 3: + History Adjust",
      "experiment": "sensitivity_thresh_0.9_0.4",
      "config": {
        "phase": 3,
        "max_new_tokens": 1000,
        "base_depth": 5,
        "max_depth": 8,
        "high_conf_threshold": 0.9,
        "low_conf_threshold": 0.4,
        "min_branch": 1,
        "max_branch": 3
      },
      "throughput_tps": 205.39969014637933,
      "speedup": 1.5382443548985723,
      "ttft_ms": 12.468185275793076,
      "ttft_std": 2.63134506416459,
      "tpot_ms": 5.06803621109575,
      "tpot_std": 1.1833583651038606,
      "total_time_ms": 0.0,
      "total_tokens_generated": 1000,
      "tokens_per_round": 6.4935064935064934,
      "acceptance_rate": 0.9474552646622753,
      "avg_path_length": 6.632186852635928,
      "total_rounds": 154,
      "high_conf_ratio": 0.8155931278081224,
      "medium_conf_ratio": 0.09594135290417427,
      "low_conf_ratio": 0.08846551928770334,
      "early_stops": 251,
      "deep_expansions": 149,
      "total_adjustments": 8,
      "peak_memory_mb": 6106.4462890625,
      "throughput_std": 37.77347831211135,
      "acceptance_std": 0.14286998615733207,
      "path_length_std": 1.0000899031013246
    },
    {
      "method": "Phase 3: + History Adjust",
      "experiment": "sensitivity_branch_1_2",
      "config": {
        "phase": 3,
        "max_new_tokens": 1000,
        "base_depth": 5,
        "max_depth": 8,
        "high_conf_threshold": 0.9,
        "low_conf_threshold": 0.4,
        "min_branch": 1,
        "max_branch": 2
      },
      "throughput_tps": 215.34996203680353,
      "speedup": 1.6127622353989912,
      "ttft_ms": 12.460840307176113,
      "ttft_std": 2.6608652072368564,
      "tpot_ms": 4.865735387522728,
      "tpot_std": 1.3362393701635873,
      "total_time_ms": 0.0,
      "total_tokens_generated": 1000,
      "tokens_per_round": 5.9523809523809526,
      "acceptance_rate": 0.93763928996903,
      "avg_path_length": 6.56347502978321,
      "total_rounds": 168,
      "high_conf_ratio": 0.8059526349623332,
      "medium_conf_ratio": 0.08900505922770686,
      "low_conf_ratio": 0.10504230580996007,
      "early_stops": 204,
      "deep_expansions": 156,
      "total_adjustments": 8,
      "peak_memory_mb": 6106.46923828125,
      "throughput_std": 38.858469018404755,
      "acceptance_std": 0.2153578972745582,
      "path_length_std": 1.5075052809219074
    },
    {
      "method": "Phase 3: + History Adjust",
      "experiment": "sensitivity_branch_1_3",
      "config": {
        "phase": 3,
        "max_new_tokens": 1000,
        "base_depth": 5,
        "max_depth": 8,
        "high_conf_threshold": 0.9,
        "low_conf_threshold": 0.4,
        "min_branch": 1,
        "max_branch": 3
      },
      "throughput_tps": 198.5052352252927,
      "speedup": 1.4866115780676714,
      "ttft_ms": 13.35325064137578,
      "ttft_std": 3.8408619901760295,
      "tpot_ms": 5.271220196224749,
      "tpot_std": 1.2612507870628422,
      "total_time_ms": 0.0,
      "total_tokens_generated": 1000,
      "tokens_per_round": 6.4935064935064934,
      "acceptance_rate": 0.9474552646622753,
      "avg_path_length": 6.632186852635928,
      "total_rounds": 154,
      "high_conf_ratio": 0.8155931278081224,
      "medium_conf_ratio": 0.09594135290417427,
      "low_conf_ratio": 0.08846551928770334,
      "early_stops": 251,
      "deep_expansions": 149,
      "total_adjustments": 8,
      "peak_memory_mb": 6106.4462890625,
      "throughput_std": 40.06215737358877,
      "acceptance_std": 0.14286998615733207,
      "path_length_std": 1.0000899031013246
    },
    {
      "method": "Phase 3: + History Adjust",
      "experiment": "sensitivity_branch_1_4",
      "config": {
        "phase": 3,
        "max_new_tokens": 1000,
        "base_depth": 5,
        "max_depth": 8,
        "high_conf_threshold": 0.9,
        "low_conf_threshold": 0.4,
        "min_branch": 1,
        "max_branch": 4
      },
      "throughput_tps": 215.2720472927117,
      "speedup": 1.612178729575895,
      "ttft_ms": 12.419903092086315,
      "ttft_std": 2.611301053505455,
      "tpot_ms": 4.709402820374817,
      "tpot_std": 0.6059887966320073,
      "total_time_ms": 0.0,
      "total_tokens_generated": 1000,
      "tokens_per_round": 6.578947368421052,
      "acceptance_rate": 0.9562592650845941,
      "avg_path_length": 6.69381485559216,
      "total_rounds": 152,
      "high_conf_ratio": 0.8366585648130508,
      "medium_conf_ratio": 0.07934468144440773,
      "low_conf_ratio": 0.0839967537425415,
      "early_stops": 299,
      "deep_expansions": 155,
      "total_adjustments": 8,
      "peak_memory_mb": 6105.2509765625,
      "throughput_std": 27.398264545997392,
      "acceptance_std": 0.14085858330737672,
      "path_length_std": 0.986010083151637
    },
    {
      "method": "Phase 3: + History Adjust",
      "experiment": "sensitivity_branch_2_4",
      "config": {
        "phase": 3,
        "max_new_tokens": 1000,
        "base_depth": 5,
        "max_depth": 8,
        "high_conf_threshold": 0.9,
        "low_conf_threshold": 0.4,
        "min_branch": 2,
        "max_branch": 4
      },
      "throughput_tps": 195.31582386259677,
      "speedup": 1.4627259820347855,
      "ttft_ms": 12.419810611754656,
      "ttft_std": 2.7115721742684062,
      "tpot_ms": 5.156283737532794,
      "tpot_std": 0.5175797829506458,
      "total_time_ms": 0.0,
      "total_tokens_generated": 1000,
      "tokens_per_round": 5.9880239520958085,
      "acceptance_rate": 0.8657076022313321,
      "avg_path_length": 6.059953215619325,
      "total_rounds": 167,
      "high_conf_ratio": 0.7504084592797897,
      "medium_conf_ratio": 0.13545859787424247,
      "low_conf_ratio": 0.11413294284596784,
      "early_stops": 1156,
      "deep_expansions": 125,
      "total_adjustments": 8,
      "peak_memory_mb": 6111.68701171875,
      "throughput_std": 18.569668623673042,
      "acceptance_std": 0.10538759017121234,
      "path_length_std": 0.7377131311984862
    }
  ],
  "paper_tables": {
    "parameter_sensitivity": {
      "title": "Parameter Sensitivity Results",
      "data": [
        {
          "method": "Baseline (AR)",
          "experiment": "sensitivity",
          "config": {
            "max_new_tokens": 1000
          },
          "throughput_tps": 133.52864874314642,
          "speedup": 1.0,
          "ttft_ms": 19.011153746396303,
          "ttft_std": 5.824966914397783,
          "tpot_ms": 7.470177007466555,
          "tpot_std": 0.03179156619074569,
          "total_time_ms": 7489.188161212951,
          "total_tokens_generated": 1000,
          "tokens_per_round": 1.0,
          "acceptance_rate": 0.0,
          "avg_path_length": 0.0,
          "total_rounds": 1000,
          "high_conf_ratio": 0.0,
          "medium_conf_ratio": 0.0,
          "low_conf_ratio": 0.0,
          "early_stops": 0,
          "deep_expansions": 0,
          "total_adjustments": 0,
          "peak_memory_mb": 5962.412109375,
          "throughput_std": 0.6149384847482418,
          "acceptance_std": 0.0,
          "path_length_std": 0.0
        },
        {
          "method": "Linear Spec (K=5)",
          "experiment": "sensitivity",
          "config": {
            "max_new_tokens": 1000,
            "K": 5
          },
          "throughput_tps": 164.8051341814001,
          "speedup": 1.2342305245551959,
          "ttft_ms": 12.632781080901623,
          "ttft_std": 2.7364877844978195,
          "tpot_ms": 6.171088895946741,
          "tpot_std": 0.8472939521057116,
          "total_time_ms": 0.0,
          "total_tokens_generated": 1000,
          "tokens_per_round": 4.608294930875576,
          "acceptance_rate": 0.934910214598745,
          "avg_path_length": 4.674551072993726,
          "total_rounds": 217,
          "high_conf_ratio": 0.0,
          "medium_conf_ratio": 0.0,
          "low_conf_ratio": 0.0,
          "early_stops": 0,
          "deep_expansions": 0,
          "total_adjustments": 0,
          "peak_memory_mb": 6104.05712890625,
          "throughput_std": 22.834741757626475,
          "acceptance_std": 0.11646185553519339,
          "path_length_std": 0.582309277675967
        },
        {
          "method": "Fixed Tree (D=5, B=2)",
          "experiment": "sensitivity",
          "config": {
            "max_new_tokens": 1000,
            "tree_depth": 5,
            "branch_factor": 2,
            "max_tree_nodes": 256
          },
          "throughput_tps": 190.42833497842304,
          "speedup": 1.4261234332171513,
          "ttft_ms": 12.47499929741025,
          "ttft_std": 2.696848177920948,
          "tpot_ms": 5.266502071171999,
          "tpot_std": 0.3799897251654345,
          "total_time_ms": 0.0,
          "total_tokens_generated": 1000,
          "tokens_per_round": 5.649717514124294,
          "acceptance_rate": 0.8076971979588142,
          "avg_path_length": 5.6538803857117,
          "total_rounds": 177,
          "high_conf_ratio": 0.0,
          "medium_conf_ratio": 0.0,
          "low_conf_ratio": 0.0,
          "early_stops": 0,
          "deep_expansions": 0,
          "total_adjustments": 0,
          "peak_memory_mb": 6105.55615234375,
          "throughput_std": 13.941742704999697,
          "acceptance_std": 0.05889819747798692,
          "path_length_std": 0.41228738234590856
        },
        {
          "method": "Phase 3: + History Adjust",
          "experiment": "sensitivity_thresh_0.7_0.2",
          "config": {
            "phase": 3,
            "max_new_tokens": 1000,
            "base_depth": 5,
            "max_depth": 8,
            "high_conf_threshold": 0.7,
            "low_conf_threshold": 0.2,
            "min_branch": 1,
            "max_branch": 3
          },
          "throughput_tps": 207.1465921840282,
          "speedup": 1.5513269559290763,
          "ttft_ms": 12.481412291526794,
          "ttft_std": 2.6042959941464856,
          "tpot_ms": 5.005847646389157,
          "tpot_std": 1.1392998412497854,
          "total_time_ms": 0.0,
          "total_tokens_generated": 1000,
          "tokens_per_round": 5.9880239520958085,
          "acceptance_rate": 0.9130653034251065,
          "avg_path_length": 6.391457123975745,
          "total_rounds": 167,
          "high_conf_ratio": 0.8626952789221551,
          "medium_conf_ratio": 0.09012506352478543,
          "low_conf_ratio": 0.0471796575530594,
          "early_stops": 184,
          "deep_expansions": 151,
          "total_adjustments": 8,
          "peak_memory_mb": 6105.68994140625,
          "throughput_std": 35.731302904113626,
          "acceptance_std": 0.19567062396886786,
          "path_length_std": 1.369694367782075
        },
        {
          "method": "Phase 3: + History Adjust",
          "experiment": "sensitivity_thresh_0.8_0.3",
          "config": {
            "phase": 3,
            "max_new_tokens": 1000,
            "base_depth": 5,
            "max_depth": 8,
            "high_conf_threshold": 0.8,
            "low_conf_threshold": 0.3,
            "min_branch": 1,
            "max_branch": 3
          },
          "throughput_tps": 210.42253379222774,
          "speedup": 1.5758605795299643,
          "ttft_ms": 12.803591694682837,
          "ttft_std": 2.9559318340382816,
          "tpot_ms": 4.830208660196513,
          "tpot_std": 0.6771801528416672,
          "total_time_ms": 0.0,
          "total_tokens_generated": 1000,
          "tokens_per_round": 6.369426751592357,
          "acceptance_rate": 0.932631881711762,
          "avg_path_length": 6.528423171982334,
          "total_rounds": 157,
          "high_conf_ratio": 0.8438046775356298,
          "medium_conf_ratio": 0.091490148570313,
          "low_conf_ratio": 0.06470517389405725,
          "early_stops": 215,
          "deep_expansions": 151,
          "total_adjustments": 8,
          "peak_memory_mb": 6104.4072265625,
          "throughput_std": 28.485110302344278,
          "acceptance_std": 0.1519088133408028,
          "path_length_std": 1.0633616933856196
        },
        {
          "method": "Phase 3: + History Adjust",
          "experiment": "sensitivity_thresh_0.9_0.4",
          "config": {
            "phase": 3,
            "max_new_tokens": 1000,
            "base_depth": 5,
            "max_depth": 8,
            "high_conf_threshold": 0.9,
            "low_conf_threshold": 0.4,
            "min_branch": 1,
            "max_branch": 3
          },
          "throughput_tps": 205.39969014637933,
          "speedup": 1.5382443548985723,
          "ttft_ms": 12.468185275793076,
          "ttft_std": 2.63134506416459,
          "tpot_ms": 5.06803621109575,
          "tpot_std": 1.1833583651038606,
          "total_time_ms": 0.0,
          "total_tokens_generated": 1000,
          "tokens_per_round": 6.4935064935064934,
          "acceptance_rate": 0.9474552646622753,
          "avg_path_length": 6.632186852635928,
          "total_rounds": 154,
          "high_conf_ratio": 0.8155931278081224,
          "medium_conf_ratio": 0.09594135290417427,
          "low_conf_ratio": 0.08846551928770334,
          "early_stops": 251,
          "deep_expansions": 149,
          "total_adjustments": 8,
          "peak_memory_mb": 6106.4462890625,
          "throughput_std": 37.77347831211135,
          "acceptance_std": 0.14286998615733207,
          "path_length_std": 1.0000899031013246
        },
        {
          "method": "Phase 3: + History Adjust",
          "experiment": "sensitivity_branch_1_2",
          "config": {
            "phase": 3,
            "max_new_tokens": 1000,
            "base_depth": 5,
            "max_depth": 8,
            "high_conf_threshold": 0.9,
            "low_conf_threshold": 0.4,
            "min_branch": 1,
            "max_branch": 2
          },
          "throughput_tps": 215.34996203680353,
          "speedup": 1.6127622353989912,
          "ttft_ms": 12.460840307176113,
          "ttft_std": 2.6608652072368564,
          "tpot_ms": 4.865735387522728,
          "tpot_std": 1.3362393701635873,
          "total_time_ms": 0.0,
          "total_tokens_generated": 1000,
          "tokens_per_round": 5.9523809523809526,
          "acceptance_rate": 0.93763928996903,
          "avg_path_length": 6.56347502978321,
          "total_rounds": 168,
          "high_conf_ratio": 0.8059526349623332,
          "medium_conf_ratio": 0.08900505922770686,
          "low_conf_ratio": 0.10504230580996007,
          "early_stops": 204,
          "deep_expansions": 156,
          "total_adjustments": 8,
          "peak_memory_mb": 6106.46923828125,
          "throughput_std": 38.858469018404755,
          "acceptance_std": 0.2153578972745582,
          "path_length_std": 1.5075052809219074
        },
        {
          "method": "Phase 3: + History Adjust",
          "experiment": "sensitivity_branch_1_3",
          "config": {
            "phase": 3,
            "max_new_tokens": 1000,
            "base_depth": 5,
            "max_depth": 8,
            "high_conf_threshold": 0.9,
            "low_conf_threshold": 0.4,
            "min_branch": 1,
            "max_branch": 3
          },
          "throughput_tps": 198.5052352252927,
          "speedup": 1.4866115780676714,
          "ttft_ms": 13.35325064137578,
          "ttft_std": 3.8408619901760295,
          "tpot_ms": 5.271220196224749,
          "tpot_std": 1.2612507870628422,
          "total_time_ms": 0.0,
          "total_tokens_generated": 1000,
          "tokens_per_round": 6.4935064935064934,
          "acceptance_rate": 0.9474552646622753,
          "avg_path_length": 6.632186852635928,
          "total_rounds": 154,
          "high_conf_ratio": 0.8155931278081224,
          "medium_conf_ratio": 0.09594135290417427,
          "low_conf_ratio": 0.08846551928770334,
          "early_stops": 251,
          "deep_expansions": 149,
          "total_adjustments": 8,
          "peak_memory_mb": 6106.4462890625,
          "throughput_std": 40.06215737358877,
          "acceptance_std": 0.14286998615733207,
          "path_length_std": 1.0000899031013246
        },
        {
          "method": "Phase 3: + History Adjust",
          "experiment": "sensitivity_branch_1_4",
          "config": {
            "phase": 3,
            "max_new_tokens": 1000,
            "base_depth": 5,
            "max_depth": 8,
            "high_conf_threshold": 0.9,
            "low_conf_threshold": 0.4,
            "min_branch": 1,
            "max_branch": 4
          },
          "throughput_tps": 215.2720472927117,
          "speedup": 1.612178729575895,
          "ttft_ms": 12.419903092086315,
          "ttft_std": 2.611301053505455,
          "tpot_ms": 4.709402820374817,
          "tpot_std": 0.6059887966320073,
          "total_time_ms": 0.0,
          "total_tokens_generated": 1000,
          "tokens_per_round": 6.578947368421052,
          "acceptance_rate": 0.9562592650845941,
          "avg_path_length": 6.69381485559216,
          "total_rounds": 152,
          "high_conf_ratio": 0.8366585648130508,
          "medium_conf_ratio": 0.07934468144440773,
          "low_conf_ratio": 0.0839967537425415,
          "early_stops": 299,
          "deep_expansions": 155,
          "total_adjustments": 8,
          "peak_memory_mb": 6105.2509765625,
          "throughput_std": 27.398264545997392,
          "acceptance_std": 0.14085858330737672,
          "path_length_std": 0.986010083151637
        },
        {
          "method": "Phase 3: + History Adjust",
          "experiment": "sensitivity_branch_2_4",
          "config": {
            "phase": 3,
            "max_new_tokens": 1000,
            "base_depth": 5,
            "max_depth": 8,
            "high_conf_threshold": 0.9,
            "low_conf_threshold": 0.4,
            "min_branch": 2,
            "max_branch": 4
          },
          "throughput_tps": 195.31582386259677,
          "speedup": 1.4627259820347855,
          "ttft_ms": 12.419810611754656,
          "ttft_std": 2.7115721742684062,
          "tpot_ms": 5.156283737532794,
          "tpot_std": 0.5175797829506458,
          "total_time_ms": 0.0,
          "total_tokens_generated": 1000,
          "tokens_per_round": 5.9880239520958085,
          "acceptance_rate": 0.8657076022313321,
          "avg_path_length": 6.059953215619325,
          "total_rounds": 167,
          "high_conf_ratio": 0.7504084592797897,
          "medium_conf_ratio": 0.13545859787424247,
          "low_conf_ratio": 0.11413294284596784,
          "early_stops": 1156,
          "deep_expansions": 125,
          "total_adjustments": 8,
          "peak_memory_mb": 6111.68701171875,
          "throughput_std": 18.569668623673042,
          "acceptance_std": 0.10538759017121234,
          "path_length_std": 0.7377131311984862
        }
      ]
    }
  },
  "timestamp": "2026-01-05T16:08:59.811833"
}