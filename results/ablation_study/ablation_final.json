======================================================================
FINAL ABLATION STUDY: HEAD-AWARE ATTENTION MASK
======================================================================

======================================================================
GROUP: A_window_only
======================================================================

  Running: A_window_512...
Evaluating (head-aware mask):   0%|                                                                                                    | 0/999 [00:00<?, ?it/s][PerLayerMaskInjector] Registered 32 hooks

[Per-Layer Mask Config] Head type distribution per layer:
  Layer 0: uniform(w=512):32
  Layer 1: uniform(w=512):32
  Layer 2: uniform(w=512):32
  Layer 3: uniform(w=512):32
  Layer 4: uniform(w=512):32
  ... (showing first 5 of 32 layers)

PPL: 13.47, Acc: 47.85%: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 999/999 [01:27<00:00, 11.43it/s]
    PPL: 13.47, Acc: 47.85%, Eff.Ctx: 512.0

  Running: A_window_256...
Evaluating (head-aware mask):   0%|                                                                                                    | 0/999 [00:00<?, ?it/s][PerLayerMaskInjector] Registered 32 hooks

[Per-Layer Mask Config] Head type distribution per layer:
  Layer 0: uniform(w=256):32
  Layer 1: uniform(w=256):32
  Layer 2: uniform(w=256):32
  Layer 3: uniform(w=256):32
  Layer 4: uniform(w=256):32
  ... (showing first 5 of 32 layers)

PPL: 21.09, Acc: 43.14%: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 999/999 [01:43<00:00,  9.61it/s]
    PPL: 21.09, Acc: 43.14%, Eff.Ctx: 256.0

  Running: A_window_128...
Evaluating (head-aware mask):   0%|                                                                                                    | 0/999 [00:00<?, ?it/s][PerLayerMaskInjector] Registered 32 hooks

[Per-Layer Mask Config] Head type distribution per layer:
  Layer 0: uniform(w=128):32
  Layer 1: uniform(w=128):32
  Layer 2: uniform(w=128):32
  Layer 3: uniform(w=128):32
  Layer 4: uniform(w=128):32
  ... (showing first 5 of 32 layers)

PPL: 26.28, Acc: 40.94%: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 999/999 [02:13<00:00,  7.46it/s]
    PPL: 26.28, Acc: 40.94%, Eff.Ctx: 128.0

  Running: A_window_64...
Evaluating (head-aware mask):   0%|                                                                                                    | 0/999 [00:00<?, ?it/s][PerLayerMaskInjector] Registered 32 hooks

[Per-Layer Mask Config] Head type distribution per layer:
  Layer 0: uniform(w=64):32
  Layer 1: uniform(w=64):32
  Layer 2: uniform(w=64):32
  Layer 3: uniform(w=64):32
  Layer 4: uniform(w=64):32
  ... (showing first 5 of 32 layers)

PPL: 38.72, Acc: 36.04%: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 999/999 [01:49<00:00,  9.15it/s]
    PPL: 38.72, Acc: 36.04%, Eff.Ctx: 64.0

======================================================================
GROUP: B_streaming
======================================================================

  Running: B_streaming_512...
Evaluating (head-aware mask):   0%|                                                                                                    | 0/999 [00:00<?, ?it/s][PerLayerMaskInjector] Registered 32 hooks

[Per-Layer Mask Config] Head type distribution per layer:
  Layer 0: uniform(w=508):32
  Layer 1: uniform(w=508):32
  Layer 2: uniform(w=508):32
  Layer 3: uniform(w=508):32
  Layer 4: uniform(w=508):32
  ... (showing first 5 of 32 layers)

PPL: 8.81, Acc: 52.45%: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 999/999 [01:26<00:00, 11.49it/s]
    PPL: 8.81, Acc: 52.45%, Eff.Ctx: 512.0

  Running: B_streaming_256...
Evaluating (head-aware mask):   0%|                                                                                                    | 0/999 [00:00<?, ?it/s][PerLayerMaskInjector] Registered 32 hooks

[Per-Layer Mask Config] Head type distribution per layer:
  Layer 0: uniform(w=252):32
  Layer 1: uniform(w=252):32
  Layer 2: uniform(w=252):32
  Layer 3: uniform(w=252):32
  Layer 4: uniform(w=252):32
  ... (showing first 5 of 32 layers)

PPL: 9.14, Acc: 51.95%: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 999/999 [01:26<00:00, 11.49it/s]
    PPL: 9.14, Acc: 51.95%, Eff.Ctx: 256.0

  Running: B_streaming_128...
Evaluating (head-aware mask):   0%|                                                                                                    | 0/999 [00:00<?, ?it/s][PerLayerMaskInjector] Registered 32 hooks

[Per-Layer Mask Config] Head type distribution per layer:
  Layer 0: uniform(w=124):32
  Layer 1: uniform(w=124):32
  Layer 2: uniform(w=124):32
  Layer 3: uniform(w=124):32
  Layer 4: uniform(w=124):32
  ... (showing first 5 of 32 layers)

PPL: 9.52, Acc: 52.05%: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 999/999 [01:26<00:00, 11.57it/s]
    PPL: 9.52, Acc: 52.05%, Eff.Ctx: 128.0

  Running: B_streaming_64...
Evaluating (head-aware mask):   0%|                                                                                                    | 0/999 [00:00<?, ?it/s][PerLayerMaskInjector] Registered 32 hooks

[Per-Layer Mask Config] Head type distribution per layer:
  Layer 0: uniform(w=60):32
  Layer 1: uniform(w=60):32
  Layer 2: uniform(w=60):32
  Layer 3: uniform(w=60):32
  Layer 4: uniform(w=60):32
  ... (showing first 5 of 32 layers)

PPL: 10.57, Acc: 51.05%: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 999/999 [02:07<00:00,  7.85it/s]
    PPL: 10.57, Acc: 51.05%, Eff.Ctx: 64.0

======================================================================
GROUP: G_confidence_sweep
======================================================================

  Running: G_conf0.3_base128...
Evaluating (head-aware mask):   0%|                                                                                                    | 0/999 [00:00<?, ?it/s][PerLayerMaskInjector] Registered 32 hooks

[Per-Layer Mask Config] Head type distribution per layer:
  Layer 0: gathering(w=128):15, gathering(w=256):14, mixed(w=64):3
  Layer 1: gathering(w=128):5, gathering(w=256):8, mixed(w=64):16, positional(w=128):1, positional(w=16):2
  Layer 2: gathering(w=128):12, gathering(w=256):12, mixed(w=64):8
  Layer 3: gathering(w=128):2, mixed(w=64):17, positional(w=128):1, positional(w=16):12
  Layer 4: gathering(w=128):3, gathering(w=256):1, mixed(w=64):25, positional(w=16):3
  ... (showing first 5 of 32 layers)

PPL: 11.21, Acc: 50.65%: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 999/999 [02:38<00:00,  6.30it/s]
    PPL: 11.21, Acc: 50.65%, Eff.Ctx: 61.6

  Running: G_conf0.4_base128...
Evaluating (head-aware mask):   0%|                                                                                                    | 0/999 [00:00<?, ?it/s][PerLayerMaskInjector] Registered 32 hooks

[Per-Layer Mask Config] Head type distribution per layer:
  Layer 0: gathering(w=128):25, gathering(w=256):4, mixed(w=64):3
  Layer 1: gathering(w=128):10, gathering(w=256):3, mixed(w=64):16, positional(w=128):1, positional(w=16):2
  Layer 2: gathering(w=128):16, gathering(w=256):8, mixed(w=64):8
  Layer 3: gathering(w=128):2, mixed(w=64):17, positional(w=128):3, positional(w=16):10
  Layer 4: gathering(w=128):3, gathering(w=256):1, mixed(w=64):25, positional(w=128):1, positional(w=16):2
  ... (showing first 5 of 32 layers)

PPL: 11.01, Acc: 50.35%: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 999/999 [02:14<00:00,  7.44it/s]
    PPL: 11.01, Acc: 50.35%, Eff.Ctx: 61.8

  Running: G_conf0.5_base128...
Evaluating (head-aware mask):   0%|                                                                                                    | 0/999 [00:00<?, ?it/s][PerLayerMaskInjector] Registered 32 hooks

[Per-Layer Mask Config] Head type distribution per layer:
  Layer 0: gathering(w=128):29, mixed(w=64):3
  Layer 1: gathering(w=128):13, mixed(w=64):16, positional(w=128):1, positional(w=16):2
  Layer 2: gathering(w=128):23, gathering(w=256):1, mixed(w=64):8
  Layer 3: gathering(w=128):2, mixed(w=64):17, positional(w=128):12, positional(w=16):1
  Layer 4: gathering(w=128):3, gathering(w=256):1, mixed(w=64):25, positional(w=128):2, positional(w=16):1
  ... (showing first 5 of 32 layers)

PPL: 10.94, Acc: 50.45%: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 999/999 [01:49<00:00,  9.12it/s]
    PPL: 10.94, Acc: 50.45%, Eff.Ctx: 73.6

  Running: G_conf0.55_base128...
Evaluating (head-aware mask):   0%|                                                                                                    | 0/999 [00:00<?, ?it/s][PerLayerMaskInjector] Registered 32 hooks

[Per-Layer Mask Config] Head type distribution per layer:
  Layer 0: gathering(w=128):29, mixed(w=128):3
  Layer 1: gathering(w=128):13, mixed(w=128):16, positional(w=128):1, positional(w=16):2
  Layer 2: gathering(w=128):24, mixed(w=128):8
  Layer 3: gathering(w=128):2, mixed(w=128):17, positional(w=128):13
  Layer 4: gathering(w=128):3, gathering(w=256):1, mixed(w=128):25, positional(w=128):2, positional(w=16):1
  ... (showing first 5 of 32 layers)

PPL: 9.76, Acc: 52.25%: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 999/999 [01:26<00:00, 11.57it/s]
    PPL: 9.76, Acc: 52.25%, Eff.Ctx: 120.6

  Running: G_conf0.6_base128...
Evaluating (head-aware mask):   0%|                                                                                                    | 0/999 [00:00<?, ?it/s][PerLayerMaskInjector] Registered 32 hooks

[Per-Layer Mask Config] Head type distribution per layer:
  Layer 0: gathering(w=128):29, mixed(w=128):3
  Layer 1: gathering(w=128):13, mixed(w=128):16, positional(w=128):1, positional(w=16):2
  Layer 2: gathering(w=128):24, mixed(w=128):8
  Layer 3: gathering(w=128):2, mixed(w=128):17, positional(w=128):13
  Layer 4: gathering(w=128):4, mixed(w=128):25, positional(w=128):2, positional(w=16):1
  ... (showing first 5 of 32 layers)

PPL: 9.57, Acc: 51.85%: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 999/999 [01:26<00:00, 11.57it/s]
    PPL: 9.57, Acc: 51.85%, Eff.Ctx: 128.3

  Running: G_conf0.65_base128...
Evaluating (head-aware mask):   0%|                                                                                                    | 0/999 [00:00<?, ?it/s][PerLayerMaskInjector] Registered 32 hooks

[Per-Layer Mask Config] Head type distribution per layer:
  Layer 0: gathering(w=128):29, mixed(w=128):3
  Layer 1: gathering(w=128):13, mixed(w=128):16, positional(w=128):1, positional(w=16):2
  Layer 2: gathering(w=128):24, mixed(w=128):8
  Layer 3: gathering(w=128):2, mixed(w=128):17, positional(w=128):13
  Layer 4: gathering(w=128):4, mixed(w=128):25, positional(w=128):2, positional(w=16):1
  ... (showing first 5 of 32 layers)

PPL: 9.63, Acc: 51.35%: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 999/999 [01:26<00:00, 11.55it/s]
    PPL: 9.63, Acc: 51.35%, Eff.Ctx: 129.9

  Running: G_conf0.7_base128...
Evaluating (head-aware mask):   0%|                                                                                                    | 0/999 [00:00<?, ?it/s][PerLayerMaskInjector] Registered 32 hooks

[Per-Layer Mask Config] Head type distribution per layer:
  Layer 0: gathering(w=128):29, mixed(w=128):3
  Layer 1: gathering(w=128):13, mixed(w=128):16, positional(w=128):1, positional(w=16):2
  Layer 2: gathering(w=128):24, mixed(w=128):8
  Layer 3: gathering(w=128):2, mixed(w=128):17, positional(w=128):13
  Layer 4: gathering(w=128):4, mixed(w=128):25, positional(w=128):2, positional(w=16):1
  ... (showing first 5 of 32 layers)

PPL: 9.63, Acc: 51.35%: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 999/999 [01:26<00:00, 11.56it/s]
    PPL: 9.63, Acc: 51.35%, Eff.Ctx: 130.5

  Running: G_conf0.8_base128...
Evaluating (head-aware mask):   0%|                                                                                                    | 0/999 [00:00<?, ?it/s][PerLayerMaskInjector] Registered 32 hooks

[Per-Layer Mask Config] Head type distribution per layer:
  Layer 0: gathering(w=128):29, mixed(w=128):3
  Layer 1: gathering(w=128):13, mixed(w=128):16, positional(w=128):2, positional(w=16):1
  Layer 2: gathering(w=128):24, mixed(w=128):8
  Layer 3: gathering(w=128):2, mixed(w=128):17, positional(w=128):13
  Layer 4: gathering(w=128):4, mixed(w=128):25, positional(w=128):3
  ... (showing first 5 of 32 layers)

PPL: 9.54, Acc: 51.35%: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 999/999 [01:26<00:00, 11.56it/s]
    PPL: 9.54, Acc: 51.35%, Eff.Ctx: 131.9

  Running: G_conf0.5_base64...
Evaluating (head-aware mask):   0%|                                                                                                    | 0/999 [00:00<?, ?it/s][PerLayerMaskInjector] Registered 32 hooks

[Per-Layer Mask Config] Head type distribution per layer:
  Layer 0: gathering(w=64):29, mixed(w=64):3
  Layer 1: gathering(w=64):13, mixed(w=64):16, positional(w=64):1, positional(w=8):2
  Layer 2: gathering(w=128):1, gathering(w=64):23, mixed(w=64):8
  Layer 3: gathering(w=64):2, mixed(w=64):17, positional(w=64):12, positional(w=8):1
  Layer 4: gathering(w=128):1, gathering(w=64):3, mixed(w=64):25, positional(w=64):2, positional(w=8):1
  ... (showing first 5 of 32 layers)

PPL: 11.27, Acc: 50.25%: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 999/999 [01:26<00:00, 11.55it/s]
    PPL: 11.27, Acc: 50.25%, Eff.Ctx: 56.5

  Running: G_conf0.6_base64...
Evaluating (head-aware mask):   0%|                                                                                                    | 0/999 [00:00<?, ?it/s][PerLayerMaskInjector] Registered 32 hooks

[Per-Layer Mask Config] Head type distribution per layer:
  Layer 0: gathering(w=64):29, mixed(w=64):3
  Layer 1: gathering(w=64):13, mixed(w=64):16, positional(w=64):1, positional(w=8):2
  Layer 2: gathering(w=64):24, mixed(w=64):8
  Layer 3: gathering(w=64):2, mixed(w=64):17, positional(w=64):13
  Layer 4: gathering(w=64):4, mixed(w=64):25, positional(w=64):2, positional(w=8):1
  ... (showing first 5 of 32 layers)

PPL: 10.47, Acc: 50.65%: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 999/999 [01:26<00:00, 11.52it/s]
    PPL: 10.47, Acc: 50.65%, Eff.Ctx: 66.1

  Running: G_conf0.7_base64...
Evaluating (head-aware mask):   0%|                                                                                                    | 0/999 [00:00<?, ?it/s][PerLayerMaskInjector] Registered 32 hooks

[Per-Layer Mask Config] Head type distribution per layer:
  Layer 0: gathering(w=64):29, mixed(w=64):3
  Layer 1: gathering(w=64):13, mixed(w=64):16, positional(w=64):1, positional(w=8):2
  Layer 2: gathering(w=64):24, mixed(w=64):8
  Layer 3: gathering(w=64):2, mixed(w=64):17, positional(w=64):13
  Layer 4: gathering(w=64):4, mixed(w=64):25, positional(w=64):2, positional(w=8):1
  ... (showing first 5 of 32 layers)

PPL: 10.42, Acc: 51.05%: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 999/999 [01:26<00:00, 11.57it/s]
    PPL: 10.42, Acc: 51.05%, Eff.Ctx: 67.2

======================================================================
GROUP: I_inverse_positional
======================================================================

  Running: I_pos128_mix64_g128...
Evaluating (head-aware mask):   0%|                                                                                                    | 0/999 [00:00<?, ?it/s][PerLayerMaskInjector] Registered 32 hooks

[Per-Layer Mask Config] Head type distribution per layer:
  Layer 0: gathering(w=128):29, mixed(w=64):3
  Layer 1: gathering(w=128):13, mixed(w=64):16, positional(w=128):3
  Layer 2: gathering(w=128):24, mixed(w=64):8
  Layer 3: gathering(w=128):2, mixed(w=64):17, positional(w=128):13
  Layer 4: gathering(w=128):4, mixed(w=64):25, positional(w=128):3
  ... (showing first 5 of 32 layers)

PPL: 10.06, Acc: 51.25%: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 999/999 [01:26<00:00, 11.58it/s]
    PPL: 10.06, Acc: 51.25%, Eff.Ctx: 96.6

  Running: I_pos256_mix64_g128...
Evaluating (head-aware mask):   0%|                                                                                                    | 0/999 [00:00<?, ?it/s][PerLayerMaskInjector] Registered 32 hooks

[Per-Layer Mask Config] Head type distribution per layer:
  Layer 0: gathering(w=128):29, mixed(w=64):3
  Layer 1: gathering(w=128):13, mixed(w=64):16, positional(w=256):3
  Layer 2: gathering(w=128):24, mixed(w=64):8
  Layer 3: gathering(w=128):2, mixed(w=64):17, positional(w=256):13
  Layer 4: gathering(w=128):4, mixed(w=64):25, positional(w=256):3
  ... (showing first 5 of 32 layers)

PPL: 9.73, Acc: 52.45%: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 999/999 [01:26<00:00, 11.56it/s]
    PPL: 9.73, Acc: 52.45%, Eff.Ctx: 142.9

  Running: I_pos512_mix64_g128...
Evaluating (head-aware mask):   0%|                                                                                                    | 0/999 [00:00<?, ?it/s][PerLayerMaskInjector] Registered 32 hooks

[Per-Layer Mask Config] Head type distribution per layer:
  Layer 0: gathering(w=128):29, mixed(w=64):3
  Layer 1: gathering(w=128):13, mixed(w=64):16, positional(w=512):3
  Layer 2: gathering(w=128):24, mixed(w=64):8
  Layer 3: gathering(w=128):2, mixed(w=64):17, positional(w=512):13
  Layer 4: gathering(w=128):4, mixed(w=64):25, positional(w=512):3
  ... (showing first 5 of 32 layers)

PPL: 9.62, Acc: 52.15%: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 999/999 [01:43<00:00,  9.67it/s]
    PPL: 9.62, Acc: 52.15%, Eff.Ctx: 235.4

  Running: I_pos256_mix128_g128...
Evaluating (head-aware mask):   0%|                                                                                                    | 0/999 [00:00<?, ?it/s][PerLayerMaskInjector] Registered 32 hooks

[Per-Layer Mask Config] Head type distribution per layer:
  Layer 0: gathering(w=128):29, mixed(w=128):3
  Layer 1: gathering(w=128):13, mixed(w=128):16, positional(w=256):3
  Layer 2: gathering(w=128):24, mixed(w=128):8
  Layer 3: gathering(w=128):2, mixed(w=128):17, positional(w=256):13
  Layer 4: gathering(w=128):4, mixed(w=128):25, positional(w=256):3
  ... (showing first 5 of 32 layers)

PPL: 9.34, Acc: 52.55%: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 999/999 [01:26<00:00, 11.56it/s]
    PPL: 9.34, Acc: 52.55%, Eff.Ctx: 178.2

======================================================================
GROUP: J_small_gathering
======================================================================

  Running: J_pos16_mix64_g64...
Evaluating (head-aware mask):   0%|                                                                                                    | 0/999 [00:00<?, ?it/s][PerLayerMaskInjector] Registered 32 hooks

[Per-Layer Mask Config] Head type distribution per layer:
  Layer 0: gathering(w=64):29, mixed(w=64):3
  Layer 1: gathering(w=64):13, mixed(w=64):16, positional(w=16):3
  Layer 2: gathering(w=64):24, mixed(w=64):8
  Layer 3: gathering(w=64):2, mixed(w=64):17, positional(w=16):13
  Layer 4: gathering(w=64):4, mixed(w=64):25, positional(w=16):3
  ... (showing first 5 of 32 layers)

PPL: 11.44, Acc: 50.35%: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 999/999 [01:26<00:00, 11.54it/s]
    PPL: 11.44, Acc: 50.35%, Eff.Ctx: 50.7

  Running: J_pos16_mix64_g128...
Evaluating (head-aware mask):   0%|                                                                                                    | 0/999 [00:00<?, ?it/s][PerLayerMaskInjector] Registered 32 hooks

[Per-Layer Mask Config] Head type distribution per layer:
  Layer 0: gathering(w=128):29, mixed(w=64):3
  Layer 1: gathering(w=128):13, mixed(w=64):16, positional(w=16):3
  Layer 2: gathering(w=128):24, mixed(w=64):8
  Layer 3: gathering(w=128):2, mixed(w=64):17, positional(w=16):13
  Layer 4: gathering(w=128):4, mixed(w=64):25, positional(w=16):3
  ... (showing first 5 of 32 layers)

PPL: 11.27, Acc: 50.75%: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 999/999 [01:26<00:00, 11.55it/s]
    PPL: 11.27, Acc: 50.75%, Eff.Ctx: 56.2

  Running: J_pos16_mix64_g256...
Evaluating (head-aware mask):   0%|                                                                                                    | 0/999 [00:00<?, ?it/s][PerLayerMaskInjector] Registered 32 hooks

[Per-Layer Mask Config] Head type distribution per layer:
  Layer 0: gathering(w=256):29, mixed(w=64):3
  Layer 1: gathering(w=256):13, mixed(w=64):16, positional(w=16):3
  Layer 2: gathering(w=256):24, mixed(w=64):8
  Layer 3: gathering(w=256):2, mixed(w=64):17, positional(w=16):13
  Layer 4: gathering(w=256):4, mixed(w=64):25, positional(w=16):3
  ... (showing first 5 of 32 layers)

PPL: 11.34, Acc: 50.45%: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 999/999 [01:26<00:00, 11.55it/s]
    PPL: 11.34, Acc: 50.45%, Eff.Ctx: 67.2

  Running: J_pos64_mix64_g128...
Evaluating (head-aware mask):   0%|                                                                                                    | 0/999 [00:00<?, ?it/s][PerLayerMaskInjector] Registered 32 hooks

[Per-Layer Mask Config] Head type distribution per layer:
  Layer 0: gathering(w=128):29, mixed(w=64):3
  Layer 1: gathering(w=128):13, mixed(w=64):16, positional(w=64):3
  Layer 2: gathering(w=128):24, mixed(w=64):8
  Layer 3: gathering(w=128):2, mixed(w=64):17, positional(w=64):13
  Layer 4: gathering(w=128):4, mixed(w=64):25, positional(w=64):3
  ... (showing first 5 of 32 layers)

PPL: 10.43, Acc: 51.45%: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 999/999 [01:26<00:00, 11.55it/s]
    PPL: 10.43, Acc: 51.45%, Eff.Ctx: 73.5

======================================================================
GROUP: K_uniform_aware
======================================================================

  Running: K_uniform64_aware...
Evaluating (head-aware mask):   0%|                                                                                                    | 0/999 [00:00<?, ?it/s][PerLayerMaskInjector] Registered 32 hooks

[Per-Layer Mask Config] Head type distribution per layer:
  Layer 0: gathering(w=64):29, mixed(w=64):3
  Layer 1: gathering(w=64):13, mixed(w=64):16, positional(w=64):3
  Layer 2: gathering(w=64):24, mixed(w=64):8
  Layer 3: gathering(w=64):2, mixed(w=64):17, positional(w=64):13
  Layer 4: gathering(w=64):4, mixed(w=64):25, positional(w=64):3
  ... (showing first 5 of 32 layers)

PPL: 10.42, Acc: 50.75%: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 999/999 [01:26<00:00, 11.58it/s]
    PPL: 10.42, Acc: 50.75%, Eff.Ctx: 68.0

  Running: K_uniform128_aware...
Evaluating (head-aware mask):   0%|                                                                                                    | 0/999 [00:00<?, ?it/s][PerLayerMaskInjector] Registered 32 hooks

[Per-Layer Mask Config] Head type distribution per layer:
  Layer 0: gathering(w=128):29, mixed(w=128):3
  Layer 1: gathering(w=128):13, mixed(w=128):16, positional(w=128):3
  Layer 2: gathering(w=128):24, mixed(w=128):8
  Layer 3: gathering(w=128):2, mixed(w=128):17, positional(w=128):13
  Layer 4: gathering(w=128):4, mixed(w=128):25, positional(w=128):3
  ... (showing first 5 of 32 layers)

PPL: 9.60, Acc: 52.45%: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 999/999 [01:26<00:00, 11.56it/s]
    PPL: 9.60, Acc: 52.45%, Eff.Ctx: 132.0

======================================================================
ABLATION RESULTS SUMMARY
======================================================================

--- A_window_only ---
Name                           PPL      Acc    Eff.Ctx
-------------------------------------------------------
A_window_64                  38.72  36.04%       64.0
A_window_128                 26.28  40.94%      128.0
A_window_256                 21.09  43.14%      256.0
A_window_512                 13.47  47.85%      512.0

--- B_streaming ---
Name                           PPL      Acc    Eff.Ctx
-------------------------------------------------------
B_streaming_64               10.57  51.05%       64.0  * 
B_streaming_128               9.52  52.05%      128.0  * 
B_streaming_256               9.14  51.95%      256.0
B_streaming_512               8.81  52.45%      512.0

--- G_confidence_sweep ---
Name                           PPL      Acc    Eff.Ctx
-------------------------------------------------------
G_conf0.5_base64             11.27  50.25%       56.5
G_conf0.3_base128            11.21  50.65%       61.6
G_conf0.4_base128            11.01  50.35%       61.8
G_conf0.6_base64             10.47  50.65%       66.1
G_conf0.7_base64             10.42  51.05%       67.2
G_conf0.5_base128            10.94  50.45%       73.6
G_conf0.55_base128            9.76  52.25%      120.6  * 
G_conf0.6_base128             9.57  51.85%      128.3
G_conf0.65_base128            9.63  51.35%      129.9
G_conf0.7_base128             9.63  51.35%      130.5
G_conf0.8_base128             9.54  51.35%      131.9

--- I_inverse_positional ---
Name                           PPL      Acc    Eff.Ctx
-------------------------------------------------------
I_pos128_mix64_g128          10.06  51.25%       96.6
I_pos256_mix64_g128           9.73  52.45%      142.9
I_pos256_mix128_g128          9.34  52.55%      178.2
I_pos512_mix64_g128           9.62  52.15%      235.4

--- J_small_gathering ---
Name                           PPL      Acc    Eff.Ctx
-------------------------------------------------------
J_pos16_mix64_g64            11.44  50.35%       50.7
J_pos16_mix64_g128           11.27  50.75%       56.2
J_pos16_mix64_g256           11.34  50.45%       67.2
J_pos64_mix64_g128           10.43  51.45%       73.5

--- K_uniform_aware ---
Name                           PPL      Acc    Eff.Ctx
-------------------------------------------------------
K_uniform64_aware            10.42  50.75%       68.0
K_uniform128_aware            9.60  52.45%      132.0

======================================================================
KEY COMPARISONS
======================================================================

Baseline (B_streaming_128): PPL=9.52, Ctx=128

Confidence-based vs StreamingLLM_128:
  G_conf0.8_base128: PPL=9.54, Ctx=132 (+0.2% worse)
  G_conf0.6_base128: PPL=9.57, Ctx=128 (+0.6% worse)
  G_conf0.65_base128: PPL=9.63, Ctx=130 (+1.2% worse)
  G_conf0.7_base128: PPL=9.63, Ctx=130 (+1.2% worse)
  G_conf0.55_base128: PPL=9.76, Ctx=121 (+2.6% worse)
  G_conf0.7_base64: PPL=10.42, Ctx=67 (+9.5% worse)
  G_conf0.6_base64: PPL=10.47, Ctx=66 (+10.1% worse)
  G_conf0.5_base128: PPL=10.94, Ctx=74 (+15.0% worse)
  G_conf0.4_base128: PPL=11.01, Ctx=62 (+15.7% worse)
  G_conf0.3_base128: PPL=11.21, Ctx=62 (+17.8% worse)
  G_conf0.5_base64: PPL=11.27, Ctx=56 (+18.4% worse)

Inverse (large positional) vs StreamingLLM:
  I_pos256_mix128_g128: PPL=9.34, Ctx=178
    vs B_streaming_128: -1.8%
  I_pos512_mix64_g128: PPL=9.62, Ctx=235
    vs B_streaming_256: +5.2%
  I_pos256_mix64_g128: PPL=9.73, Ctx=143
    vs B_streaming_128: +2.3%
  I_pos128_mix64_g128: PPL=10.06, Ctx=97
    vs B_streaming_128: +5.7%

Small gathering window experiments:
  J_pos64_mix64_g128: PPL=10.43, Ctx=74 (-1.3%)
  J_pos16_mix64_g128: PPL=11.27, Ctx=56 (+6.6%)
  J_pos16_mix64_g256: PPL=11.34, Ctx=67 (+7.3%)
  J_pos16_mix64_g64: PPL=11.44, Ctx=51 (+8.3%)

*** BEST RESULT: B_streaming_512 ***
    PPL: 8.81, Acc: 52.45%, Ctx: 512


{
  "config": {
    "model": "EleutherAI/pythia-2.8b",
    "max_tokens": 1000,
    "classifications": "results/attention_analysis_pythia-2.8b/head_classifications.json"
  },
  "results": [
    {
      "perplexity": 13.470335006713867,
      "accuracy": 0.47847847847847846,
      "num_tokens": 999,
      "final_cache_size": 999,
      "effective_context": 512.0,
      "ttft": 0.5178114489972359,
      "tpot": 0.08676957834729195,
      "throughput": 11.432160566448063,
      "total_time": 87.38505676100613,
      "name": "A_window_512",
      "config": {
        "name": "A_window_512",
        "group": "A_window_only",
        "type": "uniform",
        "sink_size": 0,
        "window_size": 512
      },
      "group": "A_window_only"
    },
    {
      "perplexity": 21.094482421875,
      "accuracy": 0.4314314314314314,
      "num_tokens": 999,
      "final_cache_size": 999,
      "effective_context": 256.0,
      "ttft": 0.08327372500207275,
      "tpot": 0.08665161752293364,
      "throughput": 9.610014957184278,
      "total_time": 103.95405256400409,
      "name": "A_window_256",
      "config": {
        "name": "A_window_256",
        "group": "A_window_only",
        "type": "uniform",
        "sink_size": 0,
        "window_size": 256
      },
      "group": "A_window_only"
    },
    {
      "perplexity": 26.28227996826172,
      "accuracy": 0.4094094094094094,
      "num_tokens": 999,
      "final_cache_size": 999,
      "effective_context": 128.0,
      "ttft": 0.08570044999942183,
      "tpot": 0.08704941668133004,
      "throughput": 7.458396403070963,
      "total_time": 133.9430014190002,
      "name": "A_window_128",
      "config": {
        "name": "A_window_128",
        "group": "A_window_only",
        "type": "uniform",
        "sink_size": 0,
        "window_size": 128
      },
      "group": "A_window_only"
    },
    {
      "perplexity": 38.72179412841797,
      "accuracy": 0.36036036036036034,
      "num_tokens": 999,
      "final_cache_size": 999,
      "effective_context": 64.0,
      "ttft": 0.08285488000547048,
      "tpot": 0.08662219507116282,
      "throughput": 9.146733990063623,
      "total_time": 109.21931271700305,
      "name": "A_window_64",
      "config": {
        "name": "A_window_64",
        "group": "A_window_only",
        "type": "uniform",
        "sink_size": 0,
        "window_size": 64
      },
      "group": "A_window_only"
    },
    {
      "perplexity": 8.81002426147461,
      "accuracy": 0.5245245245245245,
      "num_tokens": 999,
      "final_cache_size": 999,
      "effective_context": 512.0,
      "ttft": 0.08313692999945488,
      "tpot": 0.08674451016128308,
      "throughput": 11.49246678716215,
      "total_time": 86.92650746800064,
      "name": "B_streaming_512",
      "config": {
        "name": "B_streaming_512",
        "group": "B_streaming",
        "type": "uniform",
        "sink_size": 4,
        "window_size": 508
      },
      "group": "B_streaming"
    },
    {
      "perplexity": 9.144567489624023,
      "accuracy": 0.5195195195195195,
      "num_tokens": 999,
      "final_cache_size": 999,
      "effective_context": 256.0,
      "ttft": 0.0830155549920164,
      "tpot": 0.08676699089584347,
      "throughput": 11.489087071985818,
      "total_time": 86.9520784149936,
      "name": "B_streaming_256",
      "config": {
        "name": "B_streaming_256",
        "group": "B_streaming",
        "type": "uniform",
        "sink_size": 4,
        "window_size": 252
      },
      "group": "B_streaming"
    },
    {
      "perplexity": 9.515253067016602,
      "accuracy": 0.5205205205205206,
      "num_tokens": 999,
      "final_cache_size": 999,
      "effective_context": 128.0,
      "ttft": 0.08299216300656553,
      "tpot": 0.0861890106294114,
      "throughput": 11.56630102922293,
      "total_time": 86.37160640000366,
      "name": "B_streaming_128",
      "config": {
        "name": "B_streaming_128",
        "group": "B_streaming",
        "type": "uniform",
        "sink_size": 4,
        "window_size": 124
      },
      "group": "B_streaming"
    },
    {
      "perplexity": 10.569684982299805,
      "accuracy": 0.5105105105105106,
      "num_tokens": 999,
      "final_cache_size": 999,
      "effective_context": 64.0,
      "ttft": 0.08305978300631978,
      "tpot": 0.08645956219632223,
      "throughput": 7.847542384477422,
      "total_time": 127.30100088099425,
      "name": "B_streaming_64",
      "config": {
        "name": "B_streaming_64",
        "group": "B_streaming",
        "type": "uniform",
        "sink_size": 4,
        "window_size": 60
      },
      "group": "B_streaming"
    },
    {
      "perplexity": 11.213044166564941,
      "accuracy": 0.5065065065065065,
      "num_tokens": 999,
      "final_cache_size": 999,
      "effective_context": 61.5625,
      "ttft": 0.08282003099157009,
      "tpot": 0.08712742421974651,
      "throughput": 6.29507836280752,
      "total_time": 158.6954033649963,
      "name": "G_conf0.3_base128",
      "config": {
        "name": "G_conf0.3_base128",
        "group": "G_confidence_sweep",
        "type": "confidence_based",
        "classifications_path": "results/attention_analysis_pythia-2.8b/head_classifications.json",
        "confidence_threshold": 0.3,
        "base_window": 128,
        "high_conf_windows": {
          "positional": 16,
          "mixed": 64,
          "gathering": 256
        },
        "sink_size": 4
      },
      "group": "G_confidence_sweep"
    },
    {
      "perplexity": 11.009711265563965,
      "accuracy": 0.5035035035035035,
      "num_tokens": 999,
      "final_cache_size": 999,
      "effective_context": 61.765625,
      "ttft": 0.08317261000047438,
      "tpot": 0.0865276875449859,
      "throughput": 7.435167471122108,
      "total_time": 134.3614658150036,
      "name": "G_conf0.4_base128",
      "config": {
        "name": "G_conf0.4_base128",
        "group": "G_confidence_sweep",
        "type": "confidence_based",
        "classifications_path": "results/attention_analysis_pythia-2.8b/head_classifications.json",
        "confidence_threshold": 0.4,
        "base_window": 128,
        "high_conf_windows": {
          "positional": 16,
          "mixed": 64,
          "gathering": 256
        },
        "sink_size": 4
      },
      "group": "G_confidence_sweep"
    },
    {
      "perplexity": 10.942428588867188,
      "accuracy": 0.5045045045045045,
      "num_tokens": 999,
      "final_cache_size": 999,
      "effective_context": 73.578125,
      "ttft": 0.08302825200371444,
      "tpot": 0.08650396910210209,
      "throughput": 9.11525108691122,
      "total_time": 109.59654215499177,
      "name": "G_conf0.5_base128",
      "config": {
        "name": "G_conf0.5_base128",
        "group": "G_confidence_sweep",
        "type": "confidence_based",
        "classifications_path": "results/attention_analysis_pythia-2.8b/head_classifications.json",
        "confidence_threshold": 0.5,
        "base_window": 128,
        "high_conf_windows": {
          "positional": 16,
          "mixed": 64,
          "gathering": 256
        },
        "sink_size": 4
      },
      "group": "G_confidence_sweep"
    },
    {
      "perplexity": 9.762041091918945,
      "accuracy": 0.5225225225225225,
      "num_tokens": 999,
      "final_cache_size": 999,
      "effective_context": 120.640625,
      "ttft": 0.08297488700191025,
      "tpot": 0.08614911180770131,
      "throughput": 11.57202702993123,
      "total_time": 86.32886852200318,
      "name": "G_conf0.55_base128",
      "config": {
        "name": "G_conf0.55_base128",
        "group": "G_confidence_sweep",
        "type": "confidence_based",
        "classifications_path": "results/attention_analysis_pythia-2.8b/head_classifications.json",
        "confidence_threshold": 0.55,
        "base_window": 128,
        "high_conf_windows": {
          "positional": 16,
          "mixed": 64,
          "gathering": 256
        },
        "sink_size": 4
      },
      "group": "G_confidence_sweep"
    },
    {
      "perplexity": 9.574077606201172,
      "accuracy": 0.5185185185185185,
      "num_tokens": 999,
      "final_cache_size": 999,
      "effective_context": 128.28125,
      "ttft": 0.0826188840001123,
      "tpot": 0.08612920533445931,
      "throughput": 11.574720933852502,
      "total_time": 86.30877631600015,
      "name": "G_conf0.6_base128",
      "config": {
        "name": "G_conf0.6_base128",
        "group": "G_confidence_sweep",
        "type": "confidence_based",
        "classifications_path": "results/attention_analysis_pythia-2.8b/head_classifications.json",
        "confidence_threshold": 0.6,
        "base_window": 128,
        "high_conf_windows": {
          "positional": 16,
          "mixed": 64,
          "gathering": 256
        },
        "sink_size": 4
      },
      "group": "G_confidence_sweep"
    },
    {
      "perplexity": 9.631502151489258,
      "accuracy": 0.5135135135135135,
      "num_tokens": 999,
      "final_cache_size": 999,
      "effective_context": 129.921875,
      "ttft": 0.08300072001293302,
      "tpot": 0.08633576994758617,
      "throughput": 11.546943055542695,
      "total_time": 86.51640483499796,
      "name": "G_conf0.65_base128",
      "config": {
        "name": "G_conf0.65_base128",
        "group": "G_confidence_sweep",
        "type": "confidence_based",
        "classifications_path": "results/attention_analysis_pythia-2.8b/head_classifications.json",
        "confidence_threshold": 0.65,
        "base_window": 128,
        "high_conf_windows": {
          "positional": 16,
          "mixed": 64,
          "gathering": 256
        },
        "sink_size": 4
      },
      "group": "G_confidence_sweep"
    },
    {
      "perplexity": 9.632721900939941,
      "accuracy": 0.5135135135135135,
      "num_tokens": 999,
      "final_cache_size": 999,
      "effective_context": 130.46875,
      "ttft": 0.08283018499787431,
      "tpot": 0.08623049061619775,
      "throughput": 11.560961699373323,
      "total_time": 86.41149637699709,
      "name": "G_conf0.7_base128",
      "config": {
        "name": "G_conf0.7_base128",
        "group": "G_confidence_sweep",
        "type": "confidence_based",
        "classifications_path": "results/attention_analysis_pythia-2.8b/head_classifications.json",
        "confidence_threshold": 0.7,
        "base_window": 128,
        "high_conf_windows": {
          "positional": 16,
          "mixed": 64,
          "gathering": 256
        },
        "sink_size": 4
      },
      "group": "G_confidence_sweep"
    },
    {
      "perplexity": 9.537336349487305,
      "accuracy": 0.5135135135135135,
      "num_tokens": 999,
      "final_cache_size": 999,
      "effective_context": 131.890625,
      "ttft": 0.10473962199466769,
      "tpot": 0.08619353959830825,
      "throughput": 11.563119919335524,
      "total_time": 86.39536794299784,
      "name": "G_conf0.8_base128",
      "config": {
        "name": "G_conf0.8_base128",
        "group": "G_confidence_sweep",
        "type": "confidence_based",
        "classifications_path": "results/attention_analysis_pythia-2.8b/head_classifications.json",
        "confidence_threshold": 0.8,
        "base_window": 128,
        "high_conf_windows": {
          "positional": 16,
          "mixed": 64,
          "gathering": 256
        },
        "sink_size": 4
      },
      "group": "G_confidence_sweep"
    },
    {
      "perplexity": 11.267993927001953,
      "accuracy": 0.5025025025025025,
      "num_tokens": 999,
      "final_cache_size": 999,
      "effective_context": 56.4765625,
      "ttft": 0.08289111001067795,
      "tpot": 0.08628432481489431,
      "throughput": 11.55391632276266,
      "total_time": 86.46418860000267,
      "name": "G_conf0.5_base64",
      "config": {
        "name": "G_conf0.5_base64",
        "group": "G_confidence_sweep",
        "type": "confidence_based",
        "classifications_path": "results/attention_analysis_pythia-2.8b/head_classifications.json",
        "confidence_threshold": 0.5,
        "base_window": 64,
        "high_conf_windows": {
          "positional": 8,
          "mixed": 64,
          "gathering": 128
        },
        "sink_size": 4
      },
      "group": "G_confidence_sweep"
    },
    {
      "perplexity": 10.47424030303955,
      "accuracy": 0.5065065065065065,
      "num_tokens": 999,
      "final_cache_size": 999,
      "effective_context": 66.140625,
      "ttft": 0.08311676599259954,
      "tpot": 0.08650015612018357,
      "throughput": 11.524929094507144,
      "total_time": 86.68166127600125,
      "name": "G_conf0.6_base64",
      "config": {
        "name": "G_conf0.6_base64",
        "group": "G_confidence_sweep",
        "type": "confidence_based",
        "classifications_path": "results/attention_analysis_pythia-2.8b/head_classifications.json",
        "confidence_threshold": 0.6,
        "base_window": 64,
        "high_conf_windows": {
          "positional": 8,
          "mixed": 64,
          "gathering": 128
        },
        "sink_size": 4
      },
      "group": "G_confidence_sweep"
    },
    {
      "perplexity": 10.42166519165039,
      "accuracy": 0.5105105105105106,
      "num_tokens": 999,
      "final_cache_size": 999,
      "effective_context": 67.234375,
      "ttft": 0.0832269500097027,
      "tpot": 0.08615776958924584,
      "throughput": 11.570437229411093,
      "total_time": 86.34073027600243,
      "name": "G_conf0.7_base64",
      "config": {
        "name": "G_conf0.7_base64",
        "group": "G_confidence_sweep",
        "type": "confidence_based",
        "classifications_path": "results/attention_analysis_pythia-2.8b/head_classifications.json",
        "confidence_threshold": 0.7,
        "base_window": 64,
        "high_conf_windows": {
          "positional": 8,
          "mixed": 64,
          "gathering": 128
        },
        "sink_size": 4
      },
      "group": "G_confidence_sweep"
    },
    {
      "perplexity": 10.059761047363281,
      "accuracy": 0.5125125125125125,
      "num_tokens": 999,
      "final_cache_size": 999,
      "effective_context": 96.625,
      "ttft": 0.08313419799378607,
      "tpot": 0.08612346673138296,
      "throughput": 11.575119179121735,
      "total_time": 86.30580683799053,
      "name": "I_pos128_mix64_g128",
      "config": {
        "name": "I_pos128_mix64_g128",
        "group": "I_inverse_positional",
        "type": "head_aware",
        "classifications_path": "results/attention_analysis_pythia-2.8b/head_classifications.json",
        "window_override": {
          "positional": 128,
          "mixed": 64,
          "gathering": 128
        },
        "sink_size": 4
      },
      "group": "I_inverse_positional"
    },
    {
      "perplexity": 9.730536460876465,
      "accuracy": 0.5245245245245245,
      "num_tokens": 999,
      "final_cache_size": 999,
      "effective_context": 142.875,
      "ttft": 0.08284991499385796,
      "tpot": 0.08622088191882878,
      "throughput": 11.562200165652998,
      "total_time": 86.40224054999999,
      "name": "I_pos256_mix64_g128",
      "config": {
        "name": "I_pos256_mix64_g128",
        "group": "I_inverse_positional",
        "type": "head_aware",
        "classifications_path": "results/attention_analysis_pythia-2.8b/head_classifications.json",
        "window_override": {
          "positional": 256,
          "mixed": 64,
          "gathering": 128
        },
        "sink_size": 4
      },
      "group": "I_inverse_positional"
    },
    {
      "perplexity": 9.61960506439209,
      "accuracy": 0.5215215215215215,
      "num_tokens": 999,
      "final_cache_size": 999,
      "effective_context": 235.375,
      "ttft": 0.0828826119977748,
      "tpot": 0.08639568637237993,
      "throughput": 9.66934852646971,
      "total_time": 103.31616419299098,
      "name": "I_pos512_mix64_g128",
      "config": {
        "name": "I_pos512_mix64_g128",
        "group": "I_inverse_positional",
        "type": "head_aware",
        "classifications_path": "results/attention_analysis_pythia-2.8b/head_classifications.json",
        "window_override": {
          "positional": 512,
          "mixed": 64,
          "gathering": 128
        },
        "sink_size": 4
      },
      "group": "I_inverse_positional"
    },
    {
      "perplexity": 9.339359283447266,
      "accuracy": 0.5255255255255256,
      "num_tokens": 999,
      "final_cache_size": 999,
      "effective_context": 178.25,
      "ttft": 0.08311368699651212,
      "tpot": 0.08621031482552807,
      "throughput": 11.563632254257389,
      "total_time": 86.39154013499501,
      "name": "I_pos256_mix128_g128",
      "config": {
        "name": "I_pos256_mix128_g128",
        "group": "I_inverse_positional",
        "type": "head_aware",
        "classifications_path": "results/attention_analysis_pythia-2.8b/head_classifications.json",
        "window_override": {
          "positional": 256,
          "mixed": 128,
          "gathering": 128
        },
        "sink_size": 4
      },
      "group": "I_inverse_positional"
    },
    {
      "perplexity": 11.442672729492188,
      "accuracy": 0.5035035035035035,
      "num_tokens": 999,
      "final_cache_size": 999,
      "effective_context": 50.65625,
      "ttft": 0.08303792598599102,
      "tpot": 0.08638735567038458,
      "throughput": 11.540104397214476,
      "total_time": 86.56767439999385,
      "name": "J_pos16_mix64_g64",
      "config": {
        "name": "J_pos16_mix64_g64",
        "group": "J_small_gathering",
        "type": "head_aware",
        "classifications_path": "results/attention_analysis_pythia-2.8b/head_classifications.json",
        "window_override": {
          "positional": 16,
          "mixed": 64,
          "gathering": 64
        },
        "sink_size": 4
      },
      "group": "J_small_gathering"
    },
    {
      "perplexity": 11.270380020141602,
      "accuracy": 0.5075075075075075,
      "num_tokens": 999,
      "final_cache_size": 999,
      "effective_context": 56.15625,
      "ttft": 0.0831659569957992,
      "tpot": 0.08629603083779706,
      "throughput": 11.551738661381295,
      "total_time": 86.48048828699393,
      "name": "J_pos16_mix64_g128",
      "config": {
        "name": "J_pos16_mix64_g128",
        "group": "J_small_gathering",
        "type": "head_aware",
        "classifications_path": "results/attention_analysis_pythia-2.8b/head_classifications.json",
        "window_override": {
          "positional": 16,
          "mixed": 64,
          "gathering": 128
        },
        "sink_size": 4
      },
      "group": "J_small_gathering"
    },
    {
      "perplexity": 11.342434883117676,
      "accuracy": 0.5045045045045045,
      "num_tokens": 999,
      "final_cache_size": 999,
      "effective_context": 67.15625,
      "ttft": 0.08305157200084068,
      "tpot": 0.08628245171454393,
      "throughput": 11.55410176753414,
      "total_time": 86.46280083901365,
      "name": "J_pos16_mix64_g256",
      "config": {
        "name": "J_pos16_mix64_g256",
        "group": "J_small_gathering",
        "type": "head_aware",
        "classifications_path": "results/attention_analysis_pythia-2.8b/head_classifications.json",
        "window_override": {
          "positional": 16,
          "mixed": 64,
          "gathering": 256
        },
        "sink_size": 4
      },
      "group": "J_small_gathering"
    },
    {
      "perplexity": 10.432141304016113,
      "accuracy": 0.5145145145145145,
      "num_tokens": 999,
      "final_cache_size": 999,
      "effective_context": 73.5,
      "ttft": 0.08309077500598505,
      "tpot": 0.08633047662429427,
      "throughput": 11.545500801631484,
      "total_time": 86.52721238898812,
      "name": "J_pos64_mix64_g128",
      "config": {
        "name": "J_pos64_mix64_g128",
        "group": "J_small_gathering",
        "type": "head_aware",
        "classifications_path": "results/attention_analysis_pythia-2.8b/head_classifications.json",
        "window_override": {
          "positional": 64,
          "mixed": 64,
          "gathering": 128
        },
        "sink_size": 4
      },
      "group": "J_small_gathering"
    },
    {
      "perplexity": 10.423605918884277,
      "accuracy": 0.5075075075075075,
      "num_tokens": 999,
      "final_cache_size": 999,
      "effective_context": 68.0,
      "ttft": 0.08322859200416133,
      "tpot": 0.0861114398013927,
      "throughput": 11.576475450368866,
      "total_time": 86.29569546300627,
      "name": "K_uniform64_aware",
      "config": {
        "name": "K_uniform64_aware",
        "group": "K_uniform_aware",
        "type": "head_aware",
        "classifications_path": "results/attention_analysis_pythia-2.8b/head_classifications.json",
        "window_override": {
          "positional": 64,
          "mixed": 64,
          "gathering": 64
        },
        "sink_size": 4
      },
      "group": "K_uniform_aware"
    },
    {
      "perplexity": 9.600322723388672,
      "accuracy": 0.5245245245245245,
      "num_tokens": 999,
      "final_cache_size": 999,
      "effective_context": 132.0,
      "ttft": 0.08283737600140739,
      "tpot": 0.08620570973474612,
      "throughput": 11.563787219360362,
      "total_time": 86.39038241100207,
      "name": "K_uniform128_aware",
      "config": {
        "name": "K_uniform128_aware",
        "group": "K_uniform_aware",
        "type": "head_aware",
        "classifications_path": "results/attention_analysis_pythia-2.8b/head_classifications.json",
        "window_override": {
          "positional": 128,
          "mixed": 128,
          "gathering": 128
        },
        "sink_size": 4
      },
      "group": "K_uniform_aware"
    }
  ]
}