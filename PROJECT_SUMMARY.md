# DynaTree: æ ‘å½¢æŠ•æœºè§£ç é¡¹ç›®æ€»ç»“

## ðŸ“‹ é¡¹ç›®æ¦‚è§ˆ

**é¡¹ç›®åç§°**ï¼šDynaTree - Confidence-Aware Adaptive Tree Speculative Decoding  
**é¡¹ç›®ç±»åž‹**ï¼šå­¦æœ¯ç ”ç©¶é¡¹ç›®ï¼ˆè¯¾ç¨‹ä½œä¸š + æ½œåœ¨è®ºæ–‡æŠ•ç¨¿ï¼‰  
**ç ”ç©¶é¢†åŸŸ**ï¼šå¤§è¯­è¨€æ¨¡åž‹ï¼ˆLLMï¼‰é«˜æ•ˆæŽ¨ç†ã€æŠ•æœºè§£ç ï¼ˆSpeculative Decodingï¼‰  
**æ—¶é—´çº¿**ï¼š2025å¹´12æœˆ - 2026å¹´1æœˆ

---

## ðŸŽ¯ ç ”ç©¶ç›®æ ‡

### æ ¸å¿ƒé—®é¢˜
å¤§è¯­è¨€æ¨¡åž‹çš„è‡ªå›žå½’è§£ç è¿‡ç¨‹æ˜¯**ä¸²è¡Œçš„**ï¼Œæ¯æ¬¡åªç”Ÿæˆä¸€ä¸ªtokenï¼Œå¯¼è‡´GPUåˆ©ç”¨çŽ‡ä½Žã€æŽ¨ç†é€Ÿåº¦æ…¢ã€‚

### è§£å†³æ–¹æ¡ˆ
**æŠ•æœºè§£ç ï¼ˆSpeculative Decodingï¼‰**ï¼šä½¿ç”¨å°æ¨¡åž‹ï¼ˆdraft modelï¼‰å¿«é€Ÿç”Ÿæˆå¤šä¸ªå€™é€‰tokenï¼Œå†ç”¨å¤§æ¨¡åž‹ï¼ˆtarget modelï¼‰å¹¶è¡ŒéªŒè¯ï¼Œä¿æŒè¾“å‡ºåˆ†å¸ƒä¸å˜çš„å‰æä¸‹åŠ é€ŸæŽ¨ç†ã€‚

### æˆ‘ä»¬çš„åˆ›æ–°
**DynaTree**ï¼šä¸€ä¸ªåŸºäºŽæ ‘ç»“æž„çš„æŠ•æœºè§£ç æ¡†æž¶ï¼Œå…·æœ‰ä»¥ä¸‹åˆ›æ–°ç‚¹ï¼š

1. **æ ‘å½¢ç»“æž„éªŒè¯**ï¼ˆvs. Linear Speculative Decodingï¼‰
   - Linearæ–¹æ³•ï¼šdraft modelç”Ÿæˆå•é“¾ `t1 â†’ t2 â†’ t3 â†’ t4`
   - Treeæ–¹æ³•ï¼šdraft modelç”Ÿæˆæ ‘ç»“æž„ï¼ŒæŽ¢ç´¢å¤šæ¡å€™é€‰è·¯å¾„
   - ä¼˜åŠ¿ï¼šå½“early tokenè¢«æ‹’ç»æ—¶ï¼Œtreeä»æœ‰å…¶ä»–è·¯å¾„å¯é€‰

2. **è‡ªé€‚åº”æ¦‚çŽ‡å‰ªæž**ï¼ˆAdaptive Probability Pruningï¼‰
   - æ ¹æ®draft modelçš„æ¦‚çŽ‡åˆ†å¸ƒï¼ŒåŠ¨æ€å‰ªé™¤ä½Žæ¦‚çŽ‡åˆ†æ”¯
   - æŽ§åˆ¶æ ‘çš„å¤§å°ï¼Œé˜²æ­¢æŒ‡æ•°çˆ†ç‚¸
   - å¼•å…¥æ¦‚çŽ‡é˜ˆå€¼ Ï„ å’ŒèŠ‚ç‚¹é¢„ç®— N_max

3. **ðŸ”¥ ç½®ä¿¡åº¦é©±åŠ¨çš„è‡ªé€‚åº”åˆ†æ”¯ - æ ¸å¿ƒåˆ›æ–°**ï¼ˆConfidence-Aware Adaptive Branchingï¼‰
   - **é—®é¢˜**ï¼šå›ºå®šåˆ†æ”¯å› å­Bæ— æ³•é€‚åº”draft modelçš„é¢„æµ‹ç½®ä¿¡åº¦å˜åŒ–
   - **è§£å†³**ï¼šæ ¹æ®draft modelçš„top-1æ¦‚çŽ‡åŠ¨æ€è°ƒæ•´åˆ†æ”¯æ•°
     - é«˜ç½®ä¿¡åº¦ï¼ˆ>0.9ï¼‰â†’ 1ä¸ªåˆ†æ”¯ï¼ˆmodelå¾ˆç¡®å®šï¼‰
     - ä¸­ç­‰ç½®ä¿¡åº¦ï¼ˆ0.4-0.9ï¼‰â†’ 2ä¸ªåˆ†æ”¯ï¼ˆå¹³è¡¡ï¼‰
     - ä½Žç½®ä¿¡åº¦ï¼ˆ<0.4ï¼‰â†’ 3ä¸ªåˆ†æ”¯ï¼ˆå¤šæŽ¢ç´¢ï¼‰
   - **ä¸‰é˜¶æ®µæœºåˆ¶**ï¼š
     - Phase 1: Adaptive Branchingï¼ˆè‡ªé€‚åº”åˆ†æ”¯å› å­ï¼‰
     - Phase 2: Dynamic Depth Controlï¼ˆåŠ¨æ€æ·±åº¦æŽ§åˆ¶ + æ—©åœæœºåˆ¶ï¼‰
     - Phase 3: Historical Adjustmentï¼ˆåŽ†å²æŽ¥å—çŽ‡è‡ªé€‚åº”è°ƒæ•´ï¼‰

---

## ðŸ”¬ æŠ€æœ¯å®žçŽ°

### ç³»ç»Ÿæž¶æž„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DynaTree Pipeline                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Input: Prefix tokens x[1:t]
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 1: Tree Drafting               â”‚
â”‚  - Draft modelç”Ÿæˆtoken tree         â”‚
â”‚  - Adaptive branching: B âˆˆ {1,2,3}   â”‚
â”‚  - æ ¹æ®ç½®ä¿¡åº¦å†³å®šåˆ†æ”¯æ•°               â”‚
â”‚  - Breadth-first expansion           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 2: Adaptive Pruning            â”‚
â”‚  - Probability threshold pruning     â”‚
â”‚  - å‰ªé™¤ç´¯ç§¯æ¦‚çŽ‡ < Ï„ çš„åˆ†æ”¯            â”‚
â”‚  - Node budget: max N_max nodes      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 3: Tree Flattening & Masking  â”‚
â”‚  - BFSåºåˆ—åŒ–æ ‘ä¸ºtoken sequence        â”‚
â”‚  - æž„é€ tree attention mask           â”‚
â”‚  - ç¡®ä¿å› æžœå…³ç³»ï¼ˆæ¯ä¸ªnodeåªçœ‹ç¥–å…ˆï¼‰   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 4: Parallel Verification       â”‚
â”‚  - Target modelä¸€æ¬¡forward pass       â”‚
â”‚  - å¹¶è¡ŒéªŒè¯æ‰€æœ‰drafted tokens         â”‚
â”‚  - èŽ·å–æ¯ä¸ªnodeçš„target logits        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 5: Greedy Path Selection       â”‚
â”‚  - æ‰¾åˆ°æœ€é•¿çš„greedy-consistent path   â”‚
â”‚  - æ¯ä¸ªdrafted token == target argmaxâ”‚
â”‚  - Commitè¿™æ¡è·¯å¾„ + 1ä¸ªbonus token    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 6: KV-Cache Update             â”‚
â”‚  - Rollbackæœªcommittedçš„KV cache     â”‚
â”‚  - Rebuild committed tokensçš„cache   â”‚
â”‚  - å‡†å¤‡ä¸‹ä¸€è½®è¿­ä»£                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â†“
Output: Committed tokens y[t+1:t+L]
```

---

## ðŸ’» æ ¸å¿ƒä»£ç ç»“æž„

### ä¸»è¦æ¨¡å—

```
spec_decode/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ token_tree.py                    # TokenTreeæ•°æ®ç»“æž„
â”‚   â”œâ”€â”€ tree_speculative_generator.py    # Fixed Treeå®žçŽ°
â”‚   â”œâ”€â”€ tree_speculative_generator_adaptive.py  # ðŸ”¥ Adaptive Treeå®žçŽ°
â”‚   â”‚   â”œâ”€â”€ TreeSpeculativeGeneratorV2Adaptive (Phase 1)
â”‚   â”‚   â”œâ”€â”€ TreeSpeculativeGeneratorV2AdaptiveV2 (Phase 2)
â”‚   â”‚   â””â”€â”€ TreeSpeculativeGeneratorV2AdaptiveV3 (Phase 3)
â”‚   â””â”€â”€ ...
â”œâ”€â”€ __init__.py
â””â”€â”€ ...
```

### å…³é”®ç±»å’Œæ–¹æ³•

#### 1. TokenTreeï¼ˆtoken_tree.pyï¼‰
```python
class TokenTree:
    """æ ‘å½¢tokenæ•°æ®ç»“æž„"""
    def __init__(self, max_depth, branch_factor, max_nodes, device):
        self.max_depth = max_depth        # æœ€å¤§æ·±åº¦D
        self.branch_factor = branch_factor # åˆ†æ”¯å› å­B
        self.max_nodes = max_nodes        # èŠ‚ç‚¹é¢„ç®—N_max
        
    def add_node(self, token_id, parent_id, logprob, cum_logprob):
        """æ·»åŠ æ ‘èŠ‚ç‚¹"""
        
    def prune_by_probability(self, threshold):
        """æ¦‚çŽ‡é˜ˆå€¼å‰ªæž"""
        
    def get_attention_mask(self, prefix_len):
        """ç”Ÿæˆtree attention mask"""
```

#### 2. Adaptive Tree Generatorï¼ˆtree_speculative_generator_adaptive.pyï¼‰

```python
class TreeSpeculativeGeneratorV2Adaptive:
    """Phase 1: è‡ªé€‚åº”åˆ†æ”¯å› å­"""
    
    def __init__(
        self,
        high_conf_threshold=0.8,   # é«˜ç½®ä¿¡åº¦é˜ˆå€¼
        low_conf_threshold=0.3,    # ä½Žç½®ä¿¡åº¦é˜ˆå€¼
        min_branch=1,              # æœ€å°åˆ†æ”¯æ•°
        max_branch=4,              # æœ€å¤§åˆ†æ”¯æ•°
        ...
    ):
        pass
    
    def _get_adaptive_branch_factor(self, logits):
        """æ ¹æ®ç½®ä¿¡åº¦å†³å®šåˆ†æ”¯æ•°"""
        probs = torch.softmax(logits, dim=-1)
        confidence = probs.max().item()
        
        if confidence > self.high_conf_threshold:
            return self.min_branch  # é«˜ç½®ä¿¡åº¦ â†’ å°‘åˆ†æ”¯
        elif confidence < self.low_conf_threshold:
            return self.max_branch  # ä½Žç½®ä¿¡åº¦ â†’ å¤šåˆ†æ”¯
        else:
            return self.default_branch  # ä¸­ç­‰ç½®ä¿¡åº¦


class TreeSpeculativeGeneratorV2AdaptiveV2:
    """Phase 2: + åŠ¨æ€æ·±åº¦æŽ§åˆ¶"""
    
    def _should_stop_expansion(self, logits):
        """æ—©åœåˆ¤æ–­ï¼šç½®ä¿¡åº¦å¤ªä½Žåˆ™åœæ­¢æ‰©å±•"""
        confidence = torch.softmax(logits, dim=-1).max().item()
        return confidence < self.stop_threshold  # e.g., 0.1
    
    def _allow_deep_expansion(self, logits, current_depth):
        """æ·±åº¦æ‰©å±•ï¼šé«˜ç½®ä¿¡åº¦å…è®¸è¶…è¿‡base_depth"""
        confidence = torch.softmax(logits, dim=-1).max().item()
        if confidence > self.extend_threshold:  # e.g., 0.95
            return current_depth < self.max_depth
        return current_depth < self.base_depth


class TreeSpeculativeGeneratorV2AdaptiveV3:
    """Phase 3: + åŽ†å²æŽ¥å—çŽ‡è°ƒæ•´"""
    
    def _update_thresholds(self, recent_accept_rate):
        """æ ¹æ®åŽ†å²æŽ¥å—çŽ‡è°ƒæ•´é˜ˆå€¼"""
        if recent_accept_rate < self.target_rate:
            # æŽ¥å—çŽ‡ä½Ž â†’ æ”¾å®½high thresholdï¼ˆæ›´å¤šæŽ¢ç´¢ï¼‰
            self.high_conf_threshold -= self.learning_rate
        else:
            # æŽ¥å—çŽ‡é«˜ â†’ æé«˜high thresholdï¼ˆå‡å°‘å†—ä½™ï¼‰
            self.high_conf_threshold += self.learning_rate
```

---

## ðŸ”§ å®žéªŒè®¾ç½®

### æ¨¡åž‹é…ç½®

| ç»„ä»¶ | æ¨¡åž‹ | å‚æ•°é‡ | è·¯å¾„ |
|------|------|--------|------|
| Target Model | Pythia-2.8B | 2.8B | `/mnt/disk1/models/pythia-2.8b` |
| Draft Model | Pythia-70M | 70M | `/mnt/disk1/models/pythia-70m` |

**è§£ç æ¨¡å¼**ï¼šGreedy Decodingï¼ˆç¡®å®šæ€§ï¼Œä¾¿äºŽéªŒè¯æ­£ç¡®æ€§ï¼‰

### æ•°æ®é›†

1. **WikiText-2**ï¼ˆä¸»å®žéªŒï¼‰
   - ç»“æž„åŒ–çš„Wikipediaæ–‡ç« 
   - æ–‡æœ¬å¯é¢„æµ‹æ€§è¾ƒé«˜
   
2. **PG-19**ï¼ˆè·¨æ•°æ®é›†éªŒè¯ï¼‰
   - é•¿ç¯‡å°è¯´
   - æ›´å¤æ‚çš„å™äº‹ç»“æž„

### è¶…å‚æ•°é…ç½®

#### Fixed Tree Baseline
```python
D = 5            # æ ‘æ·±åº¦
B = 2            # å›ºå®šåˆ†æ”¯å› å­
Ï„ = 0.05         # æ¦‚çŽ‡å‰ªæžé˜ˆå€¼
N_max = 128      # æœ€å¤§èŠ‚ç‚¹æ•°
```

#### Adaptive Tree (Phase 3 - æœ€ä¼˜é…ç½®)
```python
# è‡ªé€‚åº”åˆ†æ”¯
high_conf_threshold = 0.9    # é«˜ç½®ä¿¡åº¦é˜ˆå€¼
low_conf_threshold = 0.4     # ä½Žç½®ä¿¡åº¦é˜ˆå€¼
min_branch = 1               # é«˜ç½®ä¿¡åº¦åˆ†æ”¯æ•°
max_branch = 3               # ä½Žç½®ä¿¡åº¦åˆ†æ”¯æ•°
default_branch = 2           # ä¸­ç­‰ç½®ä¿¡åº¦åˆ†æ”¯æ•°

# åŠ¨æ€æ·±åº¦
base_depth = 5               # åŸºç¡€æ·±åº¦
max_depth = 8                # æœ€å¤§æ·±åº¦
stop_threshold = 0.1         # æ—©åœé˜ˆå€¼
extend_threshold = 0.95      # æ·±åº¦æ‰©å±•é˜ˆå€¼

# åŽ†å²è°ƒæ•´
learning_rate = 0.01         # é˜ˆå€¼è°ƒæ•´å­¦ä¹ çŽ‡
target_accept_rate = 0.85    # ç›®æ ‡æŽ¥å—çŽ‡
```

---

## ðŸ“Š å®žéªŒç»“æžœ

### ä¸»å®žéªŒï¼ˆWikiText-2, 1000 tokensï¼‰

| æ–¹æ³• | åžåé‡ (t/s) | Speedup | æŽ¥å—çŽ‡ (%) | Tokens/Iter |
|------|-------------|---------|-----------|-------------|
| **Baseline (AR)** | 131.1Â±0.4 | 1.00Ã— | - | 1.0 |
| HuggingFace Assisted | ~164.0 | ~1.25Ã— | - | ~3.0 |
| Linear K=6 | 133.1 | 1.02Ã— | 68.3 | 4.10 |
| **Fixed Tree (D=5, B=2)** | 181.3Â±12.3 | **1.38Ã—** | 80.8 | 5.65 |
| Phase 1: Adaptive Branch | 176.7Â±36.2 | 1.35Ã— | 77.9 | 5.45 |
| Phase 2: + Dynamic Depth | 206.0Â±29.8 | 1.57Ã— | 89.6 | 6.27 |
| **Phase 3: + History Adj.** | **210.8Â±26.5** | **1.61Ã—** | **94.7** | **6.63** |

**å…³é”®å‘çŽ°**ï¼š
- âœ… Phase 3 è¾¾åˆ°æœ€é«˜åžåé‡ï¼š210.8 t/s
- âœ… ç›¸æ¯”Fixed Treeæå‡ **16.3%** (210.8 vs 181.3)
- âœ… æŽ¥è¿‘å®Œç¾Žçš„æŽ¥å—çŽ‡ï¼š**94.7%**
- âœ… ç›¸æ¯”BaselineåŠ é€Ÿ **1.61Ã—**

---

### æ¶ˆèžå®žéªŒï¼ˆWikiText-2, 500 tokensï¼‰

#### å„Phaseè´¡çŒ®åˆ†æž

| Base Depth | Method | Throughput | vs Fixed | Accept% | ä¸»è¦è´¡çŒ® |
|-----------|--------|-----------|----------|---------|---------|
| **D=4** | Fixed Tree | 145.1 t/s | - | 77.7% | baseline |
| | Phase 1 | 167.4 t/s | +15.4% | 77.1% | æµ…æ ‘æ—¶adaptiveä¼˜åŠ¿å¤§ |
| | Phase 2 | 185.3 t/s | +27.7% | 87.0% | æ—©åœ+æ·±åº¦æ‰©å±• |
| | Phase 3 | 189.4 t/s | **+31%** | 92.3% | åŽ†å²è°ƒæ•´ |
| **D=5** | Fixed Tree | 177.0 t/s | - | 73.8% | baseline |
| | Phase 1 | 174.0 t/s | -1.7% | 72.9% | å¼€é”€å°šæœªè¡¥å¿ |
| | Phase 2 | 183.5 t/s | +3.7% | 75.9% | è¡¥å¿+æå‡ |
| | Phase 3 | 187.2 t/s | **+6%** | 80.3% | æŒç»­æå‡ |
| **D=6** | Fixed Tree | 183.3 t/s | - | 69.5% | baseline |
| | Phase 1 | 176.9 t/s | -3.5% | 68.9% | æ·±æ ‘adaptiveä¼˜åŠ¿å° |
| | Phase 2 | 191.3 t/s | +4.4% | 72.2% | ä¸»è¦è´¡çŒ® |
| | Phase 3 | 192.3 t/s | **+5%** | 74.2% | å¾®å°æå‡ |

**ç»“è®º**ï¼š
- ðŸ”¥ **Phase 2ï¼ˆåŠ¨æ€æ·±åº¦ï¼‰è´¡çŒ®æœ€å¤§**ï¼š+10-27% across all depths
- âœ… Adaptiveåœ¨æµ…æ ‘æ—¶ä¼˜åŠ¿æ›´å¤§ï¼šD=4æ—¶+31%, D=6æ—¶+5%
- âœ… Phase 3åœ¨é•¿åºåˆ—æ—¶æ•ˆæžœæ›´å¥½ï¼ˆè§Scalabilityï¼‰

---

### å‚æ•°æ•æ„Ÿæ€§åˆ†æžï¼ˆWikiText-2, 500 tokensï¼‰

#### ç½®ä¿¡åº¦é˜ˆå€¼å½±å“

| é…ç½® (high/low) | åžåé‡ | Speedup | Accept% | ç»“è®º |
|----------------|--------|---------|---------|------|
| 0.7 / 0.2 | 169.9 t/s | 1.71Ã— | 78.4% | é˜ˆå€¼åä½Ž |
| 0.8 / 0.3 (é»˜è®¤) | 173.5 t/s | 1.75Ã— | 77.3% | æ¬¡ä¼˜ |
| **0.9 / 0.4** | **180.5 t/s** | **1.82Ã—** | **81.1%** | **æœ€ä¼˜** âœ… |

**å‘çŽ°**ï¼šæ›´ä¸¥æ ¼çš„é˜ˆå€¼ï¼ˆ0.9/0.4ï¼‰æ€§èƒ½æ›´å¥½ï¼Œ+6% vs é»˜è®¤é…ç½®

#### åˆ†æ”¯å› å­èŒƒå›´å½±å“

| é…ç½® [min, max] | åžåé‡ | Speedup | Accept% | ç»“è®º |
|----------------|--------|---------|---------|------|
| [1, 2] | 178.3 t/s | 1.80Ã— | 78.6% | maxå¤ªå° |
| **[1, 3]** | **179.0 t/s** | **1.80Ã—** | **79.7%** | **æœ€ä¼˜** âœ… |
| [1, 4] | 174.8 t/s | 1.76Ã— | 77.3% | maxå¤ªå¤§ |
| [2, 4] | 145.9 t/s | 1.47Ã— | 77.2% | âš ï¸ min=2æ€§èƒ½æš´è·Œ18%ï¼ |

**å…³é”®å‘çŽ°**ï¼š
- âœ… `min_branch=1` è‡³å…³é‡è¦ï¼å¼ºåˆ¶min=2å¯¼è‡´18%æ€§èƒ½ä¸‹é™
- âœ… `max_branch=3` æœ€ä¼˜ï¼Œå¹³è¡¡æŽ¢ç´¢ä¸Žå¼€é”€

---

### å¯æ‰©å±•æ€§åˆ†æžï¼ˆè·¨ç”Ÿæˆé•¿åº¦ï¼‰

| ç”Ÿæˆé•¿åº¦ | Fixed Tree | Adaptive Phase 3 | æå‡ | ç»“è®º |
|---------|-----------|-----------------|------|------|
| 100 | 109.6 t/s | 110.0 t/s | +0.4% | æŒå¹³ |
| 200 | 140.9 t/s | 135.6 t/s | **-3.8%** | âš ï¸ éœ€é¢„çƒ­ |
| 300 | 157.6 t/s | 159.7 t/s | +1.3% | å¼€å§‹é¢†å…ˆ |
| **500** | 165.3 t/s | 178.1 t/s | **+7.7%** | âœ… æ˜¾è‘—ä¼˜åŠ¿ |
| **750** | 183.7 t/s | 190.7 t/s | **+3.8%** | âœ… æŒç»­é¢†å…ˆ |
| **1000** | 192.2 t/s | 210.0 t/s | **+9.3%** | âœ… æœ€å¤§ä¼˜åŠ¿ |

**å…³é”®å‘çŽ°**ï¼š
- âœ… ç”Ÿæˆâ‰¥500 tokensæ—¶ï¼ŒAdaptiveæŒç»­é¢†å…ˆ7-9%
- âš ï¸ çŸ­åºåˆ—ï¼ˆ<300 tokensï¼‰æ—¶ï¼ŒåŽ†å²è°ƒæ•´æœºåˆ¶éœ€è¦"é¢„çƒ­"
- ðŸ“ˆ æŽ¥å—çŽ‡å¢žé•¿æ›²çº¿ï¼šFixed 43%â†’81%, Adaptive 39%â†’**92%**

---

## ðŸ“ é¡¹ç›®æ–‡ä»¶ç»“æž„

```
LLM-Efficient-Reasoning/
â”‚
â”œâ”€â”€ spec_decode/                          # æ ¸å¿ƒå®žçŽ°ä»£ç 
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ token_tree.py                 # æ ‘æ•°æ®ç»“æž„
â”‚   â”‚   â”œâ”€â”€ tree_speculative_generator.py # Fixed Tree
â”‚   â”‚   â””â”€â”€ tree_speculative_generator_adaptive.py  # ðŸ”¥ Adaptive Tree
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ papers/                               # å®žéªŒè„šæœ¬
â”‚   â”œâ”€â”€ benchmark_adaptive_paper.py       # ä¸»å®žéªŒï¼ˆ1000 tokensï¼‰
â”‚   â”œâ”€â”€ benchmark_adaptive_full.py        # å®Œæ•´benchmark
â”‚   â”œâ”€â”€ tree_param_search.py              # å‚æ•°æœç´¢
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ results/                              # å®žéªŒç»“æžœ
â”‚   â”œâ”€â”€ adaptive/
â”‚   â”‚   â”œâ”€â”€ main/                         # ä¸»å®žéªŒç»“æžœ
â”‚   â”‚   â”‚   â”œâ”€â”€ paper_benchmark_main_1000tokens.json  âœ…
â”‚   â”‚   â”‚   â””â”€â”€ main_analysis.md
â”‚   â”‚   â”œâ”€â”€ ablation/                     # æ¶ˆèžå®žéªŒ
â”‚   â”‚   â”‚   â”œâ”€â”€ paper_benchmark_ablation.json  âœ…
â”‚   â”‚   â”‚   â””â”€â”€ ablation_analysis.md
â”‚   â”‚   â”œâ”€â”€ sensitivity/                  # å‚æ•°æ•æ„Ÿæ€§
â”‚   â”‚   â”‚   â”œâ”€â”€ paper_benchmark_sensitivity.json  âœ…
â”‚   â”‚   â”‚   â””â”€â”€ sensitivity_analysis.md
â”‚   â”‚   â””â”€â”€ scalablity/                   # å¯æ‰©å±•æ€§
â”‚   â”‚       â”œâ”€â”€ paper_benchmark_scalability.json  âœ…
â”‚   â”‚       â””â”€â”€ scalability_analysis.md
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ NeurIPSæ¨¡æ¿/                          # è®ºæ–‡LaTeXæºç 
â”‚   â”œâ”€â”€ neurips_2025.tex                  # ä¸»æ–‡æ¡£
â”‚   â”œâ”€â”€ neurips_2025.pdf                  # ç¼–è¯‘PDF
â”‚   â””â”€â”€ references.bib                    # å‚è€ƒæ–‡çŒ®
â”‚
â”œâ”€â”€ figures/                              # å›¾è¡¨æ–‡ä»¶
â”‚   â”œâ”€â”€ dynatree-v8.png                   # æž¶æž„å›¾
â”‚   â”œâ”€â”€ tree_config_heatmap.pdf           # å‚æ•°çƒ­åŠ›å›¾
â”‚   â”œâ”€â”€ dataset_comparison.pdf            # æ•°æ®é›†å¯¹æ¯”
â”‚   â”œâ”€â”€ length_scaling.pdf                # é•¿åº¦æ‰©å±•
â”‚   â”œâ”€â”€ prompt_length_impact.pdf          # Prompté•¿åº¦å½±å“
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ plot_*.py                             # ç»˜å›¾è„šæœ¬
â”‚   â”œâ”€â”€ plot_tree_config_heatmap.py
â”‚   â”œâ”€â”€ plot_dataset_comparison.py
â”‚   â”œâ”€â”€ plot_length_scaling.py
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ PROJECT_SUMMARY.md                    # ðŸ“„ æœ¬æ–‡æ¡£
â”œâ”€â”€ PAPER_COMPLETE_REVISION_ROADMAP.md    # è®ºæ–‡ä¿®æ”¹è·¯çº¿å›¾
â”œâ”€â”€ TIMELINE_FINAL_DESIGN.md              # Timelineè®¾è®¡æ–‡æ¡£
â””â”€â”€ README.md
```

---

## ðŸŽ“ è®ºæ–‡çŠ¶æ€

### å½“å‰è¿›åº¦
- âœ… **æ ¸å¿ƒå®žéªŒå®Œæˆ**ï¼šmain, ablation, sensitivity, scalability
- âœ… **ä»£ç å®žçŽ°å®Œæˆ**ï¼šä¸‰é˜¶æ®µadaptiveæœºåˆ¶
- âš ï¸ **è®ºæ–‡éœ€è¦å¤§æ”¹**ï¼šçªå‡ºadaptive branchingåˆ›æ–°ç‚¹
- âš ï¸ **å›¾è¡¨éœ€è¦è¡¥å……**ï¼š7ä¸ªæ–°å›¾è¡¨ï¼ˆéƒ¨åˆ†å®Œæˆï¼‰

### éœ€è¦ä¿®æ”¹çš„è®ºæ–‡å†…å®¹

#### P0ï¼ˆæ ¸å¿ƒå¿…æ”¹ï¼‰
1. **Abstract**ï¼šæ–°å¢ž"confidence-aware adaptive branching"æè¿°
2. **Introduction**ï¼šæ–°å¢žå›ºå®šæ ‘é—®é¢˜æ®µè½ + ä¿®æ”¹è´¡çŒ®åˆ—è¡¨
3. **Method Section 3.3**ï¼šå®Œæ•´æè¿°ä¸‰é˜¶æ®µæœºåˆ¶
4. **Experiments 4.2**ï¼šé‡å†™ä¸»å®žéªŒï¼ˆåŒ…å«Phase 1/2/3ï¼‰
5. **Experiments 4.3**ï¼šæ–°å¢žAblation Study
6. **Table 1**ï¼šé‡å†™ï¼ˆåŒ…å«æ‰€æœ‰æ–¹æ³•+Phase 1/2/3ï¼‰
7. **Figure 2**ï¼šæ–°å¢žFixed vs Adaptiveç¤ºæ„å›¾
8. **Figure 3**ï¼šé‡ç»˜Phaseå¯¹æ¯”æŸ±çŠ¶å›¾

è¯¦è§ï¼š`PAPER_COMPLETE_REVISION_ROADMAP.md`ï¼ˆ2068è¡Œå®Œæ•´æŒ‡å—ï¼‰

---

## ðŸ”‘ å…³é”®æŠ€æœ¯å†³ç­–

### 1. ä¸ºä»€ä¹ˆé€‰æ‹©æ ‘ç»“æž„ï¼Ÿ
- **é—®é¢˜**ï¼šLinearæ–¹æ³•åœ¨early rejectionæ—¶æµªè´¹åŽç»­drafts
- **è§£å†³**ï¼šTreeæŽ¢ç´¢å¤šæ¡è·¯å¾„ï¼Œæé«˜æ‰¾åˆ°valid pathçš„æ¦‚çŽ‡
- **trade-off**ï¼šæ ‘å¤§å°éœ€è¦æŽ§åˆ¶ï¼ˆé€šè¿‡pruningå’Œnode budgetï¼‰

### 2. ä¸ºä»€ä¹ˆéœ€è¦Adaptive Branchingï¼Ÿ
- **é—®é¢˜**ï¼šFixed Båœ¨é«˜/ä½Žç½®ä¿¡åº¦æ—¶éƒ½ä¸å¤Ÿçµæ´»
  - é«˜ç½®ä¿¡åº¦ï¼šè¿‡åº¦æŽ¢ç´¢ï¼Œæµªè´¹è®¡ç®—
  - ä½Žç½®ä¿¡åº¦ï¼šæŽ¢ç´¢ä¸è¶³ï¼Œé”™å¤±æ­£ç¡®è·¯å¾„
- **è§£å†³**ï¼šæ ¹æ®ç½®ä¿¡åº¦åŠ¨æ€è°ƒæ•´Bâˆˆ{1,2,3}
- **æ•ˆæžœ**ï¼šPhase 3ç›¸æ¯”Fixed Treeæå‡16.3%ï¼ŒæŽ¥å—çŽ‡94.7%

### 3. ä¸ºä»€ä¹ˆéœ€è¦ä¸‰ä¸ªPhaseï¼Ÿ
- **Phase 1**ï¼ˆAdaptive Branchï¼‰ï¼šå¼•å…¥è‡ªé€‚åº”ï¼Œä½†æœ‰å¼€é”€ï¼ˆ-2.5%ï¼‰
- **Phase 2**ï¼ˆDynamic Depthï¼‰ï¼šæ—©åœ+æ·±åº¦æ‰©å±•ï¼Œå¤§å¹…æå‡ï¼ˆ+13.6%ï¼‰
- **Phase 3**ï¼ˆHistorical Adjustï¼‰ï¼šè¿è¡Œæ—¶ä¼˜åŒ–ï¼Œé•¿åºåˆ—ä¼˜åŠ¿ï¼ˆ+2.3%ï¼‰
- **è®¾è®¡å“²å­¦**ï¼šProgressive enhancementï¼Œæ¯ä¸ªPhaseè§£å†³ä¸€ä¸ªé—®é¢˜

### 4. ä¸ºä»€ä¹ˆPhase 3åœ¨é•¿åºåˆ—æ›´å¥½ï¼Ÿ
- çŸ­åºåˆ—ï¼ˆ<300 tokensï¼‰ï¼šç»Ÿè®¡æ ·æœ¬ä¸è¶³ï¼ŒåŽ†å²è°ƒæ•´æ— æ³•å‘æŒ¥
- é•¿åºåˆ—ï¼ˆâ‰¥500 tokensï¼‰ï¼šè¶³å¤Ÿæ ·æœ¬ â†’ å‡†ç¡®ä¼°è®¡æŽ¥å—çŽ‡ â†’ æœ‰æ•ˆè°ƒæ•´é˜ˆå€¼
- æ•°æ®æ”¯æ’‘ï¼š1000 tokensæ—¶+9.3% vs Fixed, 200 tokensæ—¶-3.8%

---

## ðŸ’¡ åˆ›æ–°ç‚¹æ€»ç»“

### ä¸ŽçŽ°æœ‰å·¥ä½œçš„åŒºåˆ«

| ç»´åº¦ | SpecInferç­‰ï¼ˆåŽ»å¹´ï¼‰ | **DynaTreeï¼ˆæˆ‘ä»¬ï¼‰** |
|-----|-------------------|---------------------|
| æ ‘ç»“æž„ | âœ… å›ºå®š(D, B) | âœ… **åŠ¨æ€**(Bâˆˆ{1,2,3}) |
| åˆ†æ”¯å†³ç­– | âŒ é™æ€é¢„è®¾ | âœ… **ç½®ä¿¡åº¦é©±åŠ¨** |
| æ·±åº¦æŽ§åˆ¶ | âŒ å›ºå®šæ·±åº¦ | âœ… **æ—©åœ+æ‰©å±•** |
| å‚æ•°ä¼˜åŒ– | âŒ ç¦»çº¿å›ºå®š | âœ… **è¿è¡Œæ—¶è°ƒæ•´** |
| é•¿åºåˆ—ä¼˜åŠ¿ | - | âœ… **+16.3%** (1000 tokens) |
| æŽ¥å—çŽ‡ | ~80% | âœ… **94.7%** |

**æ ¸å¿ƒåŒºåˆ«**ï¼šFixed â†’ **Adaptive** æ˜¯æœ¬è´¨åˆ›æ–°

---

## ðŸ”¬ å®žéªŒè®¾è®¡äº®ç‚¹

### 1. å®Œæ•´çš„Ablation Study
- å¯¹æ¯”3ä¸ªbase depthï¼ˆD=4/5/6ï¼‰
- é€æ­¥æ·»åŠ Phase 1 â†’ 2 â†’ 3
- æ¸…æ™°å±•ç¤ºæ¯ä¸ªcomponentçš„è´¡çŒ®

### 2. å…¨é¢çš„å‚æ•°æ•æ„Ÿæ€§åˆ†æž
- ç½®ä¿¡åº¦é˜ˆå€¼ï¼š(0.7/0.2), (0.8/0.3), (0.9/0.4)
- åˆ†æ”¯å› å­èŒƒå›´ï¼š[1,2], [1,3], [1,4], [2,4]
- å‘çŽ°ï¼šmin_branch=1 criticalï¼ˆ-18% if min=2ï¼‰

### 3. è·¨é•¿åº¦ScalabilityéªŒè¯
- 6ä¸ªç”Ÿæˆé•¿åº¦ï¼š100, 200, 300, 500, 750, 1000 tokens
- å‘çŽ°ï¼šâ‰¥500 tokensæ—¶Adaptiveæ˜¾è‘—é¢†å…ˆ
- è§£é‡Šï¼šåŽ†å²è°ƒæ•´éœ€è¦warm-up

### 4. è·¨æ•°æ®é›†Robustness
- WikiText-2ï¼ˆä¸»å®žéªŒï¼‰+ PG-19ï¼ˆéªŒè¯ï¼‰
- è¯æ˜Žæ–¹æ³•çš„æ³›åŒ–æ€§

---

## ðŸ“ˆ æ€§èƒ½æŒ‡æ ‡è§£é‡Š

### 1. Throughput (åžåé‡)
- **å®šä¹‰**ï¼šæ¯ç§’ç”Ÿæˆçš„tokenæ•°ï¼ˆtokens/secï¼‰
- **è®¡ç®—**ï¼šæ€»tokensæ•° / æ€»æ—¶é—´
- **æˆ‘ä»¬çš„æœ€ä½³**ï¼š210.8 t/s (Phase 3, 1000 tokens)
- **åŸºå‡†**ï¼š131.1 t/s (Autoregressive)

### 2. Speedup (åŠ é€Ÿæ¯”)
- **å®šä¹‰**ï¼šç›¸å¯¹äºŽAR baselineçš„å€æ•°
- **è®¡ç®—**ï¼šThroughput / Baseline_Throughput
- **æˆ‘ä»¬çš„æœ€ä½³**ï¼š1.61Ã— (Phase 3)
- **å¯¹æ¯”**ï¼šFixed Tree 1.38Ã—, Linear 1.02Ã—

### 3. Acceptance Rate (æŽ¥å—çŽ‡)
- **å®šä¹‰**ï¼šdrafted tokensä¸­è¢«targetæŽ¥å—çš„æ¯”ä¾‹
- **æ„ä¹‰**ï¼šåæ˜ draft-targetå¯¹é½ç¨‹åº¦
- **æˆ‘ä»¬çš„æœ€ä½³**ï¼š94.7% (Phase 3, 1000 tokens)
- **å¯¹æ¯”**ï¼šFixed Tree 80.8%, Linear 68.3%

### 4. Tokens per Iteration (æ¯è½®tokens)
- **å®šä¹‰**ï¼šæ¯æ¬¡éªŒè¯å¹³å‡commitçš„tokenæ•°
- **æ„ä¹‰**ï¼šåæ˜ æ¯è½®çš„"æ”¶èŽ·"
- **æˆ‘ä»¬çš„æœ€ä½³**ï¼š6.63 tokens/iter (Phase 3)
- **å¯¹æ¯”**ï¼šFixed Tree 5.65, Linear 4.10, AR 1.0

---

## ðŸš§ å·²çŸ¥é™åˆ¶å’Œæœªæ¥å·¥ä½œ

### å½“å‰é™åˆ¶
1. **æ¨¡åž‹è§„æ¨¡**ï¼šä»…åœ¨Pythia-2.8Bä¸Šæµ‹è¯•ï¼ŒæœªéªŒè¯æ›´å¤§æ¨¡åž‹ï¼ˆ7B, 13Bï¼‰
2. **æ•°æ®é›†**ï¼šä¸»è¦æ˜¯è‹±æ–‡æ–‡æœ¬ï¼Œæœªæµ‹è¯•ä»£ç ç”Ÿæˆã€å¤šè¯­è¨€
3. **Draft-Targetå¯¹**ï¼šä»…æµ‹è¯•Pythia-70Mâ†’2.8Bï¼Œæœªæµ‹è¯•å…¶ä»–ç»„åˆ
4. **ç¡¬ä»¶**ï¼šå•GPUå®žéªŒï¼Œæœªè¯„ä¼°åˆ†å¸ƒå¼åœºæ™¯

### æœªæ¥æ–¹å‘
1. **æ›´å¤§æ¨¡åž‹**ï¼šåœ¨Llama-2 7B/13Bä¸ŠéªŒè¯
2. **æ›´å¤šåœºæ™¯**ï¼šä»£ç ç”Ÿæˆï¼ˆHumanEvalï¼‰ã€é•¿æ–‡æœ¬ï¼ˆbooksumï¼‰
3. **ç³»ç»Ÿä¼˜åŒ–**ï¼šKernel-levelä¼˜åŒ–ï¼Œå‡å°‘overhead
4. **ç†è®ºåˆ†æž**ï¼šAdaptive branchingçš„ç†è®ºåŠ é€Ÿç•Œ
5. **åœ¨çº¿å­¦ä¹ **ï¼šæ›´å¤æ‚çš„å‚æ•°è°ƒæ•´ç­–ç•¥ï¼ˆRL-basedï¼‰

---

## ðŸ› ï¸ å¦‚ä½•è¿è¡Œä»£ç 

### çŽ¯å¢ƒå‡†å¤‡
```bash
# å®‰è£…ä¾èµ–
pip install torch transformers matplotlib numpy seaborn

# ç¡®è®¤æ¨¡åž‹è·¯å¾„
ls /mnt/disk1/models/pythia-2.8b
ls /mnt/disk1/models/pythia-70m
```

### è¿è¡Œä¸»å®žéªŒ
```bash
cd /root/LLM-Efficient-Reasoning

# Phase 3ä¸»å®žéªŒï¼ˆ1000 tokensï¼‰
python papers/benchmark_adaptive_paper.py

# æ¶ˆèžå®žéªŒï¼ˆ500 tokensï¼‰
python papers/benchmark_adaptive_full.py --mode ablation

# å‚æ•°æ•æ„Ÿæ€§
python papers/benchmark_adaptive_full.py --mode sensitivity

# å¯æ‰©å±•æ€§
python papers/benchmark_adaptive_full.py --mode scalability
```

### ç”Ÿæˆå›¾è¡¨
```bash
# æ ‘é…ç½®çƒ­åŠ›å›¾
python plot_tree_config_heatmap.py

# æ•°æ®é›†å¯¹æ¯”
python plot_dataset_comparison.py

# é•¿åº¦æ‰©å±•
python plot_length_scaling.py

# Prompté•¿åº¦å½±å“
python plot_prompt_length_impact.py
```

---

## ðŸ“Š é‡è¦æ•°æ®é€ŸæŸ¥

### ä¸»å®žéªŒå…³é”®æ•°æ®ï¼ˆè®°ä½è¿™äº›ï¼ï¼‰
```
è®¾ç½®ï¼šWikiText-2, 1000 tokens, Pythia-2.8B + 70M

Baseline AR:     131.1 t/s  (1.00Ã—)
Fixed Tree:      181.3 t/s  (1.38Ã—, 80.8% accept)
Adaptive Phase 3: 210.8 t/s (1.61Ã—, 94.7% accept)

æå‡ï¼š+16.3% vs Fixed Tree
```

### æœ€ä¼˜é…ç½®å‚æ•°
```python
# Adaptive Tree Phase 3
high_conf_threshold = 0.9
low_conf_threshold = 0.4
min_branch = 1
max_branch = 3
base_depth = 5
max_depth = 8
learning_rate = 0.01
target_accept_rate = 0.85
```

### å„Phaseè´¡çŒ®
```
Baseline â†’ Fixed:  +38.3% (131.1 â†’ 181.3)
Fixed â†’ Phase 1:   -2.5%  (181.3 â†’ 176.7)
Phase 1 â†’ Phase 2: +16.6% (176.7 â†’ 206.0)
Phase 2 â†’ Phase 3: +2.3%  (206.0 â†’ 210.8)

Total: +60.8% (131.1 â†’ 210.8)
```

---

## ðŸ“š ç›¸å…³æ–‡çŒ®

1. **Leviathan et al.**, "Fast Inference from Transformers via Speculative Decoding", ICML 2023
   - æå‡ºLinear Speculative Decoding

2. **Miao et al.**, "SpecInfer: Accelerating Generative Large Language Model Serving with Tree-based Speculative Inference", 2024
   - Tree-basedæ–¹æ³•ï¼Œä½†ä½¿ç”¨Fixed tree

3. **Xiao et al.**, "Efficient Streaming Language Models with Attention Sinks", ICLR 2024
   - StreamingLLMï¼Œæˆ‘ä»¬ä¹Ÿæµ‹è¯•äº†ç»“åˆæ–¹æ¡ˆ

4. **Chen et al.**, "Accelerating Large Language Model Decoding with Speculative Sampling", 2023
   - æ—©æœŸæŠ•æœºè§£ç å·¥ä½œ

---

## ðŸŽ¯ é¡¹ç›®ä»·å€¼

### å­¦æœ¯ä»·å€¼
- âœ… **åŽŸåˆ›åˆ›æ–°**ï¼šConfidence-aware adaptive branchingæ˜¯æ–°çš„
- âœ… **å®žéªŒå……åˆ†**ï¼šAblation + Sensitivity + Scalability
- âœ… **æ€§èƒ½ä¼˜å¼‚**ï¼š1.61Ã— speedup, 94.7% acceptance
- âœ… **å¯å¤çŽ°**ï¼šå®Œæ•´ä»£ç å’Œå®žéªŒè„šæœ¬

### å·¥ç¨‹ä»·å€¼
- âœ… **å³æ’å³ç”¨**ï¼šå¯é›†æˆåˆ°çŽ°æœ‰LLM servingç³»ç»Ÿ
- âœ… **Training-free**ï¼šæ— éœ€é¢å¤–è®­ç»ƒæˆ–å¾®è°ƒ
- âœ… **å†…å­˜é«˜æ•ˆ**ï¼š<1% memory overhead
- âœ… **é€šç”¨æ€§å¼º**ï¼šé€‚ç”¨äºŽä»»ä½•autoregressive LLM

### è¯¾ç¨‹ä½œä¸šä»·å€¼
- âœ… **å·¥ä½œé‡å……åˆ†**ï¼š650è¡Œæ ¸å¿ƒä»£ç  + 18ç»„å®žéªŒ
- âœ… **åˆ›æ–°ç‚¹æ¸…æ™°**ï¼šä¸ŽSpecInferç­‰å·¥ä½œæ˜Žç¡®åŒºåˆ†
- âœ… **ç»“æžœå®Œæ•´**ï¼šè®ºæ–‡draft + å®žéªŒæ•°æ® + ä»£ç å®žçŽ°

---

## ðŸ¤ å›¢é˜Ÿå’Œæ—¶é—´çº¿

### å¼€å‘æ—¶é—´çº¿
- **2025-12-15 ~ 2025-12-30**ï¼šFixed Treeå®žçŽ° + åŸºç¡€å®žéªŒ
- **2025-12-31 ~ 2026-01-03**ï¼šAdaptiveæœºåˆ¶è®¾è®¡ + å‚æ•°æœç´¢
- **2026-01-04**ï¼šAdaptiveå®Œæ•´å®žéªŒï¼ˆmain + ablation + sensitivity + scalabilityï¼‰
- **2026-01-05**ï¼šè®ºæ–‡ä¿®æ”¹è·¯çº¿å›¾åˆ¶å®š
- **2026-01-XX**ï¼šè®ºæ–‡ä¿®æ”¹å®Œæˆï¼ˆé¢„è®¡ï¼‰

### å·¥ä½œåˆ†å·¥
- **æˆå‘˜A**ï¼šæ ‘ç»“æž„å®žçŽ° + éªŒè¯æ­£ç¡®æ€§
- **æˆå‘˜B**ï¼šAdaptiveæœºåˆ¶ + å®žéªŒä»£ç 
- **æˆå‘˜C**ï¼šè®ºæ–‡æ’°å†™ + æ•°æ®åˆ†æž

---

## ðŸ“§ è”ç³»æ–¹å¼

**ä½œè€…**ï¼š
- Nuoyan Chen (cny123222@sjtu.edu.cn)
- Jiamin Liu (logic-1.0@sjtu.edu.cn)
- Zhaocheng Li (lzc050419@sjtu.edu.cn)

**æœºæž„**ï¼šä¸Šæµ·äº¤é€šå¤§å­¦ è®¡ç®—æœºç§‘å­¦ä¸Žå·¥ç¨‹ç³»

---

## ðŸ“ å¿«é€ŸFAQ

### Q1: è¿™ä¸ªé¡¹ç›®çš„æ ¸å¿ƒåˆ›æ–°æ˜¯ä»€ä¹ˆï¼Ÿ
**A**: Confidence-aware adaptive branching - æ ¹æ®draft modelçš„é¢„æµ‹ç½®ä¿¡åº¦åŠ¨æ€è°ƒæ•´æ ‘çš„åˆ†æ”¯å› å­ï¼Œè€Œä¸æ˜¯ä½¿ç”¨å›ºå®šçš„åˆ†æ”¯æ•°ã€‚

### Q2: ä¸ºä»€ä¹ˆPhase 1ä¼šæ¯”Fixed Treeæ…¢ï¼Ÿ
**A**: å› ä¸ºconfidence computationæœ‰å¼€é”€ï¼Œä½†è¿˜æ²¡æœ‰é€šè¿‡depth controlæ¥è¡¥å¿ã€‚Phase 2é€šè¿‡early stoppingå’Œdeep expansionè¡¥å¿å¹¶è¶…è¶Šã€‚

### Q3: ä¸ºä»€ä¹ˆé•¿åºåˆ—æ—¶Adaptiveæ›´å¥½ï¼Ÿ
**A**: Phase 3çš„åŽ†å²è°ƒæ•´æœºåˆ¶éœ€è¦è¶³å¤Ÿçš„ç»Ÿè®¡æ ·æœ¬ï¼ˆâ‰¥500 tokensï¼‰æ‰èƒ½æœ‰æ•ˆä¼˜åŒ–å‚æ•°ã€‚çŸ­åºåˆ—æ—¶æ ·æœ¬ä¸è¶³ï¼Œè°ƒæ•´ä¸å‡†ç¡®ã€‚

### Q4: å¦‚ä½•é€‰æ‹©æœ€ä¼˜é…ç½®ï¼Ÿ
**A**: 
- çŸ­åºåˆ—ï¼ˆ<500 tokensï¼‰ï¼šFixed Treeæˆ–Phase 2
- é•¿åºåˆ—ï¼ˆâ‰¥500 tokensï¼‰ï¼šPhase 3ï¼ˆ0.9/0.4/1/3é…ç½®ï¼‰
- èµ„æºå—é™ï¼šPhase 2 + æµ…æ ‘ï¼ˆD=4ï¼‰

### Q5: è¿™ä¸ªæ–¹æ³•å¯ä»¥ç”¨åœ¨å“ªäº›åœºæ™¯ï¼Ÿ
**A**: ä»»ä½•éœ€è¦å¿«é€Ÿç”Ÿæˆæ–‡æœ¬çš„åœºæ™¯ï¼š
- èŠå¤©æœºå™¨äººï¼ˆå¯¹è¯ç”Ÿæˆï¼‰
- æ–‡ç« ç”Ÿæˆï¼ˆé•¿æ–‡æœ¬ï¼‰
- ä»£ç è¡¥å…¨ï¼ˆä»£ç ç”Ÿæˆï¼‰
- æœºå™¨ç¿»è¯‘ï¼ˆåºåˆ—è½¬æ¢ï¼‰

---

**æ–‡æ¡£ç‰ˆæœ¬**ï¼šv1.0  
**æœ€åŽæ›´æ–°**ï¼š2026-01-05  
**çŠ¶æ€**ï¼šâœ… å®Œæ•´

---

å¸Œæœ›è¿™ä¸ªæ–‡æ¡£èƒ½å¸®åŠ©ä½ çš„AIå¿«é€Ÿç†è§£æ•´ä¸ªé¡¹ç›®ï¼å¦‚æœ‰ä»»ä½•é—®é¢˜ï¼Œæ¬¢è¿Žè”ç³»ã€‚ðŸš€

