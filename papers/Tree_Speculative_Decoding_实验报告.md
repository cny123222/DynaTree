# Tree-based Speculative Decoding å®éªŒæŠ¥å‘Š

## ğŸ“‹ æ¦‚è¿°

æœ¬æŠ¥å‘Šè®°å½•äº† Tree-based Speculative Decoding (æ ‘å½¢æŠ•æœºè§£ç ) çš„å®éªŒè¿‡ç¨‹å’Œç»“æœã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨æœ€ä¼˜å‚æ•°é…ç½®ä¸‹ï¼ŒTree V2 æ–¹æ³•å®ç°äº† **1.62x åŠ é€Ÿæ¯”**ï¼Œæ˜¾è‘—ä¼˜äº HuggingFace åŸç”Ÿ Assisted Generation (1.36x) å’Œ Linear Speculative Decoding (1.11x)ã€‚

---

## 1. å®éªŒç¯å¢ƒ

### 1.1 ç¡¬ä»¶é…ç½®

| é¡¹ç›® | é…ç½® |
|------|------|
| GPU | NVIDIA GPU (CUDA) |
| æ˜¾å­˜ | è¶³å¤Ÿè¿è¡Œ Pythia-2.8B + Pythia-70M |
| ç³»ç»Ÿ | Linux 5.15.0-126-generic |

### 1.2 è½¯ä»¶ç¯å¢ƒ

| é¡¹ç›® | ç‰ˆæœ¬ |
|------|------|
| Python | 3.x |
| PyTorch | 2.0+ (æ”¯æŒ torch.compile) |
| Transformers | 4.x (æ”¯æŒ DynamicCache) |
| CUDA | å…¼å®¹ç‰ˆæœ¬ |

### 1.3 æ¨¡å‹é…ç½®

| æ¨¡å‹è§’è‰² | æ¨¡å‹åç§° | å‚æ•°é‡ | è·¯å¾„ |
|---------|---------|--------|------|
| Target Model | Pythia-2.8B | 2.8B | `/mnt/disk1/models/pythia-2.8b` |
| Draft Model | Pythia-70M | 70M | `/mnt/disk1/models/pythia-70m` |

---

## 2. å®éªŒæ–¹æ³•

### 2.1 æµ‹è¯•æ–¹æ³•åˆ—è¡¨

æœ¬å®éªŒå¯¹æ¯”äº†ä»¥ä¸‹ 7 ç§æ¨ç†æ–¹æ³•ï¼š

1. **Baseline (AR)** - çº¯è‡ªå›å½’ç”Ÿæˆï¼Œä½œä¸ºåŸºå‡†
2. **HuggingFace Assisted Generation** - HuggingFace å®˜æ–¹å®ç°çš„è¾…åŠ©ç”Ÿæˆ
3. **Linear Speculative Decoding** - çº¿æ€§æŠ•æœºè§£ç  (K=5,6,7,8)
4. **Tree V2 Speculative Decoding** - æ ‘å½¢æŠ•æœºè§£ç  V2 ç‰ˆæœ¬
5. **StreamingLLM + Spec Decode** - ç»“åˆ StreamingLLM çš„æŠ•æœºè§£ç 

### 2.2 Tree-based Speculative Decoding åŸç†

Tree-based Speculative Decoding çš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

```
ä¼ ç»Ÿ Linear æ–¹æ³•:
  Draft æ¨¡å‹ç”Ÿæˆ: t1 -> t2 -> t3 -> t4 -> t5 (çº¿æ€§åºåˆ—)
  Target éªŒè¯: é€ä¸ªéªŒè¯

Tree-based æ–¹æ³•:
  Draft æ¨¡å‹ç”Ÿæˆæ ‘å½¢ç»“æ„:
                    t1
                 /  |  \
               t2a t2b t2c
              / |   |   | \
           t3a t3b t3c t3d t3e
           ...

  Target ä¸€æ¬¡éªŒè¯æ•´æ£µæ ‘çš„æ‰€æœ‰åˆ†æ”¯
```

**ä¼˜åŠ¿ï¼š**
- å¹¶è¡ŒéªŒè¯å¤šä¸ªå€™é€‰è·¯å¾„
- æé«˜æ‰¾åˆ°æ­£ç¡® token åºåˆ—çš„æ¦‚ç‡
- æ›´å……åˆ†åˆ©ç”¨ GPU å¹¶è¡Œè®¡ç®—èƒ½åŠ›

### 2.3 å…³é”®å‚æ•°è¯´æ˜

| å‚æ•° | å«ä¹‰ | æœ€ä¼˜å€¼ |
|------|------|--------|
| **D (tree_depth)** | æ ‘çš„æœ€å¤§æ·±åº¦ | 8 |
| **B (branch_factor)** | æ¯ä¸ªèŠ‚ç‚¹çš„åˆ†æ”¯æ•° | 3 |
| **t (probability_threshold)** | æ¦‚ç‡å‰ªæé˜ˆå€¼ | 0.03 |

---

## 3. å®éªŒé…ç½®

### 3.1 å‚æ•°æœç´¢é…ç½®

```python
# å‚æ•°æœç´¢èŒƒå›´
depths = [3, 4, 5, 6, 7, 8]      # æ ‘æ·±åº¦
branches = [2, 3, 4]             # åˆ†æ”¯å› å­
thresholds = [0.01, 0.02, 0.03, 0.05, 0.1]  # æ¦‚ç‡é˜ˆå€¼
token_lengths = [100, 200, 300, 500, 1000]  # ç”Ÿæˆé•¿åº¦

# æ€»é…ç½®æ•°: 6 Ã— 3 Ã— 5 Ã— 5 = 450 ç§ç»„åˆ
```

### 3.2 æ€§èƒ½æµ‹è¯•é…ç½®

```python
MAX_NEW_TOKENS = 500        # ç”Ÿæˆ token æ•°
NUM_RUNS = 5                # æ¯ä¸ªæ–¹æ³•è¿è¡Œæ¬¡æ•°
SKIP_FIRST = True           # è·³è¿‡é¦–æ¬¡ warmup
WARMUP_ROUNDS = 10          # é¢„çƒ­è½®æ•°

# æµ‹è¯• prompt
PROMPT = """Write a detailed technical explanation about the development 
of large language models. Cover the history, architecture innovations, 
training techniques, and future directions..."""
```

### 3.3 æœ€ä¼˜ Tree V2 é…ç½®

```python
TREE_DEPTH = 8              # æ ‘æ·±åº¦
TREE_BRANCH = 3             # åˆ†æ”¯å› å­  
TREE_THRESHOLD = 0.03       # æ¦‚ç‡é˜ˆå€¼
MAX_TREE_NODES = 128        # æœ€å¤§æ ‘èŠ‚ç‚¹æ•°
```

---

## 4. å®éªŒè„šæœ¬

### 4.1 å‚æ•°æœç´¢è„šæœ¬

**è·¯å¾„**: `papers/tree_param_search.py`

```python
# æ ¸å¿ƒæœç´¢é€»è¾‘
for depth in depths:
    for branch in branches:
        for threshold in thresholds:
            for tokens in token_lengths:
                # åˆ›å»º Tree V2 ç”Ÿæˆå™¨
                gen = TreeSpeculativeGeneratorV2(
                    target_model, draft_model, tokenizer,
                    tree_depth=depth,
                    branch_factor=branch,
                    probability_threshold=threshold,
                    max_tree_nodes=128
                )
                
                # æµ‹é‡æ€§èƒ½
                throughput, stats = measure_performance(gen, tokens)
                
                # è®°å½•ç»“æœ
                results.append({
                    'depth': depth,
                    'branch': branch,
                    'threshold': threshold,
                    'tokens': tokens,
                    'throughput': throughput,
                    'speedup': throughput / baseline
                })
```

**è¿è¡Œå‘½ä»¤**:
```bash
cd /mnt/disk1/ljm/LLM-Efficient-Reasoning
python papers/tree_param_search.py
```

### 4.2 æ€§èƒ½å¯¹æ¯”è„šæœ¬

**è·¯å¾„**: `papers/benchmark_optimal_config.py`

```python
# æµ‹è¯•æ‰€æœ‰æ–¹æ³•
methods = [
    ("Baseline", run_baseline),
    ("HF Assisted", run_hf_assisted),
    ("Linear K=5", run_linear_k5),
    ("Linear K=6", run_linear_k6),
    ("Linear K=7", run_linear_k7),
    ("Linear K=8", run_linear_k8),
    ("Tree V2 D=8 B=3 t=0.03", run_tree_v2),
    ("Streaming K=6 cache=512", run_streaming_512),
    ("Streaming K=6 cache=1024", run_streaming_1024),
]

for name, run_fn in methods:
    results = []
    for i in range(NUM_RUNS):
        cleanup()
        torch.cuda.synchronize()
        start = time.perf_counter()
        tokens, stats = run_fn()
        elapsed = time.perf_counter() - start
        throughput = tokens / elapsed
        if i > 0:  # è·³è¿‡é¦–æ¬¡ warmup
            results.append(throughput)
    
    avg_throughput = sum(results) / len(results)
    print(f"{name}: {avg_throughput:.1f} t/s")
```

**è¿è¡Œå‘½ä»¤**:
```bash
cd /mnt/disk1/ljm/LLM-Efficient-Reasoning
python papers/benchmark_optimal_config.py
```

### 4.3 ç»“æœåˆ†æè„šæœ¬

**è·¯å¾„**: `papers/analyze_tree_search_results.py`

```python
# åˆ†æå‚æ•°æœç´¢ç»“æœ
def analyze_results(json_path):
    with open(json_path, 'r') as f:
        data = json.load(f)
    
    results = data['results']
    
    # æŒ‰åŠ é€Ÿæ¯”æ’åº
    sorted_results = sorted(results, key=lambda x: x['speedup'], reverse=True)
    
    # è¾“å‡º Top 10
    print("Top 10 é…ç½®:")
    for i, r in enumerate(sorted_results[:10]):
        print(f"{i+1}. D={r['depth']} B={r['branch']} t={r['threshold']}")
        print(f"   {r['speedup']:.2f}x ({r['throughput']:.1f} t/s)")
```

**è¿è¡Œå‘½ä»¤**:
```bash
cd /mnt/disk1/ljm/LLM-Efficient-Reasoning
python papers/analyze_tree_search_results.py results/tree_param_search_20251231_140952.json
```

---

## 5. å®éªŒç»“æœ

### 5.1 å‚æ•°æœç´¢ç»“æœ

å‚æ•°æœç´¢å…±æµ‹è¯•äº† 450 ç§é…ç½®ç»„åˆï¼Œç»“æœä¿å­˜åœ¨:
`results/tree_param_search_20251231_140952.json`

#### 5.1.1 Top 10 æœ€ä¼˜é…ç½®

| æ’å | Tokens | D | B | t | ååé‡ | Baseline | åŠ é€Ÿæ¯” |
|-----|--------|---|---|------|--------|----------|--------|
| 1 | 500 | 8 | 3 | 0.03 | 221.4 t/s | 123.9 t/s | **1.79x** |
| 2 | 500 | 7 | 3 | 0.03 | 217.4 t/s | 123.9 t/s | 1.76x |
| 3 | 500 | 8 | 3 | 0.02 | 217.2 t/s | 123.9 t/s | 1.75x |
| 4 | 500 | 8 | 4 | 0.02 | 212.5 t/s | 123.9 t/s | 1.72x |
| 5 | 500 | 6 | 3 | 0.03 | 212.1 t/s | 123.9 t/s | 1.71x |
| 6 | 1000 | 6 | 3 | 0.05 | 212.3 t/s | 124.5 t/s | 1.71x |
| 7 | 1000 | 6 | 3 | 0.10 | 211.2 t/s | 124.5 t/s | 1.70x |
| 8 | 500 | 7 | 3 | 0.02 | 209.5 t/s | 123.9 t/s | 1.69x |
| 9 | 1000 | 7 | 3 | 0.10 | 210.0 t/s | 124.5 t/s | 1.69x |
| 10 | 1000 | 8 | 2 | 0.10 | 208.7 t/s | 124.5 t/s | 1.68x |

#### 5.1.2 å„ Token é•¿åº¦æœ€ä¼˜é…ç½®

| Token é•¿åº¦ | æœ€ä¼˜é…ç½® | ååé‡ | åŠ é€Ÿæ¯” |
|-----------|----------|--------|--------|
| 100 | D=7, B=3, t=0.03 | 150.7 t/s | 1.43x |
| 200 | D=7, B=3, t=0.03 | 193.2 t/s | 1.54x |
| 300 | D=7, B=3, t=0.03 | 199.0 t/s | 1.60x |
| **500** | **D=8, B=3, t=0.03** | **221.4 t/s** | **1.79x** |
| 1000 | D=6, B=3, t=0.05 | 212.3 t/s | 1.71x |

#### 5.1.3 å‚æ•°æ•æ„Ÿæ€§åˆ†æ

**Branch Factor (B) çš„å½±å“:**
| B | å¹³å‡åŠ é€Ÿæ¯” | æœ€å¤§åŠ é€Ÿæ¯” |
|---|-----------|-----------|
| 2 | 1.11x | 1.68x |
| **3** | **1.31x** | **1.79x** |
| 4 | 1.19x | 1.72x |

**ç»“è®º**: B=3 æ˜¯æœ€ä¼˜åˆ†æ”¯å› å­

**Probability Threshold (t) çš„å½±å“:**
| t | å¹³å‡åŠ é€Ÿæ¯” | æœ€å¤§åŠ é€Ÿæ¯” |
|---|-----------|-----------|
| 0.01 | 1.09x | 1.57x |
| 0.02 | 1.28x | 1.75x |
| **0.03** | **1.31x** | **1.79x** |
| 0.05 | 1.17x | 1.71x |
| 0.10 | 1.19x | 1.70x |

**ç»“è®º**: t=0.03 æ˜¯æœ€ä¼˜é˜ˆå€¼

### 5.2 æ€§èƒ½å¯¹æ¯”ç»“æœ

åœ¨ 500 tokensã€æœ€ä¼˜é…ç½® (D=8, B=3, t=0.03) ä¸‹çš„æ€§èƒ½å¯¹æ¯”ï¼š

| æ’å | æ–¹æ³• | ååé‡ | åŠ é€Ÿæ¯” | å¤‡æ³¨ |
|-----|------|--------|--------|------|
| ğŸ¥‡ | **Tree V2 (D=8, B=3, t=0.03)** | **193.4 t/s** | **1.62x** | æœ€ä¼˜ |
| ğŸ¥ˆ | HuggingFace Assisted | 161.9 t/s | 1.36x | å®˜æ–¹å®ç° |
| ğŸ¥‰ | Linear K=6 | 133.1 t/s | 1.11x | è‡ªå®šä¹‰å®ç° |
| 4 | Streaming K=6 cache=1024 | 132.9 t/s | 1.11x | StreamingLLM |
| 5 | Linear K=7 | 131.9 t/s | 1.10x | |
| 6 | Linear K=8 | 128.9 t/s | 1.08x | |
| 7 | Linear K=5 | 125.2 t/s | 1.05x | |
| 8 | Baseline (AR) | 119.4 t/s | 1.00x | åŸºå‡† |
| 9 | Streaming K=6 cache=512 | 114.2 t/s | 0.96x | å¼€é”€è¿‡å¤§ |

### 5.3 è¯¦ç»†è¿è¡Œæ•°æ®

#### Tree V2 (D=8, B=3, t=0.03)
```
Run 1: 500 tokens, 2.83s, 176.8 t/s (warmup, è·³è¿‡)
Run 2: 500 tokens, 2.57s, 194.5 t/s
Run 3: 500 tokens, 2.59s, 192.9 t/s
Run 4: 500 tokens, 2.60s, 192.3 t/s
Run 5: 500 tokens, 2.58s, 194.1 t/s
>>> å¹³å‡: 193.4 t/s (1.62x)
    æ¥å—ç‡: 29.6%
```

#### HuggingFace Assisted
```
Run 1: 500 tokens, 3.16s, 158.2 t/s (warmup, è·³è¿‡)
Run 2: 500 tokens, 3.08s, 162.3 t/s
Run 3: 500 tokens, 3.10s, 161.2 t/s
Run 4: 500 tokens, 3.10s, 161.4 t/s
Run 5: 500 tokens, 3.08s, 162.6 t/s
>>> å¹³å‡: 161.9 t/s (1.36x)
```

#### Linear K=6
```
Run 1: 500 tokens, 4.04s, 123.9 t/s (warmup, è·³è¿‡)
Run 2: 500 tokens, 3.76s, 132.8 t/s
Run 3: 500 tokens, 3.76s, 133.0 t/s
Run 4: 500 tokens, 3.75s, 133.2 t/s
Run 5: 500 tokens, 3.76s, 133.1 t/s
>>> å¹³å‡: 133.1 t/s (1.11x)
    æ¥å—ç‡: 68.3%, æ¯è½® tokens: 4.10
```

---

## 6. ç»“è®ºä¸åˆ†æ

### 6.1 æ ¸å¿ƒå‘ç°

1. **Tree V2 æ˜¯æœ€å¿«çš„æ–¹æ³•**
   - å®ç°äº† **1.62x åŠ é€Ÿæ¯”** (193.4 t/s)
   - æ¯” HuggingFace å®˜æ–¹å®ç°å¿« **19%**
   - æ¯” Linear æ–¹æ³•å¿« **45%**

2. **æœ€ä¼˜å‚æ•°é…ç½®**
   - æ ‘æ·±åº¦ D = 8
   - åˆ†æ”¯å› å­ B = 3
   - æ¦‚ç‡é˜ˆå€¼ t = 0.03
   - ç”Ÿæˆé•¿åº¦ = 500 tokens

3. **Tree V2 çš„ä¼˜åŠ¿æ¥æº**
   - å¹¶è¡ŒéªŒè¯å¤šä¸ªå€™é€‰åˆ†æ”¯
   - æ¦‚ç‡å‰ªæå‡å°‘æ— æ•ˆè®¡ç®—
   - æ›´é«˜æ•ˆåˆ©ç”¨ GPU å¹¶è¡Œèƒ½åŠ›

### 6.2 æ–¹æ³•å¯¹æ¯”æ€»ç»“

| æ–¹æ³• | åŠ é€Ÿæ¯” | ä¼˜ç‚¹ | ç¼ºç‚¹ |
|------|--------|------|------|
| **Tree V2** | **1.62x** | æœ€å¿«ã€å¯å®šåˆ¶ | å®ç°å¤æ‚ |
| HF Assisted | 1.36x | å®˜æ–¹æ”¯æŒã€ç¨³å®š | ä¸å¯å®šåˆ¶ |
| Linear | 1.11x | ç®€å•ã€æ˜“ç†è§£ | åŠ é€Ÿæœ‰é™ |
| Streaming | 1.11x | æ”¯æŒé•¿åºåˆ— | çŸ­åºåˆ—å¼€é”€å¤§ |

### 6.3 é€‚ç”¨åœºæ™¯å»ºè®®

| åœºæ™¯ | æ¨èæ–¹æ³• | ç†ç”± |
|------|----------|------|
| è¿½æ±‚æœ€å¤§é€Ÿåº¦ | Tree V2 (D=8, B=3, t=0.03) | åŠ é€Ÿæ¯”æœ€é«˜ |
| ç”Ÿäº§ç¯å¢ƒç¨³å®šæ€§ | HuggingFace Assisted | å®˜æ–¹ç»´æŠ¤ã€ç¨³å®š |
| è¶…é•¿åºåˆ—ç”Ÿæˆ | Streaming + Spec Decode | å†…å­˜æ•ˆç‡é«˜ |
| å¿«é€ŸåŸå‹éªŒè¯ | Linear K=6 | å®ç°ç®€å• |

### 6.4 æœªæ¥ä¼˜åŒ–æ–¹å‘

1. **åŠ¨æ€å‚æ•°è°ƒæ•´** - æ ¹æ®ç”Ÿæˆå†…å®¹åŠ¨æ€è°ƒæ•´æ ‘ç»“æ„
2. **torch.compile ä¼˜åŒ–** - åˆ©ç”¨ PyTorch 2.0 ç¼–è¯‘åŠ é€Ÿ
3. **æ›´å¤§æ¨¡å‹éªŒè¯** - åœ¨ 7Bã€13B æ¨¡å‹ä¸ŠéªŒè¯æ•ˆæœ

---

## 7. æ‰©å±•å®éªŒï¼šé‡åŒ–ä¸ StreamingLLM

### 7.1 INT8 é‡åŒ–æµ‹è¯•

**ç›®çš„**: è¯„ä¼° INT8 é‡åŒ–å¯¹ Tree V2 æ€§èƒ½çš„å½±å“

**æµ‹è¯•é…ç½®**:
- Target æ¨¡å‹: Pythia-2.8B (INT8 via bitsandbytes)
- Draft æ¨¡å‹: Pythia-70M (ä¿æŒ FP16)
- é‡åŒ–æ–¹æ³•: bitsandbytes INT8

**ç»“æœ**:

| ç²¾åº¦ | Tokens | ååé‡ | æ¥å—ç‡ | å†…å­˜å³°å€¼ | é€Ÿåº¦æ¯” |
|------|--------|--------|--------|----------|--------|
| FP16 | 100 | 61.9 t/s | 25.0% | 5557 MB | 1.00x |
| FP16 | 300 | 172.7 t/s | 28.2% | 5653 MB | 1.00x |
| FP16 | 500 | 194.5 t/s | 29.6% | 5726 MB | 1.00x |
| INT8 | 100 | 36.1 t/s | 25.0% | 3172 MB | 0.58x |
| INT8 | 300 | 57.4 t/s | 30.2% | 3256 MB | 0.33x |
| INT8 | 500 | 65.6 t/s | 30.4% | 3341 MB | 0.34x |

**ç»“è®º**:
- âŒ **INT8 é‡åŒ–å¯¼è‡´æ˜¾è‘—é™é€Ÿ** (0.33-0.58x)
- âœ“ **å†…å­˜èŠ‚çœçº¦ 42%**
- âœ“ **æ¥å—ç‡åŸºæœ¬ä¸å˜**
- **å»ºè®®**: åœ¨å½“å‰ç¡¬ä»¶ä¸Šç»§ç»­ä½¿ç”¨ FP16ï¼ŒINT8 çš„åé‡åŒ–å¼€é”€è¿‡å¤§

### 7.2 Tree V2 + StreamingLLM æµ‹è¯•

**ç›®çš„**: è¯„ä¼° `TreeStreamingSpeculativeGeneratorV2` åœ¨ä¸åŒåºåˆ—é•¿åº¦ä¸‹çš„è¡¨ç°

**æµ‹è¯•é…ç½®**:
- Tree V2: D=8, B=3, t=0.03
- StreamingLLM Cache å¤§å°: 512, 1024, 2048
- æµ‹è¯•é•¿åº¦: 500, 1000, 2000 tokens

**ç»“æœ**:

| æ–¹æ³• | Tokens | ååé‡ | vs Baseline | å†…å­˜ | å‹ç¼©æ¬¡æ•° |
|------|--------|--------|-------------|------|----------|
| Tree V2 (baseline) | 500 | 135.9 t/s | 1.00x | 5715 MB | 0 |
| + Streaming (cache=512) | 500 | 99.4 t/s | 0.73x | 5959 MB | 42 |
| + Streaming (cache=1024) | 500 | 136.5 t/s | 1.00x | 5715 MB | 0 |
| + Streaming (cache=2048) | 500 | 136.2 t/s | 1.00x | 5715 MB | 0 |
| Tree V2 (baseline) | 1000 | 179.2 t/s | 1.00x | 5932 MB | 0 |
| + Streaming (cache=512) | 1000 | 50.6 t/s | 0.28x | 5979 MB | 330 |
| + Streaming (cache=1024) | 1000 | 134.6 t/s | 0.75x | 6453 MB | 44 |
| + Streaming (cache=2048) | 1000 | 179.9 t/s | 1.00x | 5931 MB | 0 |
| Tree V2 (baseline) | 2000 | 167.9 t/s | 1.00x | 6326 MB | 0 |
| + Streaming (cache=512) | 2000 | 52.9 t/s | 0.32x | 5981 MB | 605 |
| + Streaming (cache=1024) | 2000 | 64.4 t/s | 0.38x | 6461 MB | 450 |
| **+ Streaming (cache=2048)** | **2000** | **208.3 t/s** | **1.24x** | 7395 MB | 5 |

**å…³é”®å‘ç°**:
1. **çŸ­åºåˆ— (500 tokens)**: cacheâ‰¥1024 æ— æ€§èƒ½æŸå¤±
2. **ä¸­ç­‰åºåˆ— (1000 tokens)**: ä»… cache=2048 æ— æŸ
3. **é•¿åºåˆ— (2000 tokens)**: cache=2048 **åè€Œæé€Ÿ 24%** (208.3 vs 167.9 t/s)

**ç»“è®º**:
- âœ“ **StreamingLLM åœ¨é•¿åºåˆ— (â‰¥2000) ä¸‹æœ‰æ˜¾è‘—ä¼˜åŠ¿**
- âœ“ **è¾ƒå¤§çš„ cache (2048) å¯ä»¥æå‡é•¿åºåˆ—æ€§èƒ½**
- âš  **å° cache é¢‘ç¹å‹ç¼©ä¼šä¸¥é‡å½±å“æ€§èƒ½**
- **æ¨è**: é•¿åºåˆ—ç”Ÿæˆä½¿ç”¨ `TreeStreamingSpeculativeGeneratorV2` + cache=2048

### 7.4 å…¨é¢æ€§èƒ½å¯¹æ¯” (Baseline vs Linear vs Tree)

**æµ‹è¯•é…ç½®**: å¯¹æ¯”çº¯è‡ªå›å½’ Baselineã€Linear Spec Decodeã€Tree V2 åœ¨ä¸åŒåºåˆ—é•¿åº¦ä¸‹çš„è¡¨ç°

#### 500 Tokens ç»“æœ

| æ’å | æ–¹æ³• | ååé‡ | åŠ é€Ÿæ¯” | æ¥å—ç‡ |
|-----|------|--------|--------|--------|
| ğŸ¥‡ | Tree D=8 B=2 t=0.05 + Stream(c=1024) | 192.3 t/s | **1.81x** | 40.2% |
| ğŸ¥ˆ | Tree D=8 B=2 t=0.05 | 191.4 t/s | 1.80x | 40.2% |
| ğŸ¥‰ | Tree D=8 B=3 t=0.05 | 190.4 t/s | 1.79x | 28.1% |
| 4 | Linear K=7 + Stream(c=1024) | 189.9 t/s | 1.79x | 86.1% |
| 5 | Linear K=7 | 189.3 t/s | 1.78x | 86.1% |
| - | **Baseline** | 106.1 t/s | 1.00x | - |

#### 1000 Tokens ç»“æœ

| æ’å | æ–¹æ³• | ååé‡ | åŠ é€Ÿæ¯” | æ¥å—ç‡ |
|-----|------|--------|--------|--------|
| ğŸ¥‡ | Tree D=8 B=2 t=0.05 + Stream(c=2048) | 225.3 t/s | **1.84x** | 47.7% |
| ğŸ¥ˆ | Tree D=8 B=2 t=0.05 | 225.1 t/s | 1.84x | 47.7% |
| ğŸ¥‰ | Linear K=7 + Stream(c=2048) | 218.2 t/s | 1.78x | 98.5% |
| 4 | Linear K=7 | 209.2 t/s | 1.71x | 98.5% |
| - | **Baseline** | 122.7 t/s | 1.00x | - |

#### 2000 Tokens ç»“æœ (æœ€ä½³åŠ é€Ÿæ¯”)

| æ’å | æ–¹æ³• | ååé‡ | åŠ é€Ÿæ¯” | æ¥å—ç‡ |
|-----|------|--------|--------|--------|
| ğŸ¥‡ | **Tree D=8 B=3 t=0.05** | **251.8 t/s** | **2.07x** | 39.0% |
| ğŸ¥ˆ | Tree D=8 B=2 t=0.05 | 241.3 t/s | 1.98x | 53.5% |
| ğŸ¥‰ | Linear K=8 | 239.4 t/s | 1.96x | 101.6% |
| 4 | Linear K=8 + Stream(c=2048) | 238.0 t/s | 1.95x | 101.6% |
| - | **Baseline** | 121.9 t/s | 1.00x | - |

#### å…³é”®å‘ç°

1. **Tree D=8 B=3 t=0.05 åœ¨ 2000 tokens è¾¾åˆ° 2.07x åŠ é€Ÿæ¯”ï¼**
   - è¿™æ˜¯æ‰€æœ‰é…ç½®ä¸­çš„æœ€é«˜åŠ é€Ÿæ¯”
   - 251.8 t/s vs Baseline 121.9 t/s

2. **æœ€ä¼˜å‚æ•°éš Token é•¿åº¦å˜åŒ–**ï¼š
   - 500 tokens: D=8, B=2, t=0.05 (å¯é€‰ +StreamingLLM)
   - 1000 tokens: D=8, B=2, t=0.05 (å¯é€‰ +StreamingLLM)
   - 2000 tokens: D=8, B=3, t=0.05 (**ä¸ç”¨ StreamingLLM**)

3. **Tree vs Linear å¯¹æ¯”**ï¼š
   - çŸ­åºåˆ— (500): Tree â‰ˆ Linear (å·®è· <3%)
   - ä¸­ç­‰åºåˆ— (1000): Tree > Linear (+7.6%)
   - é•¿åºåˆ— (2000): Tree > Linear (+5.2%)

4. **StreamingLLM åœ¨é•¿åºåˆ— Tree ä¸‹ä¸æ¨è**ï¼š
   - Tree + Stream åœ¨ 2000 tokens ä¸‹å‹ç¼©è¿‡äºé¢‘ç¹
   - å¯¼è‡´æ€§èƒ½ä¸¥é‡ä¸‹é™ (0.53x)

#### æ¨èé…ç½®è¡¨

| åœºæ™¯ | æ¨èæ–¹æ³• | é¢„æœŸåŠ é€Ÿæ¯” |
|------|----------|------------|
| çŸ­åºåˆ— (â‰¤500) | Tree D=8 B=2 t=0.05 + Stream(c=1024) | 1.81x |
| ä¸­ç­‰åºåˆ— (1000) | Tree D=8 B=2 t=0.05 + Stream(c=2048) | 1.84x |
| **é•¿åºåˆ— (2000+)** | **Tree D=8 B=3 t=0.05** | **2.07x** |

### 7.5 æ–°å¢åŠŸèƒ½æ¨¡å—

æœ¬æ¬¡å®éªŒæ–°å¢äº†ä»¥ä¸‹åŠŸèƒ½æ¨¡å—ï¼š

| æ¨¡å— | æ–‡ä»¶ | è¯´æ˜ |
|------|------|------|
| TreeStreamingSpeculativeGeneratorV2 | `spec_decode/core/tree_speculative_generator.py` | Tree V2 + StreamingLLM ç»„åˆ |
| quantized_generator | `spec_decode/core/quantized_generator.py` | INT8/INT4 é‡åŒ–åŠ è½½å·¥å…· |
| benchmark_quantization | `papers/benchmark_quantization.py` | é‡åŒ–æ€§èƒ½ benchmark |
| benchmark_tree_streaming_v2 | `papers/benchmark_tree_streaming_v2.py` | Tree+Streaming benchmark |

---

## 8. å¤ç°æŒ‡å—

### 8.1 ç¯å¢ƒå‡†å¤‡

```bash
# å…‹éš†ä»“åº“
git clone <repository_url>
cd LLM-Efficient-Reasoning

# å®‰è£…ä¾èµ–
pip install torch transformers matplotlib numpy
```

### 8.2 è¿è¡Œå‚æ•°æœç´¢

```bash
# å®Œæ•´å‚æ•°æœç´¢ (çº¦ 2-3 å°æ—¶)
python papers/tree_param_search.py

# ç»“æœä¿å­˜åœ¨ results/tree_param_search_*.json
```

### 8.3 è¿è¡Œæ€§èƒ½å¯¹æ¯”

```bash
# åœ¨æœ€ä¼˜é…ç½®ä¸‹å¯¹æ¯”æ‰€æœ‰æ–¹æ³• (çº¦ 10 åˆ†é’Ÿ)
python papers/benchmark_optimal_config.py
```

### 8.4 è¿è¡Œæ‰©å±•å®éªŒ

```bash
# é‡åŒ–æ€§èƒ½æµ‹è¯•
python papers/benchmark_quantization.py

# Tree + StreamingLLM æµ‹è¯•
python papers/benchmark_tree_streaming_v2.py
```

### 8.5 åˆ†æç»“æœ

```bash
# åˆ†æå‚æ•°æœç´¢ç»“æœ
python papers/analyze_tree_search_results.py results/tree_param_search_20251231_140952.json
```

---

## 9. é™„å½•

### 9.1 ç›¸å…³æ–‡ä»¶åˆ—è¡¨

| æ–‡ä»¶ | è¯´æ˜ |
|------|------|
| `spec_decode/core/token_tree.py` | TokenTree æ•°æ®ç»“æ„å®ç° |
| `spec_decode/core/tree_speculative_generator.py` | Tree V2 ç”Ÿæˆå™¨å®ç° |
| `papers/tree_param_search.py` | å‚æ•°æœç´¢è„šæœ¬ |
| `papers/benchmark_optimal_config.py` | æ€§èƒ½å¯¹æ¯”è„šæœ¬ |
| `papers/analyze_tree_search_results.py` | ç»“æœåˆ†æè„šæœ¬ |
| `results/tree_param_search_20251231_140952.json` | å‚æ•°æœç´¢åŸå§‹æ•°æ® |
| `spec_decode/core/quantized_generator.py` | INT8/INT4 é‡åŒ–å·¥å…· |
| `papers/benchmark_quantization.py` | é‡åŒ–æ€§èƒ½ benchmark |
| `papers/benchmark_tree_streaming_v2.py` | Tree+Streaming benchmark |

### 9.2 å‚è€ƒæ–‡çŒ®

1. Leviathan et al., "Fast Inference from Transformers via Speculative Decoding", ICML 2023
2. Miao et al., "SpecInfer: Accelerating Generative Large Language Model Serving with Tree-based Speculative Inference", 2024
3. Xiao et al., "Efficient Streaming Language Models with Attention Sinks", ICLR 2024

---

**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: 2026å¹´1æœˆ2æ—¥  
**å®éªŒç¯å¢ƒ**: Pythia-2.8B + Pythia-70M on CUDA


---

## 7. ç»¼åˆ Benchmark ç»“æœ (2026-01-03 æ›´æ–°)

### 7.1 ä¿®æ­£åçš„æ¥å—ç‡è®¡ç®—

**é—®é¢˜**ï¼šä¹‹å‰çš„æ¥å—ç‡è®¡ç®— `accepted_nodes / total_nodes` å¯¹ Tree æ–¹æ³•ä¸å…¬å¹³ï¼Œå› ä¸º Tree ç”Ÿæˆå¤šä¸ªåˆ†æ”¯ä½†åªæ¥å—ä¸€æ¡è·¯å¾„ã€‚

**ä¿®æ­£**ï¼šä½¿ç”¨æ·±åº¦æ¥å—ç‡ `accepted_path_depth / max_tree_depth`

| æ–¹æ³• | æ¥å—ç‡ (ä¿®æ­£å) | Tokens/Round | è¯´æ˜ |
|------|----------------|--------------|------|
| **Tree V2 (D=8, B=3)** | **68.59%** | 6.2 | æ¯è½®å¹³å‡æ¥å— 6.2/9 çš„æœ€å¤§æ·±åº¦ |
| Linear K=5 | 72.46% | 3.6 | |
| Linear K=6 | 68.31% | 4.1 | |
| Linear K=7 | 61.58% | 4.3 | |
| Linear K=8 | 55.80% | 4.5 | |

**ç»“è®º**ï¼šTree æ–¹æ³•çš„æ¥å—ç‡ (68.59%) ä¸ Linear æ–¹æ³•ç›¸å½“ (64.54% å¹³å‡)ï¼Œä½†æ¯è½®æ¥å—çš„ tokens æ›´å¤š (6.2 vs 4.1)ã€‚

### 7.2 Benchmark æŒ‡æ ‡è¯´æ˜

| æŒ‡æ ‡ | å®šä¹‰ | å•ä½ |
|------|------|------|
| TTFT | Time To First Token (é¦– token å»¶è¿Ÿ) | ms |
| TPOT | Time Per Output Token (æ¯ token å»¶è¿Ÿ) | ms |
| Throughput | ååé‡ = tokens / total_time | t/s |
| Acceptance Rate | æ¥å—ç‡ (Linear: accepted/draft, Tree: depth-based) | % |
| FLOPs | æµ®ç‚¹è¿ç®—æ¬¡æ•° (ä¼°ç®—) | - |

### 7.3 å¤ç°æ€§éªŒè¯

ä½¿ç”¨åŸå§‹ `benchmark_optimal_config.py` è„šæœ¬ï¼ˆ10 è½® warmupï¼ŒçŸ­ promptï¼‰æˆåŠŸå¤ç°ç»“æœï¼š

| æ–¹æ³• | åŸå§‹æŠ¥å‘Š | å¤ç°ç»“æœ |
|------|----------|----------|
| Tree V2 | 193.4 t/s (1.62x) | **196.8 t/s (1.61x)** âœ… |
| HF Assisted | 161.9 t/s (1.36x) | **162.8 t/s (1.34x)** âœ… |
| Linear K=6 | 133.1 t/s (1.11x) | **133.2 t/s (1.09x)** âœ… |
| Baseline | 119.4 t/s | **121.9 t/s** âœ… |

### 7.4 ç»“è®º

1. **Tree V2 ç¡®å®æ˜¯æœ€å¿«çš„æ–¹æ³•** (1.61x)ï¼Œæ¯” HF Assisted (1.34x) å¿« 20%
2. **æ¥å—ç‡è®¡ç®—å·²ä¿®æ­£**ï¼šTree çš„æ·±åº¦æ¥å—ç‡ (68.59%) ä¸ Linear (64.54%) ç›¸å½“
3. **Prompt é•¿åº¦å½±å“æ˜¾è‘—**ï¼šé•¿ prompt ä¼šé™ä½æ‰€æœ‰æ–¹æ³•çš„æ€§èƒ½
4. **Warmup å¾ˆé‡è¦**ï¼šéœ€è¦ 10+ è½® warmup æ‰èƒ½è·å¾—ç¨³å®šç»“æœ

