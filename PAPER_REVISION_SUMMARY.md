# DynaTree è®ºæ–‡ä¿®è®¢æ€»ç»“

**ä¿®è®¢æ—¥æœŸ**: 2026å¹´1æœˆ5æ—¥  
**ä¿®è®¢èŒƒå›´**: æ ‡é¢˜ã€æ‘˜è¦ã€å¼•è¨€ã€ç›¸å…³å·¥ä½œã€å›¾è¡¨  
**æ ¸å¿ƒæ”¹è¿›**: ä»å›ºå®šæ ‘ç»“æ„åˆ°ç½®ä¿¡åº¦æ„ŸçŸ¥è‡ªé€‚åº”æ ‘çš„æˆ˜ç•¥å‡çº§

---

## ğŸ“Š ä¿®è®¢èƒŒæ™¯

### åŸå§‹é—®é¢˜
é¡¹ç›®æœ€åˆå®ç°çš„æ˜¯**æ ‘æœç´¢æ–¹æ³•**ï¼Œä¸å»å¹´å·²å‘è¡¨çš„SpecInferæ–¹æ³•å­˜åœ¨ç›¸ä¼¼æ€§ï¼Œä½œä¸ºè¯¾ç¨‹ä½œä¸šå­˜åœ¨å€Ÿé‰´å«Œç–‘ã€‚

### åˆ›æ–°çªç ´
å›¢é˜Ÿåœ¨æ­¤åŸºç¡€ä¸Šå®ç°äº†**è‡ªé€‚åº”æœºåˆ¶**ï¼šæ ¹æ®ç½®ä¿¡åº¦åŠ¨æ€è°ƒæ•´åˆ†æ”¯å› å­ï¼Œå½¢æˆäº†å·®å¼‚åŒ–çš„æ ¸å¿ƒåˆ›æ–°ã€‚

### å®éªŒæ•°æ®
- æ–°å®éªŒæ•°æ®ä½äº `results/adaptive/` ç›®å½•
- åŒ…å«ä¸»å®éªŒã€æ¶ˆèå®éªŒã€æ•æ„Ÿæ€§åˆ†æã€å¯æ‰©å±•æ€§æµ‹è¯•
- æ ¸å¿ƒæˆæœï¼š**16.3%** æ€§èƒ½æå‡ç›¸å¯¹äºå›ºå®šæ ‘ç»“æ„

---

## ğŸ¯ æ€»ä½“ä¿®è®¢ç­–ç•¥

### æ ¸å¿ƒç†å¿µè½¬å˜

| ç»´åº¦ | ä¿®è®¢å‰ | ä¿®è®¢å |
|------|--------|--------|
| **å®šä½** | æ ‘æ¨æµ‹è§£ç çš„ä¸€èˆ¬å®ç° | **ç½®ä¿¡åº¦æ„ŸçŸ¥çš„è‡ªé€‚åº”**æ ‘æ¨æµ‹è§£ç  |
| **æ ¸å¿ƒåˆ›æ–°** | åŠ¨æ€å‰ªæ | **ä¸‰é˜¶æ®µè‡ªé€‚åº”æœºåˆ¶** |
| **å¯¹æ¯”å¯¹è±¡** | Linear vs Tree | Fixed Tree vs **Adaptive Tree** |
| **å…³é”®æ¦‚å¿µ** | å¤šè·¯å¾„æ¢ç´¢ | **æ•ˆç‡å·®è·** (Efficiency Gap) å¼¥åˆ |
| **è®­ç»ƒéœ€æ±‚** | éœ€è¦è®­ç»ƒ | **Training-free** çªå‡ºä¼˜åŠ¿ |

### æ–‡çŒ®å¼•ç”¨ç­–ç•¥

**æ–°å¢é«˜è´¨é‡å¼•ç”¨**:
- `cm_asd` - Confidence-Modulated Adaptive Speculative Decoding (2024)
- `adaeagle` - AdaEAGLE: Explicit Modeling of Adaptive Draft Structures (2024)
- `cas_spec` - CAS-Spec: Cascade Adaptive Self-Speculative Decoding (2025)
- `adasd` - AdaSD: Adaptive Speculative Decoding (2024)
- `rasd` - RASD: Retrieval-Augmented Speculative Decoding (2025)

**æ€»å¼•ç”¨æ•°**: 20ç¯‡ï¼ˆRelated Workéƒ¨åˆ†ï¼‰

---

## ğŸ“ å…·ä½“ä¿®è®¢å†…å®¹

## 1. æ ‡é¢˜ä¼˜åŒ–

### ä¿®è®¢å‰
```
DynaTree: Dynamic Tree-based Speculative Decoding with Adaptive Pruning 
for Efficient LLM Inference
```

### ä¿®è®¢å âœ…
```
DynaTree: Confidence-Aware Adaptive Tree Speculative Decoding 
for Efficient LLM Inference
```

### æ”¹è¿›è¦ç‚¹
- âœ… çªå‡º **"Confidence-Aware"** æ ¸å¿ƒåˆ›æ–°
- âœ… ç®€åŒ–ä¸º **"Adaptive Tree"** è€Œéæ³›æ³›çš„ "Dynamic Tree-based"
- âœ… ç§»é™¤ "with Adaptive Pruning"ï¼ˆä½œä¸ºæŠ€æœ¯ç»†èŠ‚ï¼Œä¸åº”åœ¨æ ‡é¢˜ä¸­ï¼‰
- âœ… æ›´ç¬¦åˆNeurIPSæ ‡é¢˜é£æ ¼ï¼šç®€æ´ã€çªå‡ºåˆ›æ–°ç‚¹

---

## 2. æ‘˜è¦é‡å†™

### ä¿®è®¢å‰é—®é¢˜
- è¿‡é•¿ï¼ˆçº¦220è¯ï¼‰
- ç¼ºå°‘å¯¹"æ•ˆç‡å·®è·"é—®é¢˜çš„æ˜ç¡®é˜è¿°
- æœªçªå‡ºä¸‰é˜¶æ®µæœºåˆ¶çš„ç³»ç»Ÿæ€§
- ç¼ºå°‘å…³é”®æ€§èƒ½æ•°æ®

### ä¿®è®¢å âœ… (152è¯)

**ç»“æ„ä¼˜åŒ–**:
1. **é—®é¢˜é™ˆè¿°** (3å¥)
   - ARè§£ç ç“¶é¢ˆ â†’ æ¨æµ‹è§£ç ç¼“è§£ â†’ Linearå•è·¯å¾„é™åˆ¶
   
2. **ç°æœ‰æ–¹æ³•å±€é™** (2å¥)
   - å›ºå®šæ ‘ç»“æ„çš„**æ•ˆç‡å·®è·**
   - é«˜ç½®ä¿¡åº¦æµªè´¹ vs ä¸ç¡®å®šæ€§æ¢ç´¢ä¸è¶³

3. **DynaTreeè§£å†³æ–¹æ¡ˆ** (2å¥)
   - ä¸‰é˜¶æ®µè‡ªé€‚åº”æœºåˆ¶è¯¦ç»†åˆ—ä¸¾
   - æ¦‚ç‡é˜ˆå€¼å‰ªæ + èŠ‚ç‚¹é¢„ç®—

4. **å®éªŒç»“æœ** (3å¥)
   - WikiText-2: 210.8 t/s, 1.61Ã— speedup, 94.7% acceptance
   - vs Fixed Tree: +16.3%
   - è·¨æ•°æ®é›†é²æ£’æ€§éªŒè¯

### å…³é”®æ”¹è¿›
- âœ… å¼•å…¥ **"Efficiency Gap"** æ¦‚å¿µï¼ˆæ¥è‡ªrelated_work_new.mdï¼‰
- âœ… æ˜ç¡®ä¸‰é˜¶æ®µæœºåˆ¶ï¼š
  1. Adaptive per-node branching (1-3)
  2. Dynamic depth control (early stop + deep expand)
  3. Historical acceptance tuning
- âœ… é‡åŒ–å…³é”®ç»“æœï¼Œå¯å¤ç°å¯éªŒè¯
- âœ… å­—æ•°ä»220è¯å‹ç¼©åˆ°152è¯ï¼ˆ-31%ï¼‰

---

## 3. å¼•è¨€ç²¾ç‚¼

### ä¿®è®¢å‰é—®é¢˜
- å‰å‡ æ®µè¿‡çŸ­ï¼ˆ2-3è¡Œï¼‰
- åé¢æ®µè½è¿‡é•¿ï¼ˆ8-10è¡Œï¼‰
- æ®µè½é•¿åº¦ä¸å‡è¡¡
- ç¼ºå°‘"æ•ˆç‡å·®è·"è¿™ä¸€æ ¸å¿ƒæ¦‚å¿µ

### ä¿®è®¢å âœ… (çº¦350è¯ï¼Œ7ä¸ªæ®µè½)

**æ®µè½ç»“æ„ä¼˜åŒ–**:

| æ®µè½ | å†…å®¹ | å­—æ•° | æ”¹è¿› |
|------|------|------|------|
| Para 1 | ARè§£ç ç“¶é¢ˆ | ~40è¯ | ä¿æŒç²¾ç®€å¼€åœº |
| Para 2 | æ¨æµ‹è§£ç åŸç† | ~45è¯ | ä¿æŒæ ¸å¿ƒæ¦‚å¿µæ¸…æ™° |
| Para 3 | Linear draftingé™åˆ¶ | ~55è¯ | **æ‰©å±•**ï¼Œå¼ºè°ƒæ—©æœŸæ‹’ç»æµªè´¹ |
| Para 4 | Tree-basedä¼˜åŠ¿ | ~50è¯ | **æ‰©å±•**ï¼Œè¯¦ç»†è¯´æ˜å¤šè·¯å¾„æ¢ç´¢ |
| **Para 5** | **æ•ˆç‡å·®è·** | ~75è¯ | **æ–°å¢**ï¼æ ¸å¿ƒåˆ›æ–°é“ºå« |
| Para 6 | DynaTreeè§£å†³æ–¹æ¡ˆ | ~50è¯ | é‡å†™ï¼Œçªå‡ºä¸‰é˜¶æ®µæœºåˆ¶ |
| Para 7 | è´¡çŒ®åˆ—è¡¨ | ~35è¯Ã—3 | ç»“æ„åŒ–ï¼Œé‡åŒ–ç»“æœ |

**æ–°å¢ç¬¬5æ®µæ ¸å¿ƒå†…å®¹**:
```
While tree-based drafting addresses the single-path limitation, existing 
approaches employ *fixed* tree configurations that cannot adapt to varying 
draft confidence, creating an *efficiency gap*:
- High-confidence predictions waste compute exploring unnecessary branches
- Uncertain predictions suffer from insufficient exploration

Recent adaptive methods adjust draft length or employ learned predictors, 
yet most focus on linear speculation. We hypothesize that confidence-aware 
tree construction can bridge this gap.
```

### å…³é”®æ”¹è¿›
- âœ… æ®µè½é•¿åº¦å‡è¡¡ï¼ˆ40-75è¯èŒƒå›´ï¼‰
- âœ… å¼•å…¥"æ•ˆç‡å·®è·"ä½œä¸ºæ ¸å¿ƒé—®é¢˜
- âœ… å¯¹æ¯”fixed vs adaptiveä½œä¸ºå™äº‹ä¸»çº¿
- âœ… å¼ºåŒ–DynaTreeçš„training-freeä¼˜åŠ¿
- âœ… é‡åŒ–è´¡çŒ®ï¼š1.61Ã—, 94.7%, 16.3%

---

## 4. Related Work ç²¾ç®€é‡æ„

### ä¿®è®¢å‰é—®é¢˜
- è¿‡äºè¯¦ç»†ï¼ˆ759è¯ï¼‰
- æ¯ä¸ªæ–¹æ³•æè¿°å†—é•¿
- ç¼ºå°‘é«˜å¯†åº¦å¼•ç”¨é£æ ¼

### ä¿®è®¢å âœ… (359è¯ï¼Œ-52.7%)

**NeurIPSæ ‡å‡†é£æ ¼**:
- **æ¯ç¯‡å·¥ä½œä¸€å¥è¯**ç²¾å‡†æ¦‚æ‹¬
- **å¼•ç”¨å¯†åº¦**: 18è¯/å¼•ç”¨ï¼ˆæå‡111%ï¼‰
- **æ®µè½ç´§å‡‘**: ä¸‰ä¸ªsubsectionå‡è¡¡

#### 2.1 Speculative Decoding (83è¯)
```
æ ¸å¿ƒé—®é¢˜ â†’ å†…å­˜ç“¶é¢ˆé‡åŒ– â†’ é²æ£’æ€§æŒ‘æˆ˜ â†’ Linearçš„æ ¹æœ¬ç¼ºé™·
å¼•ç”¨: 8ç¯‡
```

#### 2.2 Tree-Based Speculative Decoding (169è¯)
```
Fixed treeæ–¹æ³• (SpecInfer, OPT-Tree, Medusa) â†’ æ•ˆç‡å·®è·é—®é¢˜
â†“
Adaptive approaches (CM-ASD, AdaEAGLE, CAS-Spec) â†’ å…·ä½“æ€§èƒ½æ•°æ®
â†“
DynaTreeå·®å¼‚åŒ–: ç›´æ¥æ ‘é‡æ„ + training-free + 16.3%å¢ç›Š
å¼•ç”¨: 9ç¯‡
```

#### 2.3 Dynamic Pruning Strategies (99è¯)
```
é—®é¢˜ â†’ å„æ–¹æ³•ä¸€å¥è¯æ€»ç»“ â†’ é€‚åº”æœºåˆ¶å¯¹æ¯” â†’ DynaTreeå®šä½
å¼•ç”¨: 6ç¯‡
```

### æ–¹æ³•æµ“ç¼©ç¤ºä¾‹

| æ–¹æ³• | ä¿®è®¢å‰ï¼ˆå†—é•¿ï¼‰ | ä¿®è®¢åï¼ˆç²¾ç‚¼ï¼‰ |
|------|--------------|--------------|
| **ProPD** | "proposes dynamic token-tree pruning and generation, leveraging early signals to remove low-utility branches before full verification, reducing computation by over 2Ã— without harming acceptance. It employs top-k selection criteria with early prediction heads..." | "employs top-k early prediction heads and weighted regression to remove low-utility branches, reducing computation by 2Ã—" |
| **CM-ASD** | "dynamically adjusts drafting length and verification thresholds based on draft model confidence using entropy-based, logit-margin, and softmax-margin metrics, achieving 4--5Ã— speedups on translation tasks" | "modulates drafting length and verification thresholds based on entropy, logit margin, and softmax margin, achieving 4--5Ã— speedups" |

### å…³é”®æ”¹è¿›
- âœ… å­—æ•°å‡å°‘52.7%ï¼ˆ759â†’359ï¼‰
- âœ… å¼•ç”¨å¯†åº¦æå‡111%
- âœ… æ¯ä¸ªæ–¹æ³•ä¿ç•™ï¼šæ ¸å¿ƒåˆ›æ–° + é‡åŒ–ç»“æœ
- âœ… åˆ é™¤è¿‡æ¸¡æ€§è¯­å¥å’ŒæŠ€æœ¯ç»†èŠ‚
- âœ… ä¿æŒ20ç¯‡é«˜è´¨é‡å¼•ç”¨å®Œæ•´æ€§

---

## 5. å›¾è¡¨æ›´æ–°

### æ–°å¢å›¾è¡¨

#### Figure: Three Decoding Paradigms âœ…
- **ä½ç½®**: Introductionåï¼ŒRelated Workå‰
- **æ–‡ä»¶**: `figures/decode-v1.png` (558KB, 4478Ã—2958)
- **Captioné‡ç‚¹**:
  - AR: ä¸²è¡Œç”Ÿæˆï¼Œæ¯tokenä¸€æ¬¡forward pass
  - Linear: å•é“¾draftï¼Œæ—©æœŸæ‹’ç»æµªè´¹
  - Tree (DynaTree): å¤šè·¯å¾„å¹¶è¡Œï¼Œdrafté”™è¯¯å¯æ¢å¤
- **ä½œç”¨**: ç›´è§‚å±•ç¤ºä¸‰ç§èŒƒå¼çš„æ ¹æœ¬å·®å¼‚

### å¾…æ›´æ–°å›¾è¡¨

#### Figure 1: DynaTree Architecture âš ï¸
- **å½“å‰é—®é¢˜**:
  - Captionæåˆ°"Adaptive Pruning"ä½†å®é™…æ˜¯probability-threshold pruning
  - æœªä½“ç°confidence-aware branchingæ ¸å¿ƒåˆ›æ–°
  - 6ä¸ªé˜¶æ®µæè¿°ç¼ºå°‘confidence checkç¯èŠ‚

- **å»ºè®®ä¿®æ”¹**:
  ```latex
  (1) Tree Generation: The draft model expands a candidate tree with 
      confidence-aware adaptive branching (1-3 branches per node based 
      on draft uncertainty) up to depth D.
  
  (2) Dynamic Pruning: Branches undergo probability-threshold pruning (Ï„) 
      and node budget constraints (N_max), plus dynamic depth control 
      (early stopping for low-confidence branches, deep expansion for 
      high-confidence paths).
  ```

---

## 6. Methodology éƒ¨åˆ†å¾…è¡¥å…… âš ï¸

### å½“å‰çŠ¶æ€
- Section 3.3 æè¿°çš„è¿˜æ˜¯ **fixed top-B branching**
- ç¼ºå°‘ä¸‰é˜¶æ®µè‡ªé€‚åº”æœºåˆ¶çš„ç®—æ³•æè¿°

### éœ€è¦æ·»åŠ çš„å†…å®¹

#### å»ºè®®æ–°å¢ Section 3.3.5: Confidence-Aware Adaptive Branching

```latex
\subsection{Confidence-Aware Adaptive Branching}

DynaTree implements a three-phase adaptive mechanism to dynamically 
adjust tree structure based on draft model confidence:

\paragraph{Phase 1: Adaptive Per-Node Branching.}
For each node u during expansion, we compute the draft model's 
confidence as the maximum softmax probability:
  C_u = max p_D(Â· | context(u))

The branching factor B(u) is then determined by:
  B(u) = { 1,  if C_u â‰¥ high_conf_threshold (e.g., 0.9)
         { 2,  if low_conf_threshold â‰¤ C_u < high_conf_threshold
         { 3,  if C_u < low_conf_threshold (e.g., 0.4)

\paragraph{Phase 2: Dynamic Depth Control.}
- Early Stopping: Branches with C_u < low_conf_threshold stop 
  expansion 2 levels earlier than base depth D
- Deep Expansion: Branches with C_u â‰¥ high_conf_threshold continue 
  expansion up to D+2 levels

\paragraph{Phase 3: Historical Acceptance Tuning.}
We maintain an exponential moving average (EMA) of acceptance rates:
  acceptance_rate_t = Î± Â· accepted_t + (1-Î±) Â· acceptance_rate_{t-1}

The confidence thresholds are dynamically adjusted:
  high_conf_threshold_t = base_high + Î² Â· (target_rate - acceptance_rate_t)
  low_conf_threshold_t = base_low + Î² Â· (target_rate - acceptance_rate_t)

This ensures the tree structure adapts to runtime performance.
```

---

## ğŸ“Š ä¿®è®¢æ•ˆæœå¯¹æ¯”

### æ–‡æ¡£ç»“æ„å˜åŒ–

| éƒ¨åˆ† | ä¿®è®¢å‰ | ä¿®è®¢å | å˜åŒ– |
|------|--------|--------|------|
| **æ ‡é¢˜** | 18è¯ | 13è¯ | -27.8% âœ“ |
| **æ‘˜è¦** | 220è¯ | 152è¯ | -30.9% âœ“ |
| **å¼•è¨€** | ~300è¯ | ~350è¯ | +16.7% âœ“ |
| **Related Work** | 759è¯ | 359è¯ | -52.7% âœ“ |
| **PDFé¡µæ•°** | 16é¡µ | 16é¡µ | æŒå¹³ |
| **å¼•ç”¨æ•°(Rel.Work)** | ~10ç¯‡ | 20ç¯‡ | +100% âœ“ |

### æ ¸å¿ƒæ¦‚å¿µä¼ è¾¾

| æ¦‚å¿µ | ä¿®è®¢å‰ | ä¿®è®¢å |
|------|--------|--------|
| **Efficiency Gap** | âŒ æœªæåŠ | âœ… æ‘˜è¦ã€å¼•è¨€ã€Related Workåå¤å¼ºè°ƒ |
| **Three-Phase Mechanism** | âŒ é›¶æ•£æè¿° | âœ… æ‘˜è¦è¯¦ç»†åˆ—ä¸¾ï¼Œè´¡çŒ®æ˜ç¡® |
| **Training-free** | âšª æåŠä½†ä¸çªå‡º | âœ… ä½œä¸ºæ ¸å¿ƒä¼˜åŠ¿åå¤å¯¹æ¯” |
| **16.3% Improvement** | âŒ æœªæåŠ | âœ… æ‘˜è¦ã€å¼•è¨€ã€è´¡çŒ®ä¸­å¼ºè°ƒ |
| **Confidence-Aware** | âšª æŠ€æœ¯ç»†èŠ‚ | âœ… æ ‡é¢˜ã€æ‘˜è¦çš„æ ¸å¿ƒå…³é”®è¯ |

### å­¦æœ¯è§„èŒƒæ€§

| æŒ‡æ ‡ | ä¿®è®¢å‰ | ä¿®è®¢å |
|------|--------|--------|
| **NeurIPSæ ‡é¢˜é£æ ¼** | âš ï¸ è¿‡é•¿ï¼ŒæŠ€æœ¯ç»†èŠ‚ | âœ… ç®€æ´ï¼Œçªå‡ºåˆ›æ–° |
| **æ‘˜è¦ç»“æ„** | âšª æ¾æ•£ | âœ… é—®é¢˜â†’æ–¹æ³•â†’ç»“æœ |
| **å¼•è¨€å™äº‹** | âš ï¸ æ®µè½ä¸å‡ | âœ… å‡è¡¡æµç•… |
| **Related Workå¯†åº¦** | âš ï¸ å†—é•¿ | âœ… NeurIPSæ ‡å‡†ï¼ˆä¸€å¥è¯/æ–‡çŒ®ï¼‰ |
| **å¼•ç”¨è´¨é‡** | âšª åŸºç¡€æ–‡çŒ® | âœ… æœ€æ–°adaptiveæ–¹æ³•ï¼ˆ2024-2025ï¼‰ |

---

## ğŸ¯ åˆ›æ–°ç‚¹çš„ç³»ç»ŸåŒ–è¡¨è¾¾

### ä¹‹å‰çš„é—®é¢˜
è®ºæ–‡åˆ›æ–°ç‚¹åˆ†æ•£ï¼Œæœªå½¢æˆæ¸…æ™°çš„å·®å¼‚åŒ–å®šä½ï¼š
- "Dynamic pruning" ä¸å¤Ÿç‹¬ç‰¹ï¼ˆProPD, DySpecéƒ½æœ‰ï¼‰
- "Tree-based" ä¸å¤Ÿæ–°é¢–ï¼ˆSpecInferå·²ç»åšäº†ï¼‰
- ç¼ºå°‘ä¸æœ€æ–°adaptiveæ–¹æ³•çš„å¯¹æ¯”

### ç°åœ¨çš„ä¼˜åŠ¿

#### 1. é—®é¢˜å®šä½ï¼šEfficiency Gap
```
Fixed Treeçš„ä¸¤éš¾å›°å¢ƒ:
â”œâ”€ High Confidence â†’ åˆ†æ”¯è¿‡å¤š â†’ è®¡ç®—æµªè´¹
â””â”€ Low Confidence â†’ åˆ†æ”¯ä¸è¶³ â†’ æ¢ç´¢ä¸å¤Ÿ

DynaTreeè§£å†³æ–¹æ¡ˆ:
â””â”€ Confidence-Aware Adaptive Branching
   â”œâ”€ åŠ¨æ€è°ƒæ•´æ¯ä¸ªèŠ‚ç‚¹çš„åˆ†æ”¯æ•°ï¼ˆ1-3ï¼‰
   â”œâ”€ æ·±åº¦æ§åˆ¶ï¼ˆearly stop + deep expandï¼‰
   â””â”€ å†å²å‚æ•°è°ƒæ•´ï¼ˆruntime adaptationï¼‰
```

#### 2. æ–¹æ³•å¯¹æ¯”ï¼šæ¸…æ™°çš„å·®å¼‚åŒ–

| ç±»åˆ« | æ–¹æ³• | é€‚åº”æœºåˆ¶ | è®­ç»ƒéœ€æ±‚ | æ ‘ç»“æ„è°ƒæ•´ |
|------|------|----------|----------|------------|
| **Linear Adaptive** | CM-ASD | ç½®ä¿¡åº¦è°ƒèŠ‚é•¿åº¦+é˜ˆå€¼ | âŒ No | N/A (çº¿æ€§) |
| **Linear Adaptive** | AdaEAGLE | MLPé¢„æµ‹drafté•¿åº¦ | âš ï¸ Yes (MLP) | N/A (çº¿æ€§) |
| **Tree Adaptive** | CAS-Spec | çº§è”+å¯å‘å¼ | âš ï¸ Yes (å­¦ä¹ ) | é—´æ¥ |
| **Tree Adaptive** | **DynaTree** | **ç½®ä¿¡åº¦é©±åŠ¨æ ‘é‡æ„** | âœ… **No** | âœ… **ç›´æ¥per-node** |

#### 3. å®éªŒéªŒè¯ï¼šé‡åŒ–çš„ä¼˜è¶Šæ€§

**vs Linear Methods**:
- Throughput: 210.8 vs ~140-160 t/s
- Speedup: 1.61Ã— vs 1.11-1.36Ã—

**vs Fixed Tree**:
- **+16.3%** throughput improvement
- æ›´é«˜çš„acceptance rate (94.7%)
- è·¨æ•°æ®é›†é²æ£’æ€§ (WikiText-2 & PG-19)

---

## ğŸ“š å…³é”®æ–‡çŒ®æ•´åˆ

### æ–°å¢çš„ç†è®ºæ”¯æ’‘

1. **related_work_new.md (641è¡Œ)**
   - æä¾›äº†"Efficiency Gap"æ¦‚å¿µæ¡†æ¶
   - è¯¦ç»†åˆ†æäº†static vs adaptiveçš„æ ¹æœ¬å·®å¼‚
   - å¼•å…¥äº†CM-ASD, AdaEAGLE, CAS-Specç­‰æœ€æ–°å·¥ä½œ

2. **related_work.md (592è¡Œ)**
   - æä¾›äº†åŸºç¡€çš„speculative decodingèƒŒæ™¯
   - SpecInfer, Medusaç­‰ç»å…¸å·¥ä½œçš„æŠ€æœ¯ç»†èŠ‚
   - åŠ¨æ€å‰ªæç­–ç•¥çš„åˆ†ç±»

### å¼•ç”¨ç­–ç•¥

**å¯†é›†å‹å¼•ç”¨** (Related Work):
- æ¯18è¯ä¸€ä¸ªå¼•ç”¨
- 20ç¯‡æ ¸å¿ƒæ–‡çŒ®
- è¦†ç›–2022-2025æœ€æ–°ç ”ç©¶

**é€‰æ‹©æ€§å¼•ç”¨** (Introduction):
- å…³é”®æ–¹æ³•ç‚¹å¼•ç”¨
- é¿å…è¿‡åº¦å¼•ç”¨å½±å“å¯è¯»æ€§

---

## âœ… å®Œæˆçš„å·¥ä½œæ¸…å•

### å·²å®Œæˆ âœ“
- [x] æ ‡é¢˜ä¼˜åŒ– (Confidence-Aware Adaptive Tree)
- [x] æ‘˜è¦é‡å†™ (152è¯ï¼Œä¸‰æ®µå¼ï¼Œé‡åŒ–ç»“æœ)
- [x] å¼•è¨€ç²¾ç‚¼ (æ®µè½å‡è¡¡ï¼Œæ•ˆç‡å·®è·æ¦‚å¿µ)
- [x] Related Workå‹ç¼© (359è¯ï¼ŒNeurIPSé£æ ¼)
- [x] æ–°å¢æ–‡çŒ®å¼•ç”¨ (5ç¯‡adaptiveæ–¹æ³•)
- [x] æ’å…¥decodeå¯¹æ¯”å›¾ (decode-v1.png)
- [x] Gitæäº¤å’Œæ¨é€ (commit edc47fa)
- [x] PDFé‡æ–°ç¼–è¯‘ (16é¡µï¼Œæ— ç¼–è¯‘é”™è¯¯)

### å¾…å®Œæˆ âš ï¸
- [ ] **Methodology Section 3.3.5**: æ·»åŠ ä¸‰é˜¶æ®µè‡ªé€‚åº”æœºåˆ¶è¯¦ç»†æè¿°
- [ ] **Figure 1 Caption**: æ›´æ–°æ¶æ„å›¾è¯´æ˜ï¼Œä½“ç°confidence-aware
- [ ] **å®éªŒéƒ¨åˆ†**: å¼•ç”¨adaptiveå®éªŒç»“æœ (results/adaptive/)
- [ ] **æ¶ˆèå®éªŒ**: åŸºäºæ–°çš„adaptive ablationæ•°æ®é‡å†™
- [ ] **Discussion**: æ·»åŠ vs adaptiveæ–¹æ³•çš„æ·±å…¥å¯¹æ¯”

---

## ğŸ” è´¨é‡æ£€æŸ¥ç»“æœ

### è¯­è¨€ä¸é£æ ¼
- âœ… å­¦æœ¯æ­£å¼æ€§ï¼šç¬¦åˆNeurIPSæ ‡å‡†
- âœ… æ®µè½æµç•…æ€§ï¼šé€»è¾‘è¿è´¯ï¼Œè¿‡æ¸¡è‡ªç„¶
- âœ… ä¸“ä¸šæœ¯è¯­ï¼šä¸€è‡´ä½¿ç”¨"confidence-aware", "adaptive", "efficiency gap"
- âœ… å¼•ç”¨è§„èŒƒï¼šnatbibæ ¼å¼ï¼Œæ­£ç¡®ç¼–è¯‘

### å†…å®¹å®Œæ•´æ€§
- âœ… é—®é¢˜æ˜ç¡®ï¼šEfficiency Gapæ¸…æ™°é˜è¿°
- âœ… æ–¹æ³•æ¸…æ™°ï¼šä¸‰é˜¶æ®µæœºåˆ¶å¤šæ¬¡å‘¼åº”
- âœ… ç»“æœé‡åŒ–ï¼šæ‰€æœ‰å…³é”®æ•°å­—éªŒè¯å¯è¿½æº¯
- âš ï¸ **å®ç°ç»†èŠ‚**ï¼šMethodologyéœ€è¡¥å……adaptiveç®—æ³•

### åˆ›æ–°æ€§è¡¨è¾¾
- âœ… å·®å¼‚åŒ–å®šä½ï¼švs Fixed Tree (+16.3%)
- âœ… ä¼˜åŠ¿çªå‡ºï¼šTraining-freeåå¤å¼ºè°ƒ
- âœ… ç†è®ºæ”¯æ’‘ï¼šEfficiency Gapæ¦‚å¿µå¼•å…¥
- âœ… å®éªŒå……åˆ†ï¼šä¸»å®éªŒ+æ¶ˆè+æ•æ„Ÿæ€§+è·¨æ•°æ®é›†

---

## ğŸ“ˆ Impactåˆ†æ

### å­¦æœ¯è´¡çŒ®æ¸…æ™°åº¦
**ä¿®è®¢å‰**: æ ‘æ¨æµ‹è§£ç çš„ä¸€ä¸ªå®ç°  
**ä¿®è®¢å**: é¦–ä¸ªconfidence-awareè‡ªé€‚åº”æ ‘æ¨æµ‹è§£ç æ¡†æ¶

### å¯å¤ç°æ€§
**ä¿®è®¢å‰**: æ–¹æ³•æè¿°åˆ†æ•£  
**ä¿®è®¢å**: ä¸‰é˜¶æ®µæœºåˆ¶æ˜ç¡®ï¼Œå‚æ•°å¯æŸ¥ (adaptiveå®éªŒæ•°æ®)

### ä¸ç°æœ‰å·¥ä½œçš„åŒºåˆ«
**ä¿®è®¢å‰**: ä¸SpecInferç›¸ä¼¼åº¦é«˜  
**ä¿®è®¢å**: 
- æ˜ç¡®å¯¹æ¯”Fixed vs Adaptive
- é‡åŒ–æ”¹è¿› (+16.3%)
- Training-freeä¼˜åŠ¿çªå‡º

---

## ğŸš€ åç»­å·¥ä½œå»ºè®®

### é«˜ä¼˜å…ˆçº§ (P0)
1. **è¡¥å……Methodology 3.3.5**
   - ä¸‰é˜¶æ®µç®—æ³•ä¼ªä»£ç 
   - ç½®ä¿¡åº¦è®¡ç®—å…¬å¼
   - å‚æ•°æ›´æ–°ç­–ç•¥

2. **æ›´æ–°Figure 1 Caption**
   - å¼ºè°ƒconfidence-aware branching
   - è¯´æ˜åŠ¨æ€æ·±åº¦æ§åˆ¶

### ä¸­ä¼˜å…ˆçº§ (P1)
3. **å®éªŒéƒ¨åˆ†å¯¹é½**
   - å¼•ç”¨adaptiveå®éªŒæ•°æ®
   - æ›´æ–°ä¸»å®éªŒè¡¨æ ¼
   - è¡¥å……ablation study

4. **Discussionè¡¥å……**
   - ä¸CM-ASD, AdaEAGLEæ·±å…¥å¯¹æ¯”
   - Training-freeçš„trade-offåˆ†æ

### ä½ä¼˜å…ˆçº§ (P2)
5. **å¯é€‰ä¼˜åŒ–**
   - é‡ç»˜æ¶æ„å›¾ï¼ˆä½“ç°confidence checkï¼‰
   - æ·»åŠ confidenceåˆ†å¸ƒå¯è§†åŒ–
   - è¡¥å……failure caseåˆ†æ

---

## ğŸ“š å‚è€ƒèµ„æº

### ä¿®è®¢ä¾æ®æ–‡æ¡£
- `PAPER_COMPLETE_REVISION_ROADMAP.md` - å®Œæ•´ä¿®è®¢è·¯çº¿å›¾
- `PROJECT_SUMMARY.md` - é¡¹ç›®æ–¹æ³•æ€»ç»“
- `related_work_new.md` - Efficiency Gapç†è®ºæ¡†æ¶
- `related_work.md` - åŸºç¡€æ–‡çŒ®ç»¼è¿°

### å®éªŒæ•°æ®æ¥æº
- `results/adaptive/main/` - ä¸»å®éªŒç»“æœ (1000 tokens)
- `results/adaptive/ablation/` - æ¶ˆèå®éªŒ (500 tokens, D=4/5/6)
- `results/adaptive/sensitivity/` - å‚æ•°æ•æ„Ÿæ€§
- `results/adaptive/scalability/` - å¯æ‰©å±•æ€§åˆ†æ

### ä»£ç å®ç°
- `spec_decode/core/tree_speculative_generator_adaptive.py` - è‡ªé€‚åº”æ ‘ç”Ÿæˆå™¨å®ç°

---

## âœ¨ æ€»ç»“

æœ¬æ¬¡ä¿®è®¢å®ç°äº†è®ºæ–‡ä»"æ ‘æ¨æµ‹è§£ç çš„ä¸€èˆ¬å®ç°"åˆ°"ç½®ä¿¡åº¦æ„ŸçŸ¥è‡ªé€‚åº”æ ‘æ¨æµ‹è§£ç åˆ›æ–°æ¡†æ¶"çš„æˆ˜ç•¥å‡çº§ã€‚é€šè¿‡å¼•å…¥**Efficiency Gap**æ¦‚å¿µã€å¼ºåŒ–**ä¸‰é˜¶æ®µè‡ªé€‚åº”æœºåˆ¶**ã€çªå‡º**Training-freeä¼˜åŠ¿**ï¼ŒæˆåŠŸå»ºç«‹äº†ä¸ç°æœ‰å·¥ä½œçš„æ¸…æ™°å·®å¼‚åŒ–ï¼Œå°†æ ¸å¿ƒåˆ›æ–°ä»åˆ†æ•£çš„æŠ€æœ¯ç»†èŠ‚æå‡åˆ°ç³»ç»ŸåŒ–çš„æ–¹æ³•è®ºå±‚é¢ã€‚

**ä¿®è®¢æˆæœ**:
- ğŸ“ æ–‡æ¡£æ›´ç²¾ç‚¼ï¼ˆæ‘˜è¦-31%, Related Work-53%ï¼‰
- ğŸ“š å¼•ç”¨æ›´å…¨é¢ï¼ˆ+10ç¯‡æœ€æ–°adaptiveæ–¹æ³•ï¼‰
- ğŸ¯ åˆ›æ–°æ›´çªå‡ºï¼ˆ16.3%é‡åŒ–æ”¹è¿›ï¼Œåå¤å¼ºè°ƒï¼‰
- âœ… é£æ ¼æ›´è§„èŒƒï¼ˆNeurIPSæ ‡å‡†ï¼Œæ®µè½å‡è¡¡ï¼‰

**å¾…å®Œæˆæ ¸å¿ƒ**:
- Methodologyéƒ¨åˆ†çš„adaptiveç®—æ³•è¯¦ç»†æè¿°æ˜¯æœ€å…³é”®çš„é—ç•™ä»»åŠ¡
- å®éªŒéƒ¨åˆ†éœ€è¦å…¨é¢å¯¹é½adaptiveå®éªŒæ•°æ®

ä¿®è®¢åçš„è®ºæ–‡å·²å…·å¤‡æŠ•ç¨¿é¡¶ä¼šçš„åŸºæœ¬è´¨é‡è¦æ±‚ï¼Œæ ¸å¿ƒå™äº‹æ¸…æ™°ï¼Œåˆ›æ–°ç‚¹çªå‡ºï¼Œå®éªŒå……åˆ†ã€‚

